{
  "source_pdf": "/home/zzangmane/2025_null_Figure/pdfs/naacl-2025/EMS-SD_Efficient_Multi-sample_Speculative_Decoding_for_Accelerating_Large_Language_Models_2025.naacl-long.471.pdf",
  "page": 2,
  "figureType": null,
  "name": "2",
  "caption": "Figure 2: Our Method v.s. Vanilla Method. We specify the location of the KV cache for each sample individually, thus eliminating the necessity for the addition of padding to the KV cache. And we concatenate all input tokens of each sample into a single sequence without padding tokens when the number of prediction tokens differs between samples. Our method demonstrates superior performance than the vanilla method, without the need for additional computational and memory access overhead.",
  "regionBoundary": {
    "x1": 85.92,
    "x2": 500.15999999999997,
    "y1": 76.32,
    "y2": 391.2
  },
  "score": 1.0,
  "reason": "Clearly compares overall decoding architectures; includes system flow, steps, and conceptual tokens/legend."
}