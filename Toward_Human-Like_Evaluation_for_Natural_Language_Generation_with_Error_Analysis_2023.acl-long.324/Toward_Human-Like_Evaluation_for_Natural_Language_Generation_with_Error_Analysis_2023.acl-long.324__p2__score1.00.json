{
  "source_pdf": "/home/zzangmane/2025_null_Figure/pdfs/acl-2023/Toward_Human-Like_Evaluation_for_Natural_Language_Generation_with_Error_Analysis_2023.acl-long.324.pdf",
  "page": 2,
  "figureType": null,
  "name": "1",
  "caption": "Figure 1: An analogy between MQM and BARTScore++. We show an evaluation example from machine translation (zh-en). Top: Source and reference sentence provided for evaluation. Medium: An annotation example using MQM framework. Errors in the hypothesis are assigned with Major and Minor. The MQM score is computed through the weighted sum of these errors. Bottom: BARTScore++. The hypothesis is first refined through an error analysis framework. The refined sentence is then used to obtain the distance of explicit/ implicit errors through vanilla BARTScore. Different weights are finally assigned to these errors to get a more accurate score.",
  "regionBoundary": {
    "x1": 69.6,
    "x2": 526.0799999999999,
    "y1": 69.6,
    "y2": 296.15999999999997
  },
  "score": 1.0,
  "reason": "Depicts the architecture and workflow of MQM and BARTScore++ systems in an overview format."
}