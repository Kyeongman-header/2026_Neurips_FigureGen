{
  "source_pdf": "/home/zzangmane/2025_null_Figure/pdfs/coling-2025/Automated_Progressive_Red_Teaming_2025.coling-main.260.pdf",
  "page": 1,
  "figureType": null,
  "name": "1",
  "caption": "Figure 1: Illustration of APRT. In the training process, the Intention Expanding LLM first generates diverse samples that are relatively easy to jailbreak the Target LLM after intention concealment. For each prompt generated by the Intention Expanding LLM, the Intention Hiding LLM transforms it into multiple effective samples with deceptive behavior towards the Target LLM, without changing the original intention of the prompt. The Target LLM dedicates to generating safe responses to resist the attacks from the Intention Hiding LLM. Two Reward LLMs provide a bias to select new incremental training samples for the Intention Hiding LLM. To swiftly enhance the capability of concealing the intentions within input prompts, the Intention Hiding LLM employs an active learning strategy to prioritize selecting samples that can successfully elicit unsafe yet helpful responses from the Target LLM with intentions that are difficult to perceive.",
  "regionBoundary": {
    "x1": 70.56,
    "x2": 525.12,
    "y1": 70.56,
    "y2": 286.56
  },
  "score": 1.0,
  "reason": "Depicts a multi-stage system pipeline for attack sample collection, intention hiding, and model training."
}