{
  "source_pdf": "/home/zzangmane/2025_null_FigureGen/for_human_eval_papers/Finetuning LLMs for Human Behavior Prediction in Social Science Experiments.pdf",
  "page": 0,
  "figureType": null,
  "name": "1",
  "caption": "Figure 1: We release SOCSCI210, a large-scale dataset built from open-source social science experiments. Through finetuning, we create behavioral prediction models SOCRATES-LLAMA-8B and SOCRATESQWEN-14B, which predict responses that are 12.1% and 13.2% respectively more aligned with human response distributions to outcomes under diverse experimental conditions, relative to GPT-4o.",
  "regionBoundary": {
    "x1": 305.76,
    "x2": 524.16,
    "y1": 222.72,
    "y2": 465.12
  },
  "score": 1.0,
  "reason": "Figure provides a dataset and system overview, as well as model framework comparisons."
}