{
  "source_pdf": "/home/zzangmane/2025_null_FigureGen/for_human_eval_papers/2025.naacl-long.434.pdf",
  "page": 3,
  "figureType": null,
  "name": "2",
  "caption": "Figure 2: REVTHINK consists of two stages: (1) Data augmentation and (2) Student model learning. First, given a dataset D = {(Q(i), A(i))}ni=1, we augment it by prompting the teacher model to generate forward reasoning, backward question, and backward reasoning. We keep instances only with correct forward reasoning (validated by the ground truth) and consistent forward-backward reasoning (validated by the teacher model). This yields an augmented dataset Daug = (Q(i), R (i) f , Q (i) b , R (i) b )ni=1. Next, we train the student model with three objectives: Q → Rf , Q → Qb and Qb → Rb, enabling the student to reason in both directions during training. At test time, the student model performs only forward reasoning, making test-time compute as efficient as zero-shot prompting.",
  "regionBoundary": {
    "x1": 72.48,
    "x2": 524.16,
    "y1": 71.52,
    "y2": 235.2
  },
  "score": 1.0,
  "reason": "Illustrates system workflow, showing dataset, model roles, processes, and learning objectives overview."
}