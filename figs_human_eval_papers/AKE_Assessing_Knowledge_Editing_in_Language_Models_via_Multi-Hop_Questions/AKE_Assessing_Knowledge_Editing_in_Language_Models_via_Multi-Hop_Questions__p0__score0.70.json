{
  "source_pdf": "/home/zzangmane/2025_null_FigureGen/for_human_eval_papers/2023.emnlp-main.971.pdf",
  "page": 0,
  "figureType": null,
  "name": "1",
  "caption": "Figure 1: An example of our benchmark MQUAKE. Existing knowledge-editing methods often perform well at answering paraphrased questions of the edited fact but fail on multi-hop questions that are entailed consequences of the edited fact.",
  "regionBoundary": {
    "x1": 305.76,
    "x2": 525.12,
    "y1": 211.67999999999998,
    "y2": 345.12
  },
  "score": 0.7,
  "reason": "Presents a system editing overview with before/after model results."
}