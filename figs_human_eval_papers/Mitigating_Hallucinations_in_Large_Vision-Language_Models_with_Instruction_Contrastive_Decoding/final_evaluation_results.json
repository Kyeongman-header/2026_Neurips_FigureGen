{
  "paper_name": "Mitigating_Hallucinations_in_Large_Vision-Language_Models_with_Instruction_Contrastive_Decoding",
  "evaluated_at": "2025-12-28T01:24:28.503624",
  "figure_evaluations": [
    {
      "figure_file": "Mitigating_Hallucinations_in_Large_Vision-Language_Models_with_Instruction_Contrastive_Decoding__p3__score1.00.png",
      "caption": "Figure 1: An illustration on inference framework and contrastive decoding process of ICD method. At the core (middle orange box), the framework integrates a frozen image encoder, LLM, and query vectors (gray box) within the Q-Former, focusing solely on adjusting the standard and disturbance instructions. The latter, exemplified by adding role prefixes like ‘You are a confused object detector,’ aims to increase multimodal alignment uncertainty. This results in two distinct distributions: one from the standard instruction and another influenced by the disturbance. The contrastive decoding method (right orange box) highlights how disturbance instructions amplify hallucinated concepts (‘person and fork’), which are then corrected by subtracting probabilities derived from the standard instruction, ensuring accurate recognition of the correct concept ‘dog’.",
      "scores": {
        "Informativeness": {
          "score": 0.55,
          "sub_metrics": [
            {
              "question": "1.1. Content Coverage: Does it include all major components or formulas mentioned in the paper without omission?",
              "score": 0.6,
              "reason": "The figure captures the core architectural components relevant to ICD (image encoder, Q-Former/fusion module with learnable queries, LLM) and the key idea of producing two distributions (standard vs disturbance instruction) and performing contrastive decoding by subtracting probabilities to suppress hallucinated concepts. However, it does not include the main mathematical formulation(s) in the method section (e.g., the paper’s explicit equations/definitions for the contrasted distributions, scaling/hyperparameters, decoding rule details), nor does it reflect benchmark/metric definitions or other methodological elements beyond the central schematic."
            },
            {
              "question": "1.2. Standalone Intelligibility: Can one understand the general operating principle of the system just by looking at this figure without reading the paper?",
              "score": 0.8,
              "reason": "Yes at a high level: it shows an input image + text query, two instruction variants (standard and disturbance), two resulting probability distributions, and a contrastive decoding step that removes disturbance-amplified (hallucinatory) tokens to favor the correct token. Labels like “disturbance instruction,” “multimodal alignment uncertainty,” and the example (‘dog’ vs hallucinated ‘person/fork’) make the intended mechanism understandable, though precise implementation details (exact subtraction rule, where applied, and any constraints) are not fully recoverable from the figure alone."
            },
            {
              "question": "1.3. Completeness: Is the content from the beginning to the end of the paper summarized and included?",
              "score": 0.25,
              "reason": "No. The figure focuses on the method overview and intuition only. It does not summarize the full paper arc (motivation/background, detailed algorithmic steps and variants, experimental setup, datasets/benchmarks like POPE/MME/LLaVa-Bench, quantitative results, ablations, analysis, limitations). As a method schematic, it is not intended to cover the entire paper content."
            }
          ]
        },
        "Fidelity": {
          "score": 0.9,
          "sub_metrics": [
            {
              "question": "2.1. Hallucination: Does it avoid including components or formulas not mentioned in the paper?",
              "score": 0.85,
              "reason": "The figure largely sticks to elements described in the paper’s method (image encoder, Q-Former/fusion, LLM, two instructions producing two distributions, then contrastive decoding). However, it introduces some implementation-detail labels/blocks (e.g., explicit “Self Attention / Cross-attention / Feedforward” sublayers and “Fully Connected”) that are plausible for a transformer/Q-Former but are not clearly specified in the provided text excerpt, making them mildly speculative rather than directly grounded."
            },
            {
              "question": "2.2. Relation Correctness: Are the relationships between major components or formulas mentioned in the paper accurately represented?",
              "score": 0.9,
              "reason": "The depicted relationships align with the described mechanism: the instruction (and disturbance instruction) conditions the fusion/Q-Former to produce different multimodal-aligned representations and thus different token probability distributions, and ICD contrasts/subtracts to suppress hallucinated concepts. The overall flow (image→encoder→fusion with instruction→LLM distribution; then contrast) matches the paper description, though the exact mathematical form shown on the right is schematic rather than a verified equation from the excerpt."
            },
            {
              "question": "2.3. Label Accuracy: Are the names of major components or methodologies mentioned in the paper accurately labeled?",
              "score": 0.95,
              "reason": "Major components/methods are labeled consistently with the paper context: “Image Encoder,” “Q-former,” “LLM,” “Instruction,” “Disturbance Instruction,” and “Contrastive Decoding/ICD.” The disturbance example with role prefix is consistent with the text. Minor ambiguity: calling the module “Q-former” is specific to BLIP-2/miniGPT4/InstructBLIP and may not generalize to all LVLMs, but it is accurate for the discussed class of models."
            }
          ]
        },
        "Overall Readability": {
          "score": 0.78,
          "sub_metrics": [
            {
              "question": "Overall Readability",
              "score": 0.78,
              "reason": "The figure is generally readable and communicates the ICD pipeline (standard vs. disturbance instruction → two distributions → contrastive subtraction) with a clear left-to-right flow and consistent color grouping. However, readability is reduced by small text (especially within the Q-former blocks and probability labels), dense internal annotations, and reliance on color/visual clutter in the middle panel; key mathematical notations and distribution expressions are difficult to parse at typical paper viewing sizes. The caption is long and partially compensates, but the figure would benefit from fewer micro-labels, larger fonts, and stronger emphasis of the key contrast (two distributions and the subtraction outcome) over internal module details."
            }
          ]
        },
        "Design Quality": {
          "score": 0.864,
          "sub_metrics": [
            {
              "question": "4.1. Direction: Does the diagram flow from left to right or top to bottom?",
              "score": 0.9,
              "reason": "Overall flow is clearly left-to-right: inputs (image/text) on the left, model/fusion in the center, and decoding outcome on the right. Minor ambiguity arises because the middle module contains two parallel branches (disturbance vs. standard) and internal top-down subflows, but the primary reading direction remains clear."
            },
            {
              "question": "4.2. Crossing: Do the connection lines avoid crossing each other?",
              "score": 0.95,
              "reason": "Arrows and connectors are mostly non-overlapping and do not visibly cross. The layout uses parallel lanes and boxed regions to keep paths separated; any potential overlaps are avoided via spacing and grouping."
            },
            {
              "question": "4.3. Proximity: Are functionally closely related modules physically placed near each other?",
              "score": 0.85,
              "reason": "Strong grouping: the Q-Former subcomponents are co-located, and each branch (disturbance vs. instruction) contains its own aligned stack (attention blocks, feedforward, FC, LLM). The right-side contrastive decoding is appropriately separated as a downstream step, though the mapping from the two branch outputs to the right panel could be made more spatially explicit."
            },
            {
              "question": "4.4. Alignment: Are nodes aligned neatly horizontally and vertically according to an invisible grid?",
              "score": 0.8,
              "reason": "Within each branch, blocks are fairly well aligned, and the two branches are roughly symmetric. However, there are small inconsistencies in horizontal/vertical alignment among the small internal components (e.g., query boxes and some labels), and the transition from the center panel to the right panel is not grid-tight."
            },
            {
              "question": "4.5. Hierarchy: Do the important main components stand out in size, thickness, or position?",
              "score": 0.9,
              "reason": "Key stages are visually prominent: inputs on the left, the main framework (large central orange box), and contrastive decoding (large right orange box). Major modules (Image Encoder, LLM) are emphasized with larger colored blocks. Some finer elements (e.g., learned queries vs. text query) could be more distinctly emphasized relative to surrounding decorations."
            },
            {
              "question": "4.6. Margin: Is there sufficient margin between elements?",
              "score": 0.75,
              "reason": "The macro-level spacing between the three main regions is adequate, but the central panel is dense: multiple small blocks, labels, and arrows are packed tightly. This slightly reduces legibility and makes the figure feel crowded, particularly around the Q-Former internals and the probability distribution callouts."
            },
            {
              "question": "4.7. Consistency: Are components with similar roles represented with the same shape and color?",
              "score": 0.9,
              "reason": "Consistent visual language across the two branches: corresponding modules use the same shapes and colors (attention/feedforward/FC/LLM). The color palette is stable across the figure. Minor inconsistency comes from the use of multiple highlight colors for small tokens/queries without a fully explicit legend, which can make equivalence classes slightly ambiguous."
            }
          ]
        },
        "Creativity": {
          "score": 0.517,
          "sub_metrics": [
            {
              "question": "5.1. Metaphor: To what extent are abstract concepts replaced with concrete icons, symbols, or abbreviations?",
              "score": 0.55,
              "reason": "The figure concretizes abstract inference/decoding concepts using schematic modules (Image Encoder, Q-Former, LLM), token-probability bars, and check/cross marks to depict suppression of hallucinated concepts. However, most elements remain standard block-diagram abstractions rather than richer metaphorical iconography or symbolic encodings beyond labels and simple marks."
            },
            {
              "question": "5.2. Novelty: Does the generated image have a unique style that differentiates it from common templates?",
              "score": 0.38,
              "reason": "The visual style largely follows common ML paper conventions: pipeline blocks, attention/cross-attention boxes, and probability bar charts. The split between standard vs disturbance instruction and the explicit subtraction depiction adds some distinctiveness, but overall it resembles familiar architecture-and-decoding schematics rather than a notably unique visual language."
            },
            {
              "question": "5.3. Adaptability: Does it apply a layout more suitable for the specific paper, breaking away from uniform design principles?",
              "score": 0.62,
              "reason": "The layout is tailored to the paper’s core claim by juxtaposing two instruction conditions within the same fusion/LLM framework and then linking them to a dedicated contrastive decoding panel. This multi-panel cause→effect structure (disturbance induces hallucinations; subtraction removes them) is more customized than a generic single-flow architecture diagram, though it still uses standard modular composition."
            }
          ]
        },
        "weighted_total": 0.722
      }
    }
  ]
}