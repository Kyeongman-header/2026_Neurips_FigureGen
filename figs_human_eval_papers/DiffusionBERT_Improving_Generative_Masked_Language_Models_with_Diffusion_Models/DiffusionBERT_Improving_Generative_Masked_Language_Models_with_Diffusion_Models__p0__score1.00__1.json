{
  "source_pdf": "/home/zzangmane/2025_null_FigureGen/for_human_eval_papers/2023.acl-long.248.pdf",
  "page": 0,
  "figureType": null,
  "name": "1",
  "caption": "Figure 1: In contrast to conventional discrete diffusion models, DiffusionBERT uses BERT as its backbone to perform text generation. The main differences are highlighted in color: (1) DiffusionBERT performs decoding without knowing the current time step while canonical diffusion models are conditioned on time step. (2) The diffusion process of DiffusionBERT is non-Markovian in that it generates noise samples xt conditioning not only on xtâˆ’1 but also on x0. Such a non-Markov process is due to our proposed noise schedule.",
  "regionBoundary": {
    "x1": 309.59999999999997,
    "x2": 523.1999999999999,
    "y1": 216.0,
    "y2": 339.84
  },
  "score": 1.0,
  "reason": "Depicts system overviews of diffusion models and Non-Markovian DiffusionBERT architectures."
}