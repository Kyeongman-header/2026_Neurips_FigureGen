{
  "source_pdf": "/home/zzangmane/2025_null_FigureGen/for_human_eval_papers/new/2024.naacl-long.302.pdf",
  "page": 0,
  "figureType": null,
  "name": "1",
  "caption": "Figure 1: An overview of our evaluation benchmark, EvolvingQA. Our benchmark employs LLM to generate question-answer pairs based on the changes in Wikipediaâ€™s snapshots, effectively capturing the temporal evolution of the knowledge base.",
  "regionBoundary": {
    "x1": 305.76,
    "x2": 525.12,
    "y1": 219.84,
    "y2": 447.35999999999996
  },
  "score": 0.95,
  "reason": "Diagram shows system overview of data evolution, timelines, and question-answer process."
}