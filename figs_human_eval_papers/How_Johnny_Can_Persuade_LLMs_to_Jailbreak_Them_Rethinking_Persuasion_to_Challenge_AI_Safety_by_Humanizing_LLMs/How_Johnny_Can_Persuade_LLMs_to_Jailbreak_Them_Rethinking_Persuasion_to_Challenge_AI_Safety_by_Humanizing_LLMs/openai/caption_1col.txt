Figure 2. Comparison of jailbreak paradigms by degree of “humanizing” LLM interaction, showing representative optimization-, side-channel-, and distribution-based prompts versus human-readable persuasive adversarial prompts (PAPs) generated from a social-science–grounded persuasion taxonomy.