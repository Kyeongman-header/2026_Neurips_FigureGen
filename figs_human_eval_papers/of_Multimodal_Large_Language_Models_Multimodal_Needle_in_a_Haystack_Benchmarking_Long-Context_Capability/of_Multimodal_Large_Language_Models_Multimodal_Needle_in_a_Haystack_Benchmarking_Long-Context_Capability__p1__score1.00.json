{
  "source_pdf": "/home/zzangmane/2025_null_FigureGen/for_human_eval_papers/2025.naacl-long.166.pdf",
  "page": 1,
  "figureType": null,
  "name": "1",
  "caption": "Figure 1: MMNeedle evaluation overview. Correct answers are marked with checkmark (✓), while the incorrect answers are marked with cross (×). Our evaluation setup involves the following key components: (a) Needle Sub-Image: The needle sub-image to be retrieved based on the given caption. (b) Haystack Image Inputs: The long-context visual inputs consist of M images, each stitched from N × N sub-images. (c) Text Inputs (Instructions and Caption): Detailed instructions to MLLMs, followed by a caption describing the needle, i.e., sub-image 20. See Sec. A for MMNeedle’s complete instructions. (d) LLM Outputs: The answers from different MLLMs, indicating their ability to accurately locate the needle in the haystack based on the given caption. The expected output is composed of the model’s identification of the index, row, and column of the matching sub-image. The results showcase the comparative performance of various models: GPT-4o correctly predicts the exact location of the needle; Gemini Pro 1.5 only correctly predicts the image index of the needle; other API models predict incorrect locations; open-source models often output with wrong formats.",
  "regionBoundary": {
    "x1": 70.56,
    "x2": 524.16,
    "y1": 70.56,
    "y2": 154.07999999999998
  },
  "score": 1.0,
  "reason": "Diagram provides an overview of a multimodal system's architecture and workflow."
}