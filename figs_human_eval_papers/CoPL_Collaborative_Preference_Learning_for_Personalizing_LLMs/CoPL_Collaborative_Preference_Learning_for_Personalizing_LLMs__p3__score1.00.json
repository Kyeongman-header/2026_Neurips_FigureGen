{
  "source_pdf": "/home/zzangmane/2025_null_FigureGen/for_human_eval_papers/CoPL  Collaborative Preference Learning for Personalizing LLMs.pdf",
  "page": 3,
  "figureType": null,
  "name": "2",
  "caption": "Figure 2: An overview of CoPL. To learn user representations, the GCF model is trained on a user-response bipartite graph. To build a personalized reward model, CoPL uses the learned representations to select a user-specific expert from MoLE, enabling effective modeling of diverse preferences.",
  "regionBoundary": {
    "x1": 72.0,
    "x2": 524.16,
    "y1": 71.52,
    "y2": 180.95999999999998
  },
  "score": 1.0,
  "reason": "Depicts an end-to-end system overview with modules, data flow, and major components."
}