{
  "source_pdf": "/home/zzangmane/2025_null_FigureGen/for_human_eval_papers/Shifting Attention to Relevance  Towards the Predictive Uncertainty Quantification of Free Form Large Language Models.pdf",
  "page": 0,
  "figureType": null,
  "name": "1",
  "caption": "Figure 1: Irrelevant tokens (or sentences) may commit majority uncertainty in free-form generations, such as the token “of” committing extremely large uncertainty misleads the uncertainty quantification of LLMs. We term these observations as generative inequalities and tackle them by shifting attention to more relevant components.",
  "regionBoundary": {
    "x1": 316.8,
    "x2": 514.0799999999999,
    "y1": 219.84,
    "y2": 417.12
  },
  "score": 0.9,
  "reason": "Diagram compares two system-level uncertainty quantification frameworks for LLMs."
}