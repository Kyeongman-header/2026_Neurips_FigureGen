[
    {
        "figure_name": "Weakly_Supervised_Semantic_Parsing_with_Execution-based_Spurious_Program_Filtering__p2__score0.70.png",
        "Correlation_Impact": -0.041733,
        "details": {
            "Informativeness": 0.001612,
            "Fidelity": -0.01384,
            "Overall Readability": 0.000766,
            "Creativity": -0.005586,
            "Design Quality": -0.024685
        }
    },
    {
        "figure_name": "Exploring_Precision_and_Recall_to_assess_the_quality_and_diversity_of_LLMs__p4__score1.00.png",
        "Correlation_Impact": -0.036512,
        "details": {
            "Informativeness": -0.001574,
            "Fidelity": -0.000803,
            "Overall Readability": -0.022011,
            "Creativity": -0.011926,
            "Design Quality": -0.000198
        }
    },
    {
        "figure_name": "Distilling_Step-by-Step_Outperforming_Larger_Language_Models_with_Less_Training_Data_and_Smaller_Model_Sizes__p2__score0.95.png",
        "Correlation_Impact": -0.031942,
        "details": {
            "Informativeness": -0.00239,
            "Fidelity": -0.014794,
            "Overall Readability": -0.012533,
            "Creativity": 0.007041,
            "Design Quality": -0.009266
        }
    },
    {
        "figure_name": "IHEval_Evaluating_Language_Models_on_Following_the_Instruction_Hierarchy__p4__score0.80.png",
        "Correlation_Impact": -0.028143,
        "details": {
            "Informativeness": -0.022862,
            "Fidelity": -0.00257,
            "Overall Readability": 8.9e-05,
            "Creativity": -0.00122,
            "Design Quality": -0.00158
        }
    },
    {
        "figure_name": "VISTA_Visualized_Text_Embedding_For_Universal_Multi-Modal_Retrieval__p3__score1.00.png",
        "Correlation_Impact": -0.025386,
        "details": {
            "Informativeness": 6.3e-05,
            "Fidelity": -0.004905,
            "Overall Readability": -0.01235,
            "Creativity": 0.003919,
            "Design Quality": -0.012114
        }
    },
    {
        "figure_name": "ImageInWords_Unlocking_Hyper-Detailed_Image_Descriptions__p1__score0.98.png",
        "Correlation_Impact": -0.024103,
        "details": {
            "Informativeness": 0.001523,
            "Fidelity": -0.00257,
            "Overall Readability": -0.022011,
            "Creativity": -0.000364,
            "Design Quality": -0.000681
        }
    },
    {
        "figure_name": "How_Johnny_Can_Persuade_LLMs_to_Jailbreak_Them_Rethinking_Persuasion_to_Challenge_AI_Safety_by_Humanizing_LLMs__p4__score0.80.png",
        "Correlation_Impact": -0.021845,
        "details": {
            "Informativeness": -0.00382,
            "Fidelity": 0.004671,
            "Overall Readability": -0.022011,
            "Creativity": 0.000895,
            "Design Quality": -0.00158
        }
    },
    {
        "figure_name": "DocFinQA_A_Long-Context_Financial_Reasoning_Dataset__p0__score0.80.png",
        "Correlation_Impact": -0.020728,
        "details": {
            "Informativeness": 0.000871,
            "Fidelity": -0.013,
            "Overall Readability": -0.003593,
            "Creativity": -0.006438,
            "Design Quality": 0.001433
        }
    },
    {
        "figure_name": "Exploring_Precision_and_Recall_to_assess_the_quality_and_diversity_of_LLMs__p3__score0.80.png",
        "Correlation_Impact": -0.018518,
        "details": {
            "Informativeness": 0.001517,
            "Fidelity": 0.000531,
            "Overall Readability": -0.002767,
            "Creativity": -0.011926,
            "Design Quality": -0.005873
        }
    },
    {
        "figure_name": "Humans_or_LLMs_as_the_Judge_A_Study_on_Judgement_Bias__p3__score1.00.png",
        "Correlation_Impact": -0.018499,
        "details": {
            "Informativeness": -0.007483,
            "Fidelity": -0.00503,
            "Overall Readability": -0.001687,
            "Creativity": 0.000765,
            "Design Quality": -0.005063
        }
    },
    {
        "figure_name": "Know_When_To_Stop_A_Study_of_Semantic_Drift_in_Text_Generation__p1__score0.70.png",
        "Correlation_Impact": -0.018016,
        "details": {
            "Informativeness": 0.001644,
            "Fidelity": -0.008508,
            "Overall Readability": -0.006984,
            "Creativity": 0.000895,
            "Design Quality": -0.005063
        }
    },
    {
        "figure_name": "Locating_and_Extracting_Relational_Concepts_in_Large_Language_Models__p0__score0.95.png",
        "Correlation_Impact": -0.017953,
        "details": {
            "Informativeness": -0.016663,
            "Fidelity": 0.000531,
            "Overall Readability": 0.003674,
            "Creativity": -0.005586,
            "Design Quality": 9e-05
        }
    },
    {
        "figure_name": "Memory_OS_of_AI_Agent__p7__score0.90.png",
        "Correlation_Impact": -0.017399,
        "details": {
            "Informativeness": -0.004914,
            "Fidelity": -0.004905,
            "Overall Readability": -0.00486,
            "Creativity": -0.006438,
            "Design Quality": 0.003719
        }
    },
    {
        "figure_name": "MP2D_AnAutomated_Topic_Shift_Dialogue_Generation_Framework__p2__score1.00.png",
        "Correlation_Impact": -0.016478,
        "details": {
            "Informativeness": -0.00382,
            "Fidelity": -0.00257,
            "Overall Readability": -0.005293,
            "Creativity": -0.006438,
            "Design Quality": 0.001642
        }
    },
    {
        "figure_name": "Finetuning_LLMs_for_Human_Behavior_Prediction_in_Social_Science_Experiments__p0__score1.00.png",
        "Correlation_Impact": -0.016034,
        "details": {
            "Informativeness": 0.001093,
            "Fidelity": -0.000445,
            "Overall Readability": -0.001687,
            "Creativity": -0.006438,
            "Design Quality": -0.008557
        }
    },
    {
        "figure_name": "Less_is_More_Mitigating_Multimodal_Hallucination_from_an_EOS_Decision_Perspective__p4__score0.70.png",
        "Correlation_Impact": -0.015498,
        "details": {
            "Informativeness": 0.001517,
            "Fidelity": -0.000445,
            "Overall Readability": -0.005293,
            "Creativity": 0.000895,
            "Design Quality": -0.012172
        }
    },
    {
        "figure_name": "Models_Fine-grained_Gender_Control_in_Machine_Translation_with_Large_Language__p1__score0.70.png",
        "Correlation_Impact": -0.015209,
        "details": {
            "Informativeness": -0.010781,
            "Fidelity": -0.004905,
            "Overall Readability": 0.000766,
            "Creativity": -0.001932,
            "Design Quality": 0.001642
        }
    },
    {
        "figure_name": "AGrail_A_Lifelong_Agent_Guardrail_with_Effective_and_Adaptive_Safety_Detection__p3__score1.00.png",
        "Correlation_Impact": -0.014543,
        "details": {
            "Informativeness": 0.001093,
            "Fidelity": -0.006313,
            "Overall Readability": -0.00671,
            "Creativity": 0.003919,
            "Design Quality": -0.006533
        }
    },
    {
        "figure_name": "A_Theory_of_Response_Sampling_in_LLMs_Part_Descriptive_and_Part_Prescriptive__p4__score0.80.png",
        "Correlation_Impact": -0.014509,
        "details": {
            "Informativeness": -0.00382,
            "Fidelity": 0.000531,
            "Overall Readability": 0.003674,
            "Creativity": -0.011926,
            "Design Quality": -0.002969
        }
    },
    {
        "figure_name": "How_Johnny_Can_Persuade_LLMs_to_Jailbreak_Them_Rethinking_Persuasion_to_Challenge_AI_Safety_by_Humanizing_LLMs__p3__score1.00.png",
        "Correlation_Impact": -0.014098,
        "details": {
            "Informativeness": 0.001093,
            "Fidelity": 0.001624,
            "Overall Readability": -0.001921,
            "Creativity": -0.011926,
            "Design Quality": -0.002969
        }
    },
    {
        "figure_name": "Learning_from_Diverse_Reasoning_Paths_with_Routing_and_Collaboration__p0__score0.95.png",
        "Correlation_Impact": -0.0137,
        "details": {
            "Informativeness": -0.00239,
            "Fidelity": -0.006313,
            "Overall Readability": -0.000474,
            "Creativity": -0.000743,
            "Design Quality": -0.00378
        }
    },
    {
        "figure_name": "Generating_Diverse_Hypotheses_for_Inductive_Reasoning__p7__score0.70.png",
        "Correlation_Impact": -0.013521,
        "details": {
            "Informativeness": -0.007483,
            "Fidelity": 0.001858,
            "Overall Readability": -0.002767,
            "Creativity": -0.002516,
            "Design Quality": -0.002612
        }
    },
    {
        "figure_name": "LLMs_Trust_Humans_More_That_s_a_Problem_Unveiling_and_Mitigating_the_Authority_Bias_in_Retrieval-Augmented_Generation__p4__score1.00.png",
        "Correlation_Impact": -0.012766,
        "details": {
            "Informativeness": 0.000818,
            "Fidelity": -0.006313,
            "Overall Readability": -0.00671,
            "Creativity": -0.000364,
            "Design Quality": -0.000198
        }
    },
    {
        "figure_name": "Making_Long-Context_Language_Models_Better_Multi-Hop_Reasoners__p3__score1.00.png",
        "Correlation_Impact": -0.012433,
        "details": {
            "Informativeness": 0.005306,
            "Fidelity": -0.008508,
            "Overall Readability": -0.006984,
            "Creativity": 0.00631,
            "Design Quality": -0.008557
        }
    },
    {
        "figure_name": "Locating_and_Extracting_Relational_Concepts_in_Large_Language_Models__p3__score1.00.png",
        "Correlation_Impact": -0.012415,
        "details": {
            "Informativeness": -0.010781,
            "Fidelity": 0.001858,
            "Overall Readability": 0.003674,
            "Creativity": -0.005586,
            "Design Quality": -0.00158
        }
    },
    {
        "figure_name": "Mind_the_Value-Action_Gap_Do_LLMs_Act_in_Alignment_with_Their_Values__p1__score1.00.png",
        "Correlation_Impact": -0.012047,
        "details": {
            "Informativeness": 0.006417,
            "Fidelity": -0.004905,
            "Overall Readability": -0.00387,
            "Creativity": -0.00978,
            "Design Quality": 9e-05
        }
    },
    {
        "figure_name": "When_Not_to_Trust_Language_Models_Investigating_Effectiveness_of_Parametric_and_Non-Parametric_Memories__p2__score1.00.png",
        "Correlation_Impact": -0.011944,
        "details": {
            "Informativeness": 0.001517,
            "Fidelity": -0.009216,
            "Overall Readability": 8.9e-05,
            "Creativity": -0.005586,
            "Design Quality": 0.001252
        }
    },
    {
        "figure_name": "Locating_and_Extracting_Relational_Concepts_in_Large_Language_Models__p6__score0.97.png",
        "Correlation_Impact": -0.011701,
        "details": {
            "Informativeness": -0.010781,
            "Fidelity": 0.000531,
            "Overall Readability": 0.003674,
            "Creativity": -0.004928,
            "Design Quality": -0.000198
        }
    },
    {
        "figure_name": "Express_Uncertainty__p0__score0.80.png",
        "Correlation_Impact": -0.011609,
        "details": {
            "Informativeness": 0.001644,
            "Fidelity": -0.001502,
            "Overall Readability": -0.000474,
            "Creativity": 0.000895,
            "Design Quality": -0.012172
        }
    },
    {
        "figure_name": "Learning_from_Diverse_Reasoning_Paths_with_Routing_and_Collaboration__p2__score0.95.png",
        "Correlation_Impact": -0.010445,
        "details": {
            "Informativeness": 0.001612,
            "Fidelity": -0.007751,
            "Overall Readability": -0.000474,
            "Creativity": -0.00122,
            "Design Quality": -0.002612
        }
    },
    {
        "figure_name": "VISTA_Visualized_Text_Embedding_For_Universal_Multi-Modal_Retrieval__p2__score1.00.png",
        "Correlation_Impact": -0.00917,
        "details": {
            "Informativeness": -0.000966,
            "Fidelity": -0.00503,
            "Overall Readability": 0.003674,
            "Creativity": -0.006438,
            "Design Quality": -0.00041
        }
    },
    {
        "figure_name": "of_Multimodal_Large_Language_Models_Multimodal_Needle_in_a_Haystack_Benchmarking_Long-Context_Capability__p1__score1.00.png",
        "Correlation_Impact": -0.008961,
        "details": {
            "Informativeness": 0.001342,
            "Fidelity": -0.00257,
            "Overall Readability": -0.002767,
            "Creativity": -0.00013,
            "Design Quality": -0.004836
        }
    },
    {
        "figure_name": "MASTER_A_Multi-Agent_System_with_LLM_Specialized_MCTS__p2__score1.00.png",
        "Correlation_Impact": -0.008943,
        "details": {
            "Informativeness": 0.001093,
            "Fidelity": -0.001502,
            "Overall Readability": -0.001687,
            "Creativity": -0.006438,
            "Design Quality": -0.00041
        }
    },
    {
        "figure_name": "MARVEL_Unlocking_the_Multi-Modal_Capability_of_Dense_Retrieval_via_Visual_Module_Plugin__p0__score1.00.png",
        "Correlation_Impact": -0.008691,
        "details": {
            "Informativeness": -0.007483,
            "Fidelity": 0.004169,
            "Overall Readability": 0.003674,
            "Creativity": -0.006438,
            "Design Quality": -0.002612
        }
    },
    {
        "figure_name": "On_LLM-Based_Scientific_Inductive_Reasoning_Beyond_Equations__p6__score1.00.png",
        "Correlation_Impact": -0.008631,
        "details": {
            "Informativeness": -0.005565,
            "Fidelity": -0.004905,
            "Overall Readability": -0.002767,
            "Creativity": -0.000364,
            "Design Quality": 0.004971
        }
    },
    {
        "figure_name": "R-VLM_Region-Aware_Vision_Language_Model_for_Precise_GUI_Grounding__p1__score1.00.png",
        "Correlation_Impact": -0.008589,
        "details": {
            "Informativeness": 6.3e-05,
            "Fidelity": -0.00257,
            "Overall Readability": 0.000766,
            "Creativity": -0.006438,
            "Design Quality": -0.00041
        }
    },
    {
        "figure_name": "Blinded_by_Generated_Contexts_How_Language_Models_Merge_Generated_and_Retrieved_Contexts_When_Knowledge_Conflicts__p2__score0.95.png",
        "Correlation_Impact": -0.008567,
        "details": {
            "Informativeness": 6.3e-05,
            "Fidelity": 0.003173,
            "Overall Readability": -0.012533,
            "Creativity": -5e-06,
            "Design Quality": 0.000734
        }
    },
    {
        "figure_name": "ZoomEye_Enhancing_Multimodal_LLMs_with_Human-Like_Zooming_Capabilities_through_Tree-Based_Image_Exploration__p3__score0.95.png",
        "Correlation_Impact": -0.008304,
        "details": {
            "Informativeness": -0.006699,
            "Fidelity": 0.003661,
            "Overall Readability": -0.002767,
            "Creativity": -0.000743,
            "Design Quality": -0.001756
        }
    },
    {
        "figure_name": "Fooling_the_LVLM_Judges_Visual_Biases_in_LVLM-Based_Evaluation_3.5_4.1__p0__score0.95.png",
        "Correlation_Impact": -0.00821,
        "details": {
            "Informativeness": -0.001574,
            "Fidelity": -0.002151,
            "Overall Readability": -0.00387,
            "Creativity": -0.005586,
            "Design Quality": 0.004971
        }
    },
    {
        "figure_name": "Fooling_the_LVLM_Judges_Visual_Biases_in_LVLM-Based_Evaluation_3.5_4.1__p2__score0.60.png",
        "Correlation_Impact": -0.007578,
        "details": {
            "Informativeness": -0.00382,
            "Fidelity": -0.00257,
            "Overall Readability": 0.001229,
            "Creativity": -0.00978,
            "Design Quality": 0.007363
        }
    },
    {
        "figure_name": "Less_is_More_Mitigating_Multimodal_Hallucination_from_an_EOS_Decision_Perspective__p0__score0.60.png",
        "Correlation_Impact": -0.007443,
        "details": {
            "Informativeness": -0.006699,
            "Fidelity": 0.006689,
            "Overall Readability": -0.007979,
            "Creativity": 0.001227,
            "Design Quality": -0.000681
        }
    },
    {
        "figure_name": "IHEval_Evaluating_Language_Models_on_Following_the_Instruction_Hierarchy__p1__score1.00.png",
        "Correlation_Impact": -0.007367,
        "details": {
            "Informativeness": 0.001093,
            "Fidelity": 0.003173,
            "Overall Readability": -0.012533,
            "Creativity": -0.000743,
            "Design Quality": 0.001642
        }
    },
    {
        "figure_name": "Spiral_of_Silence_How_is_Large_Language_Model_Killing_Information_Retrieval_A_Case_Study_on_Open_Domain_Question_Answering__p0__score1.00.png",
        "Correlation_Impact": -0.00727,
        "details": {
            "Informativeness": 0.000818,
            "Fidelity": 0.000531,
            "Overall Readability": 8.9e-05,
            "Creativity": -0.004928,
            "Design Quality": -0.00378
        }
    },
    {
        "figure_name": "When_Not_to_Trust_Language_Models_Investigating_Effectiveness_of_Parametric_and_Non-Parametric_Memories__p0__score0.70.png",
        "Correlation_Impact": -0.006922,
        "details": {
            "Informativeness": 0.000818,
            "Fidelity": 0.003173,
            "Overall Readability": -0.002767,
            "Creativity": -0.006438,
            "Design Quality": -0.001707
        }
    },
    {
        "figure_name": "Blinded_by_Generated_Contexts_How_Language_Models_Merge_Generated_and_Retrieved_Contexts_When_Knowledge_Conflicts__p2__score1.00.png",
        "Correlation_Impact": -0.006854,
        "details": {
            "Informativeness": 6.3e-05,
            "Fidelity": 0.003173,
            "Overall Readability": -0.012533,
            "Creativity": -5e-06,
            "Design Quality": 0.002447
        }
    },
    {
        "figure_name": "LINC_A_Neurosymbolic_Approach_for_Logical_Reasoning_by_Combining_Language_Models_with_First-Order_Logic_Provers__p3__score0.98.png",
        "Correlation_Impact": -0.006582,
        "details": {
            "Informativeness": -0.00262,
            "Fidelity": 0.003173,
            "Overall Readability": -0.005293,
            "Creativity": -0.001932,
            "Design Quality": 9e-05
        }
    },
    {
        "figure_name": "LINC_A_Neurosymbolic_Approach_for_Logical_Reasoning_by_Combining_Language_Models_with_First-Order_Logic_Provers__p3__score1.00.png",
        "Correlation_Impact": -0.006582,
        "details": {
            "Informativeness": -0.00262,
            "Fidelity": 0.003173,
            "Overall Readability": -0.005293,
            "Creativity": -0.001932,
            "Design Quality": 9e-05
        }
    },
    {
        "figure_name": "DRAGIN_Dynamic_Retrieval_Augmented_Generation_based_on_the_Information_Needs_of_Large_Language_Models__p5__score0.60.png",
        "Correlation_Impact": -0.006576,
        "details": {
            "Informativeness": -0.00239,
            "Fidelity": 0.000531,
            "Overall Readability": -0.000807,
            "Creativity": -0.00013,
            "Design Quality": -0.00378
        }
    },
    {
        "figure_name": "Weakly_Supervised_Semantic_Parsing_with_Execution-based_Spurious_Program_Filtering__p0__score0.80.png",
        "Correlation_Impact": -0.006537,
        "details": {
            "Informativeness": 0.008391,
            "Fidelity": -0.010716,
            "Overall Readability": 0.008283,
            "Creativity": 0.00383,
            "Design Quality": -0.016325
        }
    },
    {
        "figure_name": "Self-Knowledge_Guided_Retrieval_Augmentation_for_Large_Language_Models__p3__score1.00.png",
        "Correlation_Impact": -0.006225,
        "details": {
            "Informativeness": 0.001517,
            "Fidelity": 0.001858,
            "Overall Readability": 8.9e-05,
            "Creativity": -0.00978,
            "Design Quality": 9e-05
        }
    },
    {
        "figure_name": "How_Johnny_Can_Persuade_LLMs_to_Jailbreak_Them_Rethinking_Persuasion_to_Challenge_AI_Safety_by_Humanizing_LLMs__p0__score0.95.png",
        "Correlation_Impact": -0.006161,
        "details": {
            "Informativeness": -0.00239,
            "Fidelity": -0.000445,
            "Overall Readability": -0.007979,
            "Creativity": 0.003919,
            "Design Quality": 0.000734
        }
    },
    {
        "figure_name": "Can_You_Trick_the_Grader_Adversarial_Persuasion_of_LLM_Judges__p0__score0.90.png",
        "Correlation_Impact": -0.005863,
        "details": {
            "Informativeness": 0.001644,
            "Fidelity": -0.001502,
            "Overall Readability": -0.002767,
            "Creativity": -5e-06,
            "Design Quality": -0.003234
        }
    },
    {
        "figure_name": "Language_Models_as_Inductive_Reasoners__p4__score1.00.png",
        "Correlation_Impact": -0.005788,
        "details": {
            "Informativeness": 0.001093,
            "Fidelity": -0.00352,
            "Overall Readability": -0.00486,
            "Creativity": 0.000765,
            "Design Quality": 0.000734
        }
    },
    {
        "figure_name": "Mind_the_Value-Action_Gap_Do_LLMs_Act_in_Alignment_with_Their_Values__p0__score0.95.png",
        "Correlation_Impact": -0.005754,
        "details": {
            "Informativeness": 0.000818,
            "Fidelity": -0.004905,
            "Overall Readability": -0.000807,
            "Creativity": 0.000895,
            "Design Quality": -0.001756
        }
    },
    {
        "figure_name": "Cross-Lingual_Retrieval_Augmented_Prompt_for_Low-Resource_Languages__p0__score1.00.png",
        "Correlation_Impact": -0.005536,
        "details": {
            "Informativeness": -0.007483,
            "Fidelity": 0.003173,
            "Overall Readability": 0.003674,
            "Creativity": -0.001932,
            "Design Quality": -0.002969
        }
    },
    {
        "figure_name": "Don_t_Forget_Your_ABC_s_Evaluating_the_State-of-the-Art_in_Chat-Oriented_Dialogue_Systems__p4__score0.70.png",
        "Correlation_Impact": -0.005521,
        "details": {
            "Informativeness": -0.00382,
            "Fidelity": -0.00257,
            "Overall Readability": -0.002767,
            "Creativity": 0.012902,
            "Design Quality": -0.009266
        }
    },
    {
        "figure_name": "In_Prospect_and_Retrospect_Re_ective_Memory_Management_for_Long-term_Personalized_Dialogue_Agents__p4__score1.00.png",
        "Correlation_Impact": -0.005341,
        "details": {
            "Informativeness": -0.00382,
            "Fidelity": -0.000445,
            "Overall Readability": 0.000766,
            "Creativity": -0.001932,
            "Design Quality": 9e-05
        }
    },
    {
        "figure_name": "Machine_Unlearning_of_Pre-trained_Large_Language_Models__p1__score1.00.png",
        "Correlation_Impact": -0.005179,
        "details": {
            "Informativeness": 0.001093,
            "Fidelity": 0.001858,
            "Overall Readability": 1.6e-05,
            "Creativity": -0.006438,
            "Design Quality": -0.001707
        }
    },
    {
        "figure_name": "WebEvolver_Enhancing_Web_Agent_Self-Improvement_with_Co-evolving_World_Model__p0__score1.00.png",
        "Correlation_Impact": -0.005006,
        "details": {
            "Informativeness": -0.00239,
            "Fidelity": 0.003173,
            "Overall Readability": 8.9e-05,
            "Creativity": -5e-06,
            "Design Quality": -0.005873
        }
    },
    {
        "figure_name": "IHEval_Evaluating_Language_Models_on_Following_the_Instruction_Hierarchy__p3__score1.00.png",
        "Correlation_Impact": -0.004821,
        "details": {
            "Informativeness": 0.006417,
            "Fidelity": -0.00257,
            "Overall Readability": -0.000474,
            "Creativity": -0.006438,
            "Design Quality": -0.001756
        }
    },
    {
        "figure_name": "Error-driven_Data-efficient_Large_Multimodal_Model_Tuning__p3__score0.95.png",
        "Correlation_Impact": -0.004719,
        "details": {
            "Informativeness": 6.3e-05,
            "Fidelity": -0.001502,
            "Overall Readability": 0.003674,
            "Creativity": -0.011926,
            "Design Quality": 0.004971
        }
    },
    {
        "figure_name": "Learning_from_Diverse_Reasoning_Paths_with_Routing_and_Collaboration__p3__score1.00.png",
        "Correlation_Impact": -0.004618,
        "details": {
            "Informativeness": 0.001523,
            "Fidelity": 0.000531,
            "Overall Readability": -0.007979,
            "Creativity": 0.003919,
            "Design Quality": -0.002612
        }
    },
    {
        "figure_name": "Conditional_MASK_Discrete_Diffusion_Language_Model__p0__score1.00.png",
        "Correlation_Impact": -0.004597,
        "details": {
            "Informativeness": 0.001644,
            "Fidelity": -0.007751,
            "Overall Readability": -0.003266,
            "Creativity": -0.000743,
            "Design Quality": 0.00552
        }
    },
    {
        "figure_name": "Beyond_Demographics_Fine-tuning_Large_Language_Models_to_Predict_Individuals_Subjective_Text_Perceptions__p0__score1.00.png",
        "Correlation_Impact": -0.004592,
        "details": {
            "Informativeness": 0.000818,
            "Fidelity": -0.001502,
            "Overall Readability": -0.006984,
            "Creativity": 0.00631,
            "Design Quality": -0.003234
        }
    },
    {
        "figure_name": "Knowledge_Unlearning_for_Mitigating_Privacy_Risks_in_Language_Models__p1__score1.00.png",
        "Correlation_Impact": -0.00446,
        "details": {
            "Informativeness": 0.001517,
            "Fidelity": 0.001858,
            "Overall Readability": -0.002767,
            "Creativity": -5e-06,
            "Design Quality": -0.005063
        }
    },
    {
        "figure_name": "Establishing_Trustworthy_LLM_Evaluation_via_Shortcut_Neuron_Analysis__p0__score0.95.png",
        "Correlation_Impact": -0.004437,
        "details": {
            "Informativeness": 0.001085,
            "Fidelity": 0.001858,
            "Overall Readability": 0.000766,
            "Creativity": -0.006438,
            "Design Quality": -0.001707
        }
    },
    {
        "figure_name": "Carpe_Diem_On_the_Evaluation_of_World_Knowledge_in_Lifelong_Language_Models__p0__score0.95.png",
        "Correlation_Impact": -0.00413,
        "details": {
            "Informativeness": 0.001093,
            "Fidelity": -0.000803,
            "Overall Readability": 0.000766,
            "Creativity": -0.006438,
            "Design Quality": 0.001252
        }
    },
    {
        "figure_name": "Carpe_Diem_On_the_Evaluation_of_World_Knowledge_in_Lifelong_Language_Models__p2__score1.00.png",
        "Correlation_Impact": -0.004022,
        "details": {
            "Informativeness": 0.001093,
            "Fidelity": -0.004905,
            "Overall Readability": -0.000807,
            "Creativity": 0.00383,
            "Design Quality": -0.003234
        }
    },
    {
        "figure_name": "Improve_Vision_Language_Model_Chain-of-thought_Reasoning__p3__score0.95.png",
        "Correlation_Impact": -0.003932,
        "details": {
            "Informativeness": 6.3e-05,
            "Fidelity": -0.000445,
            "Overall Readability": -0.001921,
            "Creativity": -0.00122,
            "Design Quality": -0.00041
        }
    },
    {
        "figure_name": "Visual_Evidence_Prompting_Mitigates_Hallucinations_in_Large_Vision-Language_Models__p3__score1.00.png",
        "Correlation_Impact": -0.003874,
        "details": {
            "Informativeness": 0.001093,
            "Fidelity": -0.00257,
            "Overall Readability": -0.002767,
            "Creativity": -0.000364,
            "Design Quality": 0.000734
        }
    },
    {
        "figure_name": "To_Mask_or_to_Mirror_Human-AI_Alignment_in_Collective_Reasoning__p5__score1.00.png",
        "Correlation_Impact": -0.003612,
        "details": {
            "Informativeness": -0.007483,
            "Fidelity": 0.001858,
            "Overall Readability": 0.000766,
            "Creativity": -5e-06,
            "Design Quality": 0.001252
        }
    },
    {
        "figure_name": "Active_Prompting_with_Chain-of-Thought_for_Large_Language_Models__p1__score1.00.png",
        "Correlation_Impact": -0.00331,
        "details": {
            "Informativeness": 0.001093,
            "Fidelity": 0.003173,
            "Overall Readability": 0.000766,
            "Creativity": 0.00383,
            "Design Quality": -0.012172
        }
    },
    {
        "figure_name": "RAG-Instruct_Boosting_LLMs_with_Diverse_Retrieval-Augmented_Instructions__p3__score0.95.png",
        "Correlation_Impact": -0.003103,
        "details": {
            "Informativeness": -0.012988,
            "Fidelity": 0.003173,
            "Overall Readability": 0.003473,
            "Creativity": 0.003919,
            "Design Quality": -0.000681
        }
    },
    {
        "figure_name": "How_Johnny_Can_Persuade_LLMs_to_Jailbreak_Them_Rethinking_Persuasion_to_Challenge_AI_Safety_by_Humanizing_LLMs__p1__score1.00.png",
        "Correlation_Impact": -0.003018,
        "details": {
            "Informativeness": 0.001093,
            "Fidelity": 0.000531,
            "Overall Readability": -0.000474,
            "Creativity": 0.000895,
            "Design Quality": -0.005063
        }
    },
    {
        "figure_name": "ImageInWords_Unlocking_Hyper-Detailed_Image_Descriptions__p4__score0.90.png",
        "Correlation_Impact": -0.003008,
        "details": {
            "Informativeness": 0.001523,
            "Fidelity": -0.00257,
            "Overall Readability": -0.001921,
            "Creativity": -0.00013,
            "Design Quality": 9e-05
        }
    },
    {
        "figure_name": "AKE_Assessing_Knowledge_Editing_in_Language_Models_via_Multi-Hop_Questions__p6__score1.00.png",
        "Correlation_Impact": -0.002658,
        "details": {
            "Informativeness": -0.00262,
            "Fidelity": 0.003173,
            "Overall Readability": 0.000766,
            "Creativity": -0.000743,
            "Design Quality": -0.003234
        }
    },
    {
        "figure_name": "Progressive_Multimodal_Reasoning_via_Active_Retrieval__p3__score1.00.png",
        "Correlation_Impact": -0.002556,
        "details": {
            "Informativeness": 0.005306,
            "Fidelity": -0.00503,
            "Overall Readability": 0.000766,
            "Creativity": -0.000364,
            "Design Quality": -0.003234
        }
    },
    {
        "figure_name": "Make_Every_Penny_Count_Difficulty-Adaptive_Self-Consistency_for_Cost-Efficient_Reasoning__p1__score1.00.png",
        "Correlation_Impact": -0.00245,
        "details": {
            "Informativeness": 0.001085,
            "Fidelity": 0.003173,
            "Overall Readability": -0.002767,
            "Creativity": 0.000895,
            "Design Quality": -0.004836
        }
    },
    {
        "figure_name": "Sociodemographic_Persona_Prompts_Evaluation__p0__score0.95.png",
        "Correlation_Impact": -0.002405,
        "details": {
            "Informativeness": 0.001342,
            "Fidelity": -0.00257,
            "Overall Readability": 0.003674,
            "Creativity": -0.005586,
            "Design Quality": 0.000734
        }
    },
    {
        "figure_name": "On_LLM-Based_Scientific_Inductive_Reasoning_Beyond_Equations__p4__score1.00.png",
        "Correlation_Impact": -0.00199,
        "details": {
            "Informativeness": 0.003018,
            "Fidelity": 0.001858,
            "Overall Readability": 8.9e-05,
            "Creativity": -0.011926,
            "Design Quality": 0.004971
        }
    },
    {
        "figure_name": "MARVEL_Unlocking_the_Multi-Modal_Capability_of_Dense_Retrieval_via_Visual_Module_Plugin__p3__score1.00.png",
        "Correlation_Impact": -0.001896,
        "details": {
            "Informativeness": 0.001093,
            "Fidelity": 0.000531,
            "Overall Readability": -0.000807,
            "Creativity": -0.002516,
            "Design Quality": -0.000198
        }
    },
    {
        "figure_name": "OVM_utcome-supervised_alue_odels_for_Planning_in_Mathematical_Reasoning__p2__score1.00.png",
        "Correlation_Impact": -0.001672,
        "details": {
            "Informativeness": -0.000485,
            "Fidelity": 0.003173,
            "Overall Readability": 0.000766,
            "Creativity": -0.004928,
            "Design Quality": -0.000198
        }
    },
    {
        "figure_name": "LINC_A_Neurosymbolic_Approach_for_Logical_Reasoning_by_Combining_Language_Models_with_First-Order_Logic_Provers__p1__score1.00.png",
        "Correlation_Impact": -0.001572,
        "details": {
            "Informativeness": 0.001342,
            "Fidelity": 0.000531,
            "Overall Readability": 0.003674,
            "Creativity": -0.006438,
            "Design Quality": -0.000681
        }
    },
    {
        "figure_name": "LINC_A_Neurosymbolic_Approach_for_Logical_Reasoning_by_Combining_Language_Models_with_First-Order_Logic_Provers__p1__score1.00__1.png",
        "Correlation_Impact": -0.001572,
        "details": {
            "Informativeness": 0.001342,
            "Fidelity": 0.000531,
            "Overall Readability": 0.003674,
            "Creativity": -0.006438,
            "Design Quality": -0.000681
        }
    },
    {
        "figure_name": "Interpretable_Preferences_via_Multi-Objective_Reward_Modeling_and_Mixture-of-Experts__p1__score1.00.png",
        "Correlation_Impact": -0.001386,
        "details": {
            "Informativeness": 0.001093,
            "Fidelity": -0.002865,
            "Overall Readability": 1.6e-05,
            "Creativity": -0.000364,
            "Design Quality": 0.000734
        }
    },
    {
        "figure_name": "Performance_Gap_in_Entity_Knowledge_Extraction_Across_Modalities_in_Vision_Language_Models__p1__score1.00.png",
        "Correlation_Impact": -0.001266,
        "details": {
            "Informativeness": -0.006699,
            "Fidelity": 0.003173,
            "Overall Readability": 0.013534,
            "Creativity": -0.006438,
            "Design Quality": -0.004836
        }
    },
    {
        "figure_name": "Performance_Gap_in_Entity_Knowledge_Extraction_Across_Modalities_in_Vision_Language_Models__p2__score1.00.png",
        "Correlation_Impact": -0.001176,
        "details": {
            "Informativeness": -0.000966,
            "Fidelity": 0.000531,
            "Overall Readability": -0.000807,
            "Creativity": -0.000743,
            "Design Quality": 0.000809
        }
    },
    {
        "figure_name": "How_Johnny_Can_Persuade_LLMs_to_Jailbreak_Them_Rethinking_Persuasion_to_Challenge_AI_Safety_by_Humanizing_LLMs__p2__score0.95.png",
        "Correlation_Impact": -0.001126,
        "details": {
            "Informativeness": -0.00382,
            "Fidelity": 0.003173,
            "Overall Readability": -0.005293,
            "Creativity": 0.009876,
            "Design Quality": -0.005063
        }
    },
    {
        "figure_name": "Measuring_Chain_of_Thought_Faithfulness_by_Unlearning_Reasoning_Steps__p3__score1.00.png",
        "Correlation_Impact": -0.00075,
        "details": {
            "Informativeness": -0.00239,
            "Fidelity": 0.003173,
            "Overall Readability": 0.001229,
            "Creativity": 0.00383,
            "Design Quality": -0.006591
        }
    },
    {
        "figure_name": "Mission_Impossible_Language_Models__p0__score0.95.png",
        "Correlation_Impact": -0.000611,
        "details": {
            "Informativeness": -0.00382,
            "Fidelity": 0.001858,
            "Overall Readability": 0.003674,
            "Creativity": -0.000743,
            "Design Quality": -0.00158
        }
    },
    {
        "figure_name": "Error-driven_Data-efficient_Large_Multimodal_Model_Tuning__p2__score1.00.png",
        "Correlation_Impact": -0.000554,
        "details": {
            "Informativeness": 0.001523,
            "Fidelity": 0.002647,
            "Overall Readability": 0.003473,
            "Creativity": -0.005586,
            "Design Quality": -0.002612
        }
    },
    {
        "figure_name": "ZoomEye_Enhancing_Multimodal_LLMs_with_Human-Like_Zooming_Capabilities_through_Tree-Based_Image_Exploration__p0__score1.00.png",
        "Correlation_Impact": -0.000514,
        "details": {
            "Informativeness": -0.005565,
            "Fidelity": -0.00257,
            "Overall Readability": -0.001921,
            "Creativity": 0.0079,
            "Design Quality": 0.001642
        }
    },
    {
        "figure_name": "Establishing_Trustworthy_LLM_Evaluation_via_Shortcut_Neuron_Analysis__p3__score1.00.png",
        "Correlation_Impact": -0.000375,
        "details": {
            "Informativeness": 0.001093,
            "Fidelity": -0.00352,
            "Overall Readability": 0.001607,
            "Creativity": -0.000364,
            "Design Quality": 0.000809
        }
    },
    {
        "figure_name": "Progressive_Multimodal_Reasoning_via_Active_Retrieval__p5__score1.00.png",
        "Correlation_Impact": -7.8e-05,
        "details": {
            "Informativeness": 0.001517,
            "Fidelity": -0.001566,
            "Overall Readability": -0.000474,
            "Creativity": -0.000364,
            "Design Quality": 0.000809
        }
    },
    {
        "figure_name": "Mind_the_Value-Action_Gap_Do_LLMs_Act_in_Alignment_with_Their_Values__p3__score1.00.png",
        "Correlation_Impact": 0.000249,
        "details": {
            "Informativeness": -0.00382,
            "Fidelity": 0.000531,
            "Overall Readability": 0.007136,
            "Creativity": -0.000364,
            "Design Quality": -0.003234
        }
    },
    {
        "figure_name": "LLMs_Trust_Humans_More_That_s_a_Problem_Unveiling_and_Mitigating_the_Authority_Bias_in_Retrieval-Augmented_Generation__p1__score1.00.png",
        "Correlation_Impact": 0.000299,
        "details": {
            "Informativeness": 0.000818,
            "Fidelity": 0.000531,
            "Overall Readability": 0.003473,
            "Creativity": -0.000743,
            "Design Quality": -0.00378
        }
    },
    {
        "figure_name": "DiffusionBERT_Improving_Generative_Masked_Language_Models_with_Diffusion_Models__p0__score1.00.png",
        "Correlation_Impact": 0.000943,
        "details": {
            "Informativeness": 0.007556,
            "Fidelity": 0.001858,
            "Overall Readability": -0.002767,
            "Creativity": -0.006438,
            "Design Quality": 0.000734
        }
    },
    {
        "figure_name": "AKE_Assessing_Knowledge_Editing_in_Language_Models_via_Multi-Hop_Questions__p0__score0.70.png",
        "Correlation_Impact": 0.00125,
        "details": {
            "Informativeness": -0.00239,
            "Fidelity": -0.00352,
            "Overall Readability": 1.6e-05,
            "Creativity": -0.002516,
            "Design Quality": 0.009661
        }
    },
    {
        "figure_name": "Improve_Vision_Language_Model_Chain-of-thought_Reasoning__p1__score0.98.png",
        "Correlation_Impact": 0.001703,
        "details": {
            "Informativeness": 0.001093,
            "Fidelity": -0.000445,
            "Overall Readability": -0.001921,
            "Creativity": -0.000743,
            "Design Quality": 0.003719
        }
    },
    {
        "figure_name": "CoPL_Collaborative_Preference_Learning_for_Personalizing_LLMs__p3__score1.00.png",
        "Correlation_Impact": 0.001705,
        "details": {
            "Informativeness": 0.006417,
            "Fidelity": -0.001502,
            "Overall Readability": 0.000766,
            "Creativity": -0.000743,
            "Design Quality": -0.003234
        }
    },
    {
        "figure_name": "WebEvolver_Enhancing_Web_Agent_Self-Improvement_with_Co-evolving_World_Model__p2__score1.00.png",
        "Correlation_Impact": 0.001737,
        "details": {
            "Informativeness": -0.00239,
            "Fidelity": 0.003173,
            "Overall Readability": 0.001607,
            "Creativity": -0.000743,
            "Design Quality": 9e-05
        }
    },
    {
        "figure_name": "SafeDecoding_Defending_against_Jailbreak_Attacks_via_Safety-Aware_Decoding__p0__score0.95.png",
        "Correlation_Impact": 0.002104,
        "details": {
            "Informativeness": -0.001574,
            "Fidelity": 0.001858,
            "Overall Readability": 8.9e-05,
            "Creativity": 0.007603,
            "Design Quality": -0.005873
        }
    },
    {
        "figure_name": "Do_Large_Language_Models_Latently_Perform_Multi-Hop_Reasoning__p0__score0.90.png",
        "Correlation_Impact": 0.002301,
        "details": {
            "Informativeness": -0.000485,
            "Fidelity": 0.003173,
            "Overall Readability": 0.000766,
            "Creativity": -0.000743,
            "Design Quality": -0.00041
        }
    },
    {
        "figure_name": "Blinded_by_Generated_Contexts_How_Language_Models_Merge_Generated_and_Retrieved_Contexts_When_Knowledge_Conflicts__p3__score1.00.png",
        "Correlation_Impact": 0.002316,
        "details": {
            "Informativeness": 0.006417,
            "Fidelity": -0.006313,
            "Overall Readability": 0.001607,
            "Creativity": -0.00013,
            "Design Quality": 0.000734
        }
    },
    {
        "figure_name": "DiffusionBERT_Improving_Generative_Masked_Language_Models_with_Diffusion_Models__p0__score1.00__1.png",
        "Correlation_Impact": 0.002656,
        "details": {
            "Informativeness": 0.007556,
            "Fidelity": 0.001858,
            "Overall Readability": -0.002767,
            "Creativity": -0.006438,
            "Design Quality": 0.002447
        }
    },
    {
        "figure_name": "DiffusionBERT_Improving_Generative_Masked_Language_Models_with_Diffusion_Models__p0__score1.00__2.png",
        "Correlation_Impact": 0.002656,
        "details": {
            "Informativeness": 0.007556,
            "Fidelity": 0.001858,
            "Overall Readability": -0.002767,
            "Creativity": -0.006438,
            "Design Quality": 0.002447
        }
    },
    {
        "figure_name": "Self-Knowledge_Guided_Retrieval_Augmentation_for_Large_Language_Models__p2__score1.00.png",
        "Correlation_Impact": 0.002825,
        "details": {
            "Informativeness": -0.00239,
            "Fidelity": 0.001858,
            "Overall Readability": 1.6e-05,
            "Creativity": 0.000895,
            "Design Quality": 0.002447
        }
    },
    {
        "figure_name": "Measuring_Chain_of_Thought_Faithfulness_by_Unlearning_Reasoning_Steps__p7__score0.80.png",
        "Correlation_Impact": 0.002878,
        "details": {
            "Informativeness": 0.001517,
            "Fidelity": -0.010716,
            "Overall Readability": -0.000807,
            "Creativity": -0.000364,
            "Design Quality": 0.013247
        }
    },
    {
        "figure_name": "Mitigating_Hallucinations_in_Vision-Language_Models_through_Image-Guided_Head_Suppression__p0__score0.95.png",
        "Correlation_Impact": 0.003175,
        "details": {
            "Informativeness": 0.001517,
            "Fidelity": -0.001502,
            "Overall Readability": 0.007136,
            "Creativity": -0.000743,
            "Design Quality": -0.003234
        }
    },
    {
        "figure_name": "Finetuning_LLMs_for_Human_Behavior_Prediction_in_Social_Science_Experiments__p3__score1.00.png",
        "Correlation_Impact": 0.003781,
        "details": {
            "Informativeness": 0.001093,
            "Fidelity": 0.001624,
            "Overall Readability": -0.000474,
            "Creativity": -0.000364,
            "Design Quality": 0.001902
        }
    },
    {
        "figure_name": "Progressive_Multimodal_Reasoning_via_Active_Retrieval__p2__score0.95.png",
        "Correlation_Impact": 0.00379,
        "details": {
            "Informativeness": -0.006699,
            "Fidelity": 0.003661,
            "Overall Readability": 0.003473,
            "Creativity": -0.000364,
            "Design Quality": 0.003719
        }
    },
    {
        "figure_name": "CoPL_Collaborative_Preference_Learning_for_Personalizing_LLMs__p4__score0.95.png",
        "Correlation_Impact": 0.003958,
        "details": {
            "Informativeness": 0.006417,
            "Fidelity": -0.00352,
            "Overall Readability": 0.003674,
            "Creativity": 0.003919,
            "Design Quality": -0.006533
        }
    },
    {
        "figure_name": "ZoomEye_Enhancing_Multimodal_LLMs_with_Human-Like_Zooming_Capabilities_through_Tree-Based_Image_Exploration__p1__score0.95.png",
        "Correlation_Impact": 0.004085,
        "details": {
            "Informativeness": 0.000818,
            "Fidelity": -0.000445,
            "Overall Readability": 0.003473,
            "Creativity": -0.00348,
            "Design Quality": 0.003719
        }
    },
    {
        "figure_name": "Humans_or_LLMs_as_the_Judge_A_Study_on_Judgement_Bias__p4__score1.00__1.png",
        "Correlation_Impact": 0.004228,
        "details": {
            "Informativeness": -0.014307,
            "Fidelity": -0.002865,
            "Overall Readability": 0.008283,
            "Creativity": -0.00013,
            "Design Quality": 0.013247
        }
    },
    {
        "figure_name": "A_Theory_of_Response_Sampling_in_LLMs_Part_Descriptive_and_Part_Prescriptive__p1__score1.00.png",
        "Correlation_Impact": 0.004447,
        "details": {
            "Informativeness": -0.005565,
            "Fidelity": -0.000803,
            "Overall Readability": 0.000766,
            "Creativity": 0.007603,
            "Design Quality": 0.002447
        }
    },
    {
        "figure_name": "MP2D_AnAutomated_Topic_Shift_Dialogue_Generation_Framework__p0__score0.90.png",
        "Correlation_Impact": 0.004864,
        "details": {
            "Informativeness": 0.005306,
            "Fidelity": -0.00257,
            "Overall Readability": 0.001229,
            "Creativity": -0.000743,
            "Design Quality": 0.001642
        }
    },
    {
        "figure_name": "Conditional_MASK_Discrete_Diffusion_Language_Model__p3__score1.00.png",
        "Correlation_Impact": 0.005302,
        "details": {
            "Informativeness": 0.001093,
            "Fidelity": 0.001858,
            "Overall Readability": 0.003473,
            "Creativity": -0.001932,
            "Design Quality": 0.000809
        }
    },
    {
        "figure_name": "MemInsight_Autonomous_Memory_Augmentation_for_LLM_Agents__p7__score1.00.png",
        "Correlation_Impact": 0.006146,
        "details": {
            "Informativeness": -0.010781,
            "Fidelity": -0.007751,
            "Overall Readability": 0.007878,
            "Creativity": 0.00631,
            "Design Quality": 0.010491
        }
    },
    {
        "figure_name": "R-VLM_Region-Aware_Vision_Language_Model_for_Precise_GUI_Grounding__p4__score1.00.png",
        "Correlation_Impact": 0.0062,
        "details": {
            "Informativeness": 0.003018,
            "Fidelity": 0.006689,
            "Overall Readability": -0.001921,
            "Creativity": -5e-06,
            "Design Quality": -0.00158
        }
    },
    {
        "figure_name": "Mission_Impossible_Language_Models__p7__score0.95.png",
        "Correlation_Impact": 0.006893,
        "details": {
            "Informativeness": 0.001085,
            "Fidelity": 0.009735,
            "Overall Readability": -0.007979,
            "Creativity": -0.006438,
            "Design Quality": 0.010491
        }
    },
    {
        "figure_name": "Ko-LongRAG_A_Korean_Long-Context_RAG_Benchmark_Built_with_a_Retrieval-Free_Approach__p1__score1.00.png",
        "Correlation_Impact": 0.006894,
        "details": {
            "Informativeness": 0.001093,
            "Fidelity": -0.000445,
            "Overall Readability": 0.001607,
            "Creativity": 0.00383,
            "Design Quality": 0.000809
        }
    },
    {
        "figure_name": "Weakly_Supervised_Semantic_Parsing_with_Execution-based_Spurious_Program_Filtering__p3__score0.70.png",
        "Correlation_Impact": 0.006967,
        "details": {
            "Informativeness": 0.005306,
            "Fidelity": 0.003173,
            "Overall Readability": -0.006984,
            "Creativity": 0.00383,
            "Design Quality": 0.001642
        }
    },
    {
        "figure_name": "FaST_Feature-aware_Sampling_and_Tuning_for_Personalized_Preference_Alignment_with_Limited_Data__p2__score1.00.png",
        "Correlation_Impact": 0.007117,
        "details": {
            "Informativeness": 0.006417,
            "Fidelity": 0.003173,
            "Overall Readability": 0.000766,
            "Creativity": -5e-06,
            "Design Quality": -0.003234
        }
    },
    {
        "figure_name": "Ko-LongRAG_A_Korean_Long-Context_RAG_Benchmark_Built_with_a_Retrieval-Free_Approach__p6__score0.90.png",
        "Correlation_Impact": 0.007183,
        "details": {
            "Informativeness": 0.010906,
            "Fidelity": -0.014794,
            "Overall Readability": -0.001921,
            "Creativity": 0.012902,
            "Design Quality": 9e-05
        }
    },
    {
        "figure_name": "Mitigating_Hallucinations_in_Large_Vision-Language_Models_with_Instruction_Contrastive_Decoding__p3__score1.00.png",
        "Correlation_Impact": 0.007286,
        "details": {
            "Informativeness": 0.003018,
            "Fidelity": 0.000531,
            "Overall Readability": 1.6e-05,
            "Creativity": 0.003919,
            "Design Quality": -0.000198
        }
    },
    {
        "figure_name": "Improve_Vision_Language_Model_Chain-of-thought_Reasoning__p2__score0.70.png",
        "Correlation_Impact": 0.007463,
        "details": {
            "Informativeness": 0.005306,
            "Fidelity": -0.00503,
            "Overall Readability": 0.003473,
            "Creativity": -5e-06,
            "Design Quality": 0.003719
        }
    },
    {
        "figure_name": "Generating_Diverse_Hypotheses_for_Inductive_Reasoning__p4__score0.95.png",
        "Correlation_Impact": 0.00749,
        "details": {
            "Informativeness": 0.005306,
            "Fidelity": 0.003173,
            "Overall Readability": -0.001687,
            "Creativity": 0.000895,
            "Design Quality": -0.000198
        }
    },
    {
        "figure_name": "Memory_OS_of_AI_Agent__p2__score1.00.png",
        "Correlation_Impact": 0.007633,
        "details": {
            "Informativeness": 0.006417,
            "Fidelity": 0.000531,
            "Overall Readability": -0.000474,
            "Creativity": -0.000743,
            "Design Quality": 0.001902
        }
    },
    {
        "figure_name": "PopAlign_Diversifying_Contrasting_Patterns_for_a_More_Comprehensive_Alignment__p0__score0.90.png",
        "Correlation_Impact": 0.007895,
        "details": {
            "Informativeness": 0.001523,
            "Fidelity": 0.005682,
            "Overall Readability": -0.00387,
            "Creativity": 0.00614,
            "Design Quality": -0.00158
        }
    },
    {
        "figure_name": "Competition_of_Mechanisms_Tracing_How_Language_Models_Handle_Facts_and_Counterfactuals__p0__score1.00.png",
        "Correlation_Impact": 0.007898,
        "details": {
            "Informativeness": -0.001574,
            "Fidelity": 0.000531,
            "Overall Readability": -0.000807,
            "Creativity": -0.000743,
            "Design Quality": 0.010491
        }
    },
    {
        "figure_name": "RAG-Instruct_Boosting_LLMs_with_Diverse_Retrieval-Augmented_Instructions__p4__score0.95.png",
        "Correlation_Impact": 0.00815,
        "details": {
            "Informativeness": 0.001523,
            "Fidelity": 0.001858,
            "Overall Readability": 0.007878,
            "Creativity": -0.005981,
            "Design Quality": 0.002872
        }
    },
    {
        "figure_name": "In_Prospect_and_Retrospect_Re_ective_Memory_Management_for_Long-term_Personalized_Dialogue_Agents__p3__score0.95.png",
        "Correlation_Impact": 0.008274,
        "details": {
            "Informativeness": 0.005306,
            "Fidelity": 0.003661,
            "Overall Readability": -0.002767,
            "Creativity": 0.00383,
            "Design Quality": -0.001756
        }
    },
    {
        "figure_name": "Bridging_the_Visual_Gap_Fine-Tuning_Multimodal_Models_with_Knowledge-Adapted_Captions__p1__score1.00.png",
        "Correlation_Impact": 0.008639,
        "details": {
            "Informativeness": 0.003018,
            "Fidelity": 0.001858,
            "Overall Readability": 8.9e-05,
            "Creativity": 0.001227,
            "Design Quality": 0.002447
        }
    },
    {
        "figure_name": "Measuring_Chain_of_Thought_Faithfulness_by_Unlearning_Reasoning_Steps__p0__score0.95.png",
        "Correlation_Impact": 0.008896,
        "details": {
            "Informativeness": -0.001574,
            "Fidelity": 0.001624,
            "Overall Readability": 0.003674,
            "Creativity": 0.003919,
            "Design Quality": 0.001252
        }
    },
    {
        "figure_name": "Lost_in_the_Middle_How_Language_Models_Use_Long_Contexts__p3__score0.60.png",
        "Correlation_Impact": 0.009115,
        "details": {
            "Informativeness": 0.007556,
            "Fidelity": -0.00257,
            "Overall Readability": -0.000474,
            "Creativity": 0.00631,
            "Design Quality": -0.001707
        }
    },
    {
        "figure_name": "MemInsight_Autonomous_Memory_Augmentation_for_LLM_Agents__p2__score1.00.png",
        "Correlation_Impact": 0.009168,
        "details": {
            "Informativeness": 0.006417,
            "Fidelity": 0.001858,
            "Overall Readability": 8.9e-05,
            "Creativity": -5e-06,
            "Design Quality": 0.000809
        }
    },
    {
        "figure_name": "On_LLM-Based_Scientific_Inductive_Reasoning_Beyond_Equations__p0__score1.00.png",
        "Correlation_Impact": 0.009402,
        "details": {
            "Informativeness": 0.001644,
            "Fidelity": 0.001858,
            "Overall Readability": -0.005293,
            "Creativity": 0.00383,
            "Design Quality": 0.007363
        }
    },
    {
        "figure_name": "Mitigating_Biases_for_Instruction-following_Language_Models_via_Bias_Neurons_Elimination__p0__score0.95.png",
        "Correlation_Impact": 0.00946,
        "details": {
            "Informativeness": -0.00382,
            "Fidelity": -0.000445,
            "Overall Readability": 0.003674,
            "Creativity": 0.007603,
            "Design Quality": 0.002447
        }
    },
    {
        "figure_name": "Bridging_the_Visual_Gap_Fine-Tuning_Multimodal_Models_with_Knowledge-Adapted_Captions__p3__score1.00.png",
        "Correlation_Impact": 0.009473,
        "details": {
            "Informativeness": 0.001093,
            "Fidelity": 0.002647,
            "Overall Readability": 0.000766,
            "Creativity": -5e-06,
            "Design Quality": 0.004971
        }
    },
    {
        "figure_name": "AdaRewriter_Unleashing_the_Power_of_Prompting-based_Conversational_Query_Reformulation_via_Test-Time_Adaptation__p2__score1.00.png",
        "Correlation_Impact": 0.010204,
        "details": {
            "Informativeness": 0.001093,
            "Fidelity": 0.003173,
            "Overall Readability": 0.000766,
            "Creativity": 0.003919,
            "Design Quality": 0.001252
        }
    },
    {
        "figure_name": "In_Prospect_and_Retrospect_Re_ective_Memory_Management_for_Long-term_Personalized_Dialogue_Agents__p0__score0.95.png",
        "Correlation_Impact": 0.010369,
        "details": {
            "Informativeness": 0.010906,
            "Fidelity": -0.00257,
            "Overall Readability": 0.001229,
            "Creativity": -5e-06,
            "Design Quality": 0.000809
        }
    },
    {
        "figure_name": "DRAGIN_Dynamic_Retrieval_Augmented_Generation_based_on_the_Information_Needs_of_Large_Language_Models__p2__score1.00.png",
        "Correlation_Impact": 0.010439,
        "details": {
            "Informativeness": -0.00239,
            "Fidelity": 0.003173,
            "Overall Readability": 0.000766,
            "Creativity": 0.003919,
            "Design Quality": 0.004971
        }
    },
    {
        "figure_name": "Towards_Statistical_Factuality_Guarantee_for_Large_Vision-Language_Models__p1__score1.00.png",
        "Correlation_Impact": 0.010779,
        "details": {
            "Informativeness": 0.001342,
            "Fidelity": 0.000531,
            "Overall Readability": 1.6e-05,
            "Creativity": 0.003919,
            "Design Quality": 0.004971
        }
    },
    {
        "figure_name": "How_Do_Moral_Emotions_Shape_Political_Participation_A_Cross-Cultural_Analysis_of_Online_Petitions_Using_Language_Models__p3__score1.00.png",
        "Correlation_Impact": 0.011173,
        "details": {
            "Informativeness": 0.009248,
            "Fidelity": 0.003173,
            "Overall Readability": -0.000474,
            "Creativity": -0.000364,
            "Design Quality": -0.00041
        }
    },
    {
        "figure_name": "Steering_Llama_2_via_Contrastive_Activation_Addition__p0__score1.00.png",
        "Correlation_Impact": 0.011426,
        "details": {
            "Informativeness": -0.000966,
            "Fidelity": 0.003173,
            "Overall Readability": 0.007136,
            "Creativity": -0.000364,
            "Design Quality": 0.002447
        }
    },
    {
        "figure_name": "Visual_Evidence_Prompting_Mitigates_Hallucinations_in_Large_Vision-Language_Models__p0__score0.90.png",
        "Correlation_Impact": 0.012008,
        "details": {
            "Informativeness": -0.00239,
            "Fidelity": 0.019119,
            "Overall Readability": -0.001921,
            "Creativity": -0.00122,
            "Design Quality": -0.00158
        }
    },
    {
        "figure_name": "Generating_Diverse_Hypotheses_for_Inductive_Reasoning__p1__score1.00.png",
        "Correlation_Impact": 0.012058,
        "details": {
            "Informativeness": -0.00239,
            "Fidelity": 0.001858,
            "Overall Readability": 1.6e-05,
            "Creativity": 0.007603,
            "Design Quality": 0.004971
        }
    },
    {
        "figure_name": "Language_Models_as_Inductive_Reasoners__p1__score0.70.png",
        "Correlation_Impact": 0.012257,
        "details": {
            "Informativeness": 0.005306,
            "Fidelity": -0.00257,
            "Overall Readability": 0.003404,
            "Creativity": 0.010953,
            "Design Quality": -0.004836
        }
    },
    {
        "figure_name": "Humans_or_LLMs_as_the_Judge_A_Study_on_Judgement_Bias__p4__score1.00.png",
        "Correlation_Impact": 0.01235,
        "details": {
            "Informativeness": -0.007483,
            "Fidelity": -0.001566,
            "Overall Readability": 0.008283,
            "Creativity": -0.00013,
            "Design Quality": 0.013247
        }
    },
    {
        "figure_name": "Con_dence_Improves_Self-Consistency_in_LLMs__p1__score0.90.png",
        "Correlation_Impact": 0.012994,
        "details": {
            "Informativeness": -0.000966,
            "Fidelity": 0.001858,
            "Overall Readability": 0.007136,
            "Creativity": -5e-06,
            "Design Quality": 0.004971
        }
    },
    {
        "figure_name": "Rewarding_the_Unlikely_Lifting_GRPO_Beyond_Distribution_Sharpening__p0__score0.90.png",
        "Correlation_Impact": 0.014009,
        "details": {
            "Informativeness": -0.001574,
            "Fidelity": 0.001858,
            "Overall Readability": 0.003674,
            "Creativity": 0.007603,
            "Design Quality": 0.002447
        }
    },
    {
        "figure_name": "Are_LLM-Judges_Robust_to_Expressions_of_Uncertainty_Investigating_the_effect_of_Epistemic_Markers_on_LLM-based_Evaluation__p4__score1.00.png",
        "Correlation_Impact": 0.014936,
        "details": {
            "Informativeness": 6.3e-05,
            "Fidelity": 0.003173,
            "Overall Readability": 0.007136,
            "Creativity": 0.00383,
            "Design Quality": 0.000734
        }
    },
    {
        "figure_name": "Reverse_Thinking_Makes_LLMs_Stronger_Reasoners__p0__score0.98.png",
        "Correlation_Impact": 0.015262,
        "details": {
            "Informativeness": 0.006417,
            "Fidelity": 0.001858,
            "Overall Readability": -0.007979,
            "Creativity": 0.007603,
            "Design Quality": 0.007363
        }
    },
    {
        "figure_name": "Shifting_Attention_to_Relevance_Towards_the_Predictive_Uncertainty_Quantification_of_Free-Form_Large_Language_Models__p0__score0.90.png",
        "Correlation_Impact": 0.015272,
        "details": {
            "Informativeness": 0.001093,
            "Fidelity": -0.000803,
            "Overall Readability": 1.6e-05,
            "Creativity": 0.007603,
            "Design Quality": 0.007363
        }
    },
    {
        "figure_name": "Bridging_the_Visual_Gap_Fine-Tuning_Multimodal_Models_with_Knowledge-Adapted_Captions__p0__score1.00.png",
        "Correlation_Impact": 0.015359,
        "details": {
            "Informativeness": 0.000818,
            "Fidelity": 0.003173,
            "Overall Readability": 0.003674,
            "Creativity": 0.007603,
            "Design Quality": 9e-05
        }
    },
    {
        "figure_name": "Vision-Language_Models_Can_Self-Improve_Reasoning_via_Reflection__p3__score1.00.png",
        "Correlation_Impact": 0.015765,
        "details": {
            "Informativeness": 0.001342,
            "Fidelity": 0.001858,
            "Overall Readability": 0.003674,
            "Creativity": 0.003919,
            "Design Quality": 0.004971
        }
    },
    {
        "figure_name": "AGrail_A_Lifelong_Agent_Guardrail_with_Effective_and_Adaptive_Safety_Detection__p0__score0.95.png",
        "Correlation_Impact": 0.016259,
        "details": {
            "Informativeness": -0.00239,
            "Fidelity": -0.002151,
            "Overall Readability": 0.035773,
            "Creativity": -0.013265,
            "Design Quality": -0.001707
        }
    },
    {
        "figure_name": "PopAlign_Diversifying_Contrasting_Patterns_for_a_More_Comprehensive_Alignment__p2__score1.00.png",
        "Correlation_Impact": 0.016283,
        "details": {
            "Informativeness": 0.006417,
            "Fidelity": -0.001502,
            "Overall Readability": 0.003674,
            "Creativity": 0.007603,
            "Design Quality": 9e-05
        }
    },
    {
        "figure_name": "VLind-Bench_Measuring_Language_Priors_in_Large_Vision-Language_Models__p1__score1.00.png",
        "Correlation_Impact": 0.017769,
        "details": {
            "Informativeness": 0.001093,
            "Fidelity": 0.003173,
            "Overall Readability": 0.007136,
            "Creativity": 0.003919,
            "Design Quality": 0.002447
        }
    },
    {
        "figure_name": "Make_Every_Penny_Count_Difficulty-Adaptive_Self-Consistency_for_Cost-Efficient_Reasoning__p2__score1.00.png",
        "Correlation_Impact": 0.018847,
        "details": {
            "Informativeness": 0.006417,
            "Fidelity": 0.003661,
            "Overall Readability": 0.008283,
            "Creativity": 0.000895,
            "Design Quality": -0.00041
        }
    },
    {
        "figure_name": "ZoomEye_Enhancing_Multimodal_LLMs_with_Human-Like_Zooming_Capabilities_through_Tree-Based_Image_Exploration__p7__score0.95.png",
        "Correlation_Impact": 0.020448,
        "details": {
            "Informativeness": -0.00382,
            "Fidelity": -0.000445,
            "Overall Readability": 0.021971,
            "Creativity": -0.00013,
            "Design Quality": 0.002872
        }
    },
    {
        "figure_name": "Long-text_Uncertainty_Quantification_for_LLMs__p1__score1.00.png",
        "Correlation_Impact": 0.022283,
        "details": {
            "Informativeness": 0.003018,
            "Fidelity": -0.000445,
            "Overall Readability": 0.007136,
            "Creativity": 0.007603,
            "Design Quality": 0.004971
        }
    },
    {
        "figure_name": "SafeDecoding_Defending_against_Jailbreak_Attacks_via_Safety-Aware_Decoding__p4__score1.00.png",
        "Correlation_Impact": 0.023058,
        "details": {
            "Informativeness": 0.003018,
            "Fidelity": 0.001858,
            "Overall Readability": 1.6e-05,
            "Creativity": 0.013196,
            "Design Quality": 0.004971
        }
    },
    {
        "figure_name": "How_Johnny_Can_Persuade_LLMs_to_Jailbreak_Them_Rethinking_Persuasion_to_Challenge_AI_Safety_by_Humanizing_LLMs__p3__score0.70.png",
        "Correlation_Impact": 0.023068,
        "details": {
            "Informativeness": -0.007483,
            "Fidelity": 0.012728,
            "Overall Readability": 0.01256,
            "Creativity": 0.00383,
            "Design Quality": 0.001433
        }
    },
    {
        "figure_name": "MemInsight_Autonomous_Memory_Augmentation_for_LLM_Agents__p3__score0.95.png",
        "Correlation_Impact": 0.023868,
        "details": {
            "Informativeness": -0.010781,
            "Fidelity": -0.010716,
            "Overall Readability": 0.021971,
            "Creativity": 0.012902,
            "Design Quality": 0.010491
        }
    },
    {
        "figure_name": "Reverse_Thinking_Makes_LLMs_Stronger_Reasoners__p3__score1.00.png",
        "Correlation_Impact": 0.025386,
        "details": {
            "Informativeness": 0.009248,
            "Fidelity": 0.003173,
            "Overall Readability": 0.007136,
            "Creativity": 0.003919,
            "Design Quality": 0.00191
        }
    },
    {
        "figure_name": "Step-level_Value_Preference_Optimization_for_Mathematical_Reasoning__p2__score1.00.png",
        "Correlation_Impact": 0.026149,
        "details": {
            "Informativeness": 6.3e-05,
            "Fidelity": 0.003173,
            "Overall Readability": 8.9e-05,
            "Creativity": 0.018384,
            "Design Quality": 0.004439
        }
    },
    {
        "figure_name": "Generating_Diverse_Hypotheses_for_Inductive_Reasoning__p3__score1.00.png",
        "Correlation_Impact": 0.028475,
        "details": {
            "Informativeness": 0.009248,
            "Fidelity": 0.003173,
            "Overall Readability": 0.007136,
            "Creativity": -0.000743,
            "Design Quality": 0.009661
        }
    },
    {
        "figure_name": "Self-Knowledge_Guided_Retrieval_Augmentation_for_Large_Language_Models__p0__score0.95.png",
        "Correlation_Impact": 0.031618,
        "details": {
            "Informativeness": 0.010906,
            "Fidelity": 0.022624,
            "Overall Readability": -0.002767,
            "Creativity": 0.000765,
            "Design Quality": 9e-05
        }
    },
    {
        "figure_name": "Model_Editing_by_Standard_Fine-Tuning__p6__score0.90.png",
        "Correlation_Impact": 0.046329,
        "details": {
            "Informativeness": -0.00382,
            "Fidelity": 0.001858,
            "Overall Readability": 0.008283,
            "Creativity": 0.023395,
            "Design Quality": 0.016613
        }
    },
    {
        "figure_name": "Distilling_Step-by-Step_Outperforming_Larger_Language_Models_with_Less_Training_Data_and_Smaller_Model_Sizes__p0__score0.60.png",
        "Correlation_Impact": 0.05146,
        "details": {
            "Informativeness": 0.013689,
            "Fidelity": 0.03289,
            "Overall Readability": -0.003593,
            "Creativity": 0.007041,
            "Design Quality": 0.001433
        }
    }
]