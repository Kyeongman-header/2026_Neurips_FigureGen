[
    {
        "figure_name": "DocFinQA_A_Long-Context_Financial_Reasoning_Dataset__p0__score0.80.png",
        "Total_Abs_Diff": 12.334
    },
    {
        "figure_name": "Distilling_Step-by-Step_Outperforming_Larger_Language_Models_with_Less_Training_Data_and_Smaller_Model_Sizes__p2__score0.95.png",
        "Total_Abs_Diff": 10.286
    },
    {
        "figure_name": "Mission_Impossible_Language_Models__p7__score0.95.png",
        "Total_Abs_Diff": 9.905
    },
    {
        "figure_name": "How_Johnny_Can_Persuade_LLMs_to_Jailbreak_Them_Rethinking_Persuasion_to_Challenge_AI_Safety_by_Humanizing_LLMs__p3__score0.70.png",
        "Total_Abs_Diff": 9.334
    },
    {
        "figure_name": "MemInsight_Autonomous_Memory_Augmentation_for_LLM_Agents__p3__score0.95.png",
        "Total_Abs_Diff": 9.237
    },
    {
        "figure_name": "Exploring_Precision_and_Recall_to_assess_the_quality_and_diversity_of_LLMs__p4__score1.00.png",
        "Total_Abs_Diff": 8.857
    },
    {
        "figure_name": "Humans_or_LLMs_as_the_Judge_A_Study_on_Judgement_Bias__p3__score1.00.png",
        "Total_Abs_Diff": 8.62
    },
    {
        "figure_name": "Don_t_Forget_Your_ABC_s_Evaluating_the_State-of-the-Art_in_Chat-Oriented_Dialogue_Systems__p4__score0.70.png",
        "Total_Abs_Diff": 8.619
    },
    {
        "figure_name": "MemInsight_Autonomous_Memory_Augmentation_for_LLM_Agents__p7__score1.00.png",
        "Total_Abs_Diff": 8.571
    },
    {
        "figure_name": "Weakly_Supervised_Semantic_Parsing_with_Execution-based_Spurious_Program_Filtering__p2__score0.70.png",
        "Total_Abs_Diff": 8.523
    },
    {
        "figure_name": "Distilling_Step-by-Step_Outperforming_Larger_Language_Models_with_Less_Training_Data_and_Smaller_Model_Sizes__p0__score0.60.png",
        "Total_Abs_Diff": 8.334
    },
    {
        "figure_name": "VISTA_Visualized_Text_Embedding_For_Universal_Multi-Modal_Retrieval__p2__score1.00.png",
        "Total_Abs_Diff": 7.81
    },
    {
        "figure_name": "Know_When_To_Stop_A_Study_of_Semantic_Drift_in_Text_Generation__p1__score0.70.png",
        "Total_Abs_Diff": 7.619
    },
    {
        "figure_name": "Locating_and_Extracting_Relational_Concepts_in_Large_Language_Models__p6__score0.97.png",
        "Total_Abs_Diff": 7.524
    },
    {
        "figure_name": "How_Johnny_Can_Persuade_LLMs_to_Jailbreak_Them_Rethinking_Persuasion_to_Challenge_AI_Safety_by_Humanizing_LLMs__p4__score0.80.png",
        "Total_Abs_Diff": 7.476
    },
    {
        "figure_name": "VISTA_Visualized_Text_Embedding_For_Universal_Multi-Modal_Retrieval__p3__score1.00.png",
        "Total_Abs_Diff": 7.428000000000001
    },
    {
        "figure_name": "Mind_the_Value-Action_Gap_Do_LLMs_Act_in_Alignment_with_Their_Values__p1__score1.00.png",
        "Total_Abs_Diff": 7.143999999999999
    },
    {
        "figure_name": "AGrail_A_Lifelong_Agent_Guardrail_with_Effective_and_Adaptive_Safety_Detection__p0__score0.95.png",
        "Total_Abs_Diff": 7.143
    },
    {
        "figure_name": "Finetuning_LLMs_for_Human_Behavior_Prediction_in_Social_Science_Experiments__p0__score1.00.png",
        "Total_Abs_Diff": 7.096
    },
    {
        "figure_name": "Humans_or_LLMs_as_the_Judge_A_Study_on_Judgement_Bias__p4__score1.00__1.png",
        "Total_Abs_Diff": 7.095000000000001
    },
    {
        "figure_name": "Less_is_More_Mitigating_Multimodal_Hallucination_from_an_EOS_Decision_Perspective__p0__score0.60.png",
        "Total_Abs_Diff": 7.0
    },
    {
        "figure_name": "A_Theory_of_Response_Sampling_in_LLMs_Part_Descriptive_and_Part_Prescriptive__p4__score0.80.png",
        "Total_Abs_Diff": 7.0
    },
    {
        "figure_name": "MARVEL_Unlocking_the_Multi-Modal_Capability_of_Dense_Retrieval_via_Visual_Module_Plugin__p0__score1.00.png",
        "Total_Abs_Diff": 6.952999999999999
    },
    {
        "figure_name": "Measuring_Chain_of_Thought_Faithfulness_by_Unlearning_Reasoning_Steps__p7__score0.80.png",
        "Total_Abs_Diff": 6.7620000000000005
    },
    {
        "figure_name": "Making_Long-Context_Language_Models_Better_Multi-Hop_Reasoners__p3__score1.00.png",
        "Total_Abs_Diff": 6.7620000000000005
    },
    {
        "figure_name": "Weakly_Supervised_Semantic_Parsing_with_Execution-based_Spurious_Program_Filtering__p0__score0.80.png",
        "Total_Abs_Diff": 6.7620000000000005
    },
    {
        "figure_name": "Language_Models_as_Inductive_Reasoners__p4__score1.00.png",
        "Total_Abs_Diff": 6.619999999999999
    },
    {
        "figure_name": "Fooling_the_LVLM_Judges_Visual_Biases_in_LVLM-Based_Evaluation_3.5_4.1__p0__score0.95.png",
        "Total_Abs_Diff": 6.571
    },
    {
        "figure_name": "Models_Fine-grained_Gender_Control_in_Machine_Translation_with_Large_Language__p1__score0.70.png",
        "Total_Abs_Diff": 6.571
    },
    {
        "figure_name": "Model_Editing_by_Standard_Fine-Tuning__p6__score0.90.png",
        "Total_Abs_Diff": 6.571
    },
    {
        "figure_name": "On_LLM-Based_Scientific_Inductive_Reasoning_Beyond_Equations__p6__score1.00.png",
        "Total_Abs_Diff": 6.571
    },
    {
        "figure_name": "MP2D_AnAutomated_Topic_Shift_Dialogue_Generation_Framework__p2__score1.00.png",
        "Total_Abs_Diff": 6.571
    },
    {
        "figure_name": "Machine_Unlearning_of_Pre-trained_Large_Language_Models__p1__score1.00.png",
        "Total_Abs_Diff": 6.476
    },
    {
        "figure_name": "Locating_and_Extracting_Relational_Concepts_in_Large_Language_Models__p0__score0.95.png",
        "Total_Abs_Diff": 6.476
    },
    {
        "figure_name": "AGrail_A_Lifelong_Agent_Guardrail_with_Effective_and_Adaptive_Safety_Detection__p3__score1.00.png",
        "Total_Abs_Diff": 6.380000000000001
    },
    {
        "figure_name": "IHEval_Evaluating_Language_Models_on_Following_the_Instruction_Hierarchy__p3__score1.00.png",
        "Total_Abs_Diff": 6.286999999999999
    },
    {
        "figure_name": "ZoomEye_Enhancing_Multimodal_LLMs_with_Human-Like_Zooming_Capabilities_through_Tree-Based_Image_Exploration__p3__score0.95.png",
        "Total_Abs_Diff": 6.286
    },
    {
        "figure_name": "Memory_OS_of_AI_Agent__p7__score0.90.png",
        "Total_Abs_Diff": 6.2379999999999995
    },
    {
        "figure_name": "Less_is_More_Mitigating_Multimodal_Hallucination_from_an_EOS_Decision_Perspective__p4__score0.70.png",
        "Total_Abs_Diff": 6.237
    },
    {
        "figure_name": "LLMs_Trust_Humans_More_That_s_a_Problem_Unveiling_and_Mitigating_the_Authority_Bias_in_Retrieval-Augmented_Generation__p4__score1.00.png",
        "Total_Abs_Diff": 6.19
    },
    {
        "figure_name": "MASTER_A_Multi-Agent_System_with_LLM_Specialized_MCTS__p2__score1.00.png",
        "Total_Abs_Diff": 6.143999999999999
    },
    {
        "figure_name": "Ko-LongRAG_A_Korean_Long-Context_RAG_Benchmark_Built_with_a_Retrieval-Free_Approach__p6__score0.90.png",
        "Total_Abs_Diff": 6.143
    },
    {
        "figure_name": "Exploring_Precision_and_Recall_to_assess_the_quality_and_diversity_of_LLMs__p3__score0.80.png",
        "Total_Abs_Diff": 6.143
    },
    {
        "figure_name": "When_Not_to_Trust_Language_Models_Investigating_Effectiveness_of_Parametric_and_Non-Parametric_Memories__p2__score1.00.png",
        "Total_Abs_Diff": 6.095000000000001
    },
    {
        "figure_name": "How_Johnny_Can_Persuade_LLMs_to_Jailbreak_Them_Rethinking_Persuasion_to_Challenge_AI_Safety_by_Humanizing_LLMs__p2__score0.95.png",
        "Total_Abs_Diff": 5.952
    },
    {
        "figure_name": "Error-driven_Data-efficient_Large_Multimodal_Model_Tuning__p3__score0.95.png",
        "Total_Abs_Diff": 5.904
    },
    {
        "figure_name": "Make_Every_Penny_Count_Difficulty-Adaptive_Self-Consistency_for_Cost-Efficient_Reasoning__p2__score1.00.png",
        "Total_Abs_Diff": 5.81
    },
    {
        "figure_name": "Establishing_Trustworthy_LLM_Evaluation_via_Shortcut_Neuron_Analysis__p0__score0.95.png",
        "Total_Abs_Diff": 5.81
    },
    {
        "figure_name": "Locating_and_Extracting_Relational_Concepts_in_Large_Language_Models__p3__score1.00.png",
        "Total_Abs_Diff": 5.809
    },
    {
        "figure_name": "Carpe_Diem_On_the_Evaluation_of_World_Knowledge_in_Lifelong_Language_Models__p2__score1.00.png",
        "Total_Abs_Diff": 5.763
    },
    {
        "figure_name": "Reverse_Thinking_Makes_LLMs_Stronger_Reasoners__p0__score0.98.png",
        "Total_Abs_Diff": 5.7620000000000005
    },
    {
        "figure_name": "A_Theory_of_Response_Sampling_in_LLMs_Part_Descriptive_and_Part_Prescriptive__p1__score1.00.png",
        "Total_Abs_Diff": 5.714
    },
    {
        "figure_name": "How_Johnny_Can_Persuade_LLMs_to_Jailbreak_Them_Rethinking_Persuasion_to_Challenge_AI_Safety_by_Humanizing_LLMs__p3__score1.00.png",
        "Total_Abs_Diff": 5.666
    },
    {
        "figure_name": "How_Johnny_Can_Persuade_LLMs_to_Jailbreak_Them_Rethinking_Persuasion_to_Challenge_AI_Safety_by_Humanizing_LLMs__p1__score1.00.png",
        "Total_Abs_Diff": 5.619999999999999
    },
    {
        "figure_name": "Mind_the_Value-Action_Gap_Do_LLMs_Act_in_Alignment_with_Their_Values__p0__score0.95.png",
        "Total_Abs_Diff": 5.619999999999999
    },
    {
        "figure_name": "Learning_from_Diverse_Reasoning_Paths_with_Routing_and_Collaboration__p2__score0.95.png",
        "Total_Abs_Diff": 5.619999999999999
    },
    {
        "figure_name": "ZoomEye_Enhancing_Multimodal_LLMs_with_Human-Like_Zooming_Capabilities_through_Tree-Based_Image_Exploration__p0__score1.00.png",
        "Total_Abs_Diff": 5.571
    },
    {
        "figure_name": "Performance_Gap_in_Entity_Knowledge_Extraction_Across_Modalities_in_Vision_Language_Models__p1__score1.00.png",
        "Total_Abs_Diff": 5.571
    },
    {
        "figure_name": "On_LLM-Based_Scientific_Inductive_Reasoning_Beyond_Equations__p4__score1.00.png",
        "Total_Abs_Diff": 5.57
    },
    {
        "figure_name": "When_Not_to_Trust_Language_Models_Investigating_Effectiveness_of_Parametric_and_Non-Parametric_Memories__p0__score0.70.png",
        "Total_Abs_Diff": 5.476999999999999
    },
    {
        "figure_name": "Fooling_the_LVLM_Judges_Visual_Biases_in_LVLM-Based_Evaluation_3.5_4.1__p2__score0.60.png",
        "Total_Abs_Diff": 5.429
    },
    {
        "figure_name": "CoPL_Collaborative_Preference_Learning_for_Personalizing_LLMs__p4__score0.95.png",
        "Total_Abs_Diff": 5.381
    },
    {
        "figure_name": "Mitigating_Biases_for_Instruction-following_Language_Models_via_Bias_Neurons_Elimination__p0__score0.95.png",
        "Total_Abs_Diff": 5.380000000000001
    },
    {
        "figure_name": "Performance_Gap_in_Entity_Knowledge_Extraction_Across_Modalities_in_Vision_Language_Models__p2__score1.00.png",
        "Total_Abs_Diff": 5.334
    },
    {
        "figure_name": "Interpretable_Preferences_via_Multi-Objective_Reward_Modeling_and_Mixture-of-Experts__p1__score1.00.png",
        "Total_Abs_Diff": 5.285
    },
    {
        "figure_name": "Competition_of_Mechanisms_Tracing_How_Language_Models_Handle_Facts_and_Counterfactuals__p0__score1.00.png",
        "Total_Abs_Diff": 5.238999999999999
    },
    {
        "figure_name": "Make_Every_Penny_Count_Difficulty-Adaptive_Self-Consistency_for_Cost-Efficient_Reasoning__p1__score1.00.png",
        "Total_Abs_Diff": 5.2379999999999995
    },
    {
        "figure_name": "Express_Uncertainty__p0__score0.80.png",
        "Total_Abs_Diff": 5.2379999999999995
    },
    {
        "figure_name": "SafeDecoding_Defending_against_Jailbreak_Attacks_via_Safety-Aware_Decoding__p4__score1.00.png",
        "Total_Abs_Diff": 5.237
    },
    {
        "figure_name": "Mitigating_Hallucinations_in_Large_Vision-Language_Models_with_Instruction_Contrastive_Decoding__p3__score1.00.png",
        "Total_Abs_Diff": 5.19
    },
    {
        "figure_name": "R-VLM_Region-Aware_Vision_Language_Model_for_Precise_GUI_Grounding__p1__score1.00.png",
        "Total_Abs_Diff": 5.143
    },
    {
        "figure_name": "Lost_in_the_Middle_How_Language_Models_Use_Long_Contexts__p3__score0.60.png",
        "Total_Abs_Diff": 5.143
    },
    {
        "figure_name": "Conditional_MASK_Discrete_Diffusion_Language_Model__p0__score1.00.png",
        "Total_Abs_Diff": 5.143
    },
    {
        "figure_name": "R-VLM_Region-Aware_Vision_Language_Model_for_Precise_GUI_Grounding__p4__score1.00.png",
        "Total_Abs_Diff": 5.143
    },
    {
        "figure_name": "Mind_the_Value-Action_Gap_Do_LLMs_Act_in_Alignment_with_Their_Values__p3__score1.00.png",
        "Total_Abs_Diff": 5.096
    },
    {
        "figure_name": "Beyond_Demographics_Fine-tuning_Large_Language_Models_to_Predict_Individuals_Subjective_Text_Perceptions__p0__score1.00.png",
        "Total_Abs_Diff": 5.096
    },
    {
        "figure_name": "Humans_or_LLMs_as_the_Judge_A_Study_on_Judgement_Bias__p4__score1.00.png",
        "Total_Abs_Diff": 5.095000000000001
    },
    {
        "figure_name": "Shifting_Attention_to_Relevance_Towards_the_Predictive_Uncertainty_Quantification_of_Free-Form_Large_Language_Models__p0__score0.90.png",
        "Total_Abs_Diff": 5.095000000000001
    },
    {
        "figure_name": "Rewarding_the_Unlikely_Lifting_GRPO_Beyond_Distribution_Sharpening__p0__score0.90.png",
        "Total_Abs_Diff": 5.047000000000001
    },
    {
        "figure_name": "RAG-Instruct_Boosting_LLMs_with_Diverse_Retrieval-Augmented_Instructions__p4__score0.95.png",
        "Total_Abs_Diff": 5.047000000000001
    },
    {
        "figure_name": "ImageInWords_Unlocking_Hyper-Detailed_Image_Descriptions__p1__score0.98.png",
        "Total_Abs_Diff": 5.0
    },
    {
        "figure_name": "Blinded_by_Generated_Contexts_How_Language_Models_Merge_Generated_and_Retrieved_Contexts_When_Knowledge_Conflicts__p3__score1.00.png",
        "Total_Abs_Diff": 4.952
    },
    {
        "figure_name": "Long-text_Uncertainty_Quantification_for_LLMs__p1__score1.00.png",
        "Total_Abs_Diff": 4.904
    },
    {
        "figure_name": "Self-Knowledge_Guided_Retrieval_Augmentation_for_Large_Language_Models__p0__score0.95.png",
        "Total_Abs_Diff": 4.81
    },
    {
        "figure_name": "PopAlign_Diversifying_Contrasting_Patterns_for_a_More_Comprehensive_Alignment__p2__score1.00.png",
        "Total_Abs_Diff": 4.81
    },
    {
        "figure_name": "SafeDecoding_Defending_against_Jailbreak_Attacks_via_Safety-Aware_Decoding__p0__score0.95.png",
        "Total_Abs_Diff": 4.809
    },
    {
        "figure_name": "DiffusionBERT_Improving_Generative_Masked_Language_Models_with_Diffusion_Models__p0__score1.00__2.png",
        "Total_Abs_Diff": 4.714
    },
    {
        "figure_name": "DiffusionBERT_Improving_Generative_Masked_Language_Models_with_Diffusion_Models__p0__score1.00__1.png",
        "Total_Abs_Diff": 4.714
    },
    {
        "figure_name": "Knowledge_Unlearning_for_Mitigating_Privacy_Risks_in_Language_Models__p1__score1.00.png",
        "Total_Abs_Diff": 4.619
    },
    {
        "figure_name": "AKE_Assessing_Knowledge_Editing_in_Language_Models_via_Multi-Hop_Questions__p0__score0.70.png",
        "Total_Abs_Diff": 4.619
    },
    {
        "figure_name": "Language_Models_as_Inductive_Reasoners__p1__score0.70.png",
        "Total_Abs_Diff": 4.571
    },
    {
        "figure_name": "IHEval_Evaluating_Language_Models_on_Following_the_Instruction_Hierarchy__p1__score1.00.png",
        "Total_Abs_Diff": 4.571
    },
    {
        "figure_name": "Memory_OS_of_AI_Agent__p2__score1.00.png",
        "Total_Abs_Diff": 4.5249999999999995
    },
    {
        "figure_name": "MARVEL_Unlocking_the_Multi-Modal_Capability_of_Dense_Retrieval_via_Visual_Module_Plugin__p3__score1.00.png",
        "Total_Abs_Diff": 4.524
    },
    {
        "figure_name": "IHEval_Evaluating_Language_Models_on_Following_the_Instruction_Hierarchy__p4__score0.80.png",
        "Total_Abs_Diff": 4.476
    },
    {
        "figure_name": "Improve_Vision_Language_Model_Chain-of-thought_Reasoning__p3__score0.95.png",
        "Total_Abs_Diff": 4.476
    },
    {
        "figure_name": "CoPL_Collaborative_Preference_Learning_for_Personalizing_LLMs__p3__score1.00.png",
        "Total_Abs_Diff": 4.43
    },
    {
        "figure_name": "Mitigating_Hallucinations_in_Vision-Language_Models_through_Image-Guided_Head_Suppression__p0__score0.95.png",
        "Total_Abs_Diff": 4.43
    },
    {
        "figure_name": "Blinded_by_Generated_Contexts_How_Language_Models_Merge_Generated_and_Retrieved_Contexts_When_Knowledge_Conflicts__p2__score1.00.png",
        "Total_Abs_Diff": 4.380000000000001
    },
    {
        "figure_name": "Progressive_Multimodal_Reasoning_via_Active_Retrieval__p5__score1.00.png",
        "Total_Abs_Diff": 4.333
    },
    {
        "figure_name": "Establishing_Trustworthy_LLM_Evaluation_via_Shortcut_Neuron_Analysis__p3__score1.00.png",
        "Total_Abs_Diff": 4.333
    },
    {
        "figure_name": "DiffusionBERT_Improving_Generative_Masked_Language_Models_with_Diffusion_Models__p0__score1.00.png",
        "Total_Abs_Diff": 4.286
    },
    {
        "figure_name": "Active_Prompting_with_Chain-of-Thought_for_Large_Language_Models__p1__score1.00.png",
        "Total_Abs_Diff": 4.2379999999999995
    },
    {
        "figure_name": "of_Multimodal_Large_Language_Models_Multimodal_Needle_in_a_Haystack_Benchmarking_Long-Context_Capability__p1__score1.00.png",
        "Total_Abs_Diff": 4.237
    },
    {
        "figure_name": "Progressive_Multimodal_Reasoning_via_Active_Retrieval__p2__score0.95.png",
        "Total_Abs_Diff": 4.237
    },
    {
        "figure_name": "PopAlign_Diversifying_Contrasting_Patterns_for_a_More_Comprehensive_Alignment__p0__score0.90.png",
        "Total_Abs_Diff": 4.143999999999999
    },
    {
        "figure_name": "Mission_Impossible_Language_Models__p0__score0.95.png",
        "Total_Abs_Diff": 4.143
    },
    {
        "figure_name": "Learning_from_Diverse_Reasoning_Paths_with_Routing_and_Collaboration__p0__score0.95.png",
        "Total_Abs_Diff": 4.096
    },
    {
        "figure_name": "Spiral_of_Silence_How_is_Large_Language_Model_Killing_Information_Retrieval_A_Case_Study_on_Open_Domain_Question_Answering__p0__score1.00.png",
        "Total_Abs_Diff": 4.096
    },
    {
        "figure_name": "Carpe_Diem_On_the_Evaluation_of_World_Knowledge_in_Lifelong_Language_Models__p0__score0.95.png",
        "Total_Abs_Diff": 4.096
    },
    {
        "figure_name": "Bridging_the_Visual_Gap_Fine-Tuning_Multimodal_Models_with_Knowledge-Adapted_Captions__p1__score1.00.png",
        "Total_Abs_Diff": 4.047000000000001
    },
    {
        "figure_name": "Steering_Llama_2_via_Contrastive_Activation_Addition__p0__score1.00.png",
        "Total_Abs_Diff": 4.047000000000001
    },
    {
        "figure_name": "Cross-Lingual_Retrieval_Augmented_Prompt_for_Low-Resource_Languages__p0__score1.00.png",
        "Total_Abs_Diff": 4.0
    },
    {
        "figure_name": "Learning_from_Diverse_Reasoning_Paths_with_Routing_and_Collaboration__p3__score1.00.png",
        "Total_Abs_Diff": 3.953
    },
    {
        "figure_name": "In_Prospect_and_Retrospect_Re_ective_Memory_Management_for_Long-term_Personalized_Dialogue_Agents__p3__score0.95.png",
        "Total_Abs_Diff": 3.9529999999999994
    },
    {
        "figure_name": "Generating_Diverse_Hypotheses_for_Inductive_Reasoning__p7__score0.70.png",
        "Total_Abs_Diff": 3.9520000000000004
    },
    {
        "figure_name": "Sociodemographic_Persona_Prompts_Evaluation__p0__score0.95.png",
        "Total_Abs_Diff": 3.952
    },
    {
        "figure_name": "Blinded_by_Generated_Contexts_How_Language_Models_Merge_Generated_and_Retrieved_Contexts_When_Knowledge_Conflicts__p2__score0.95.png",
        "Total_Abs_Diff": 3.952
    },
    {
        "figure_name": "Con_dence_Improves_Self-Consistency_in_LLMs__p1__score0.90.png",
        "Total_Abs_Diff": 3.904
    },
    {
        "figure_name": "Measuring_Chain_of_Thought_Faithfulness_by_Unlearning_Reasoning_Steps__p0__score0.95.png",
        "Total_Abs_Diff": 3.7620000000000005
    },
    {
        "figure_name": "LINC_A_Neurosymbolic_Approach_for_Logical_Reasoning_by_Combining_Language_Models_with_First-Order_Logic_Provers__p1__score1.00__1.png",
        "Total_Abs_Diff": 3.667
    },
    {
        "figure_name": "LINC_A_Neurosymbolic_Approach_for_Logical_Reasoning_by_Combining_Language_Models_with_First-Order_Logic_Provers__p1__score1.00.png",
        "Total_Abs_Diff": 3.667
    },
    {
        "figure_name": "Visual_Evidence_Prompting_Mitigates_Hallucinations_in_Large_Vision-Language_Models__p3__score1.00.png",
        "Total_Abs_Diff": 3.6189999999999998
    },
    {
        "figure_name": "Improve_Vision_Language_Model_Chain-of-thought_Reasoning__p1__score0.98.png",
        "Total_Abs_Diff": 3.571
    },
    {
        "figure_name": "Generating_Diverse_Hypotheses_for_Inductive_Reasoning__p1__score1.00.png",
        "Total_Abs_Diff": 3.5700000000000003
    },
    {
        "figure_name": "Generating_Diverse_Hypotheses_for_Inductive_Reasoning__p4__score0.95.png",
        "Total_Abs_Diff": 3.524
    },
    {
        "figure_name": "In_Prospect_and_Retrospect_Re_ective_Memory_Management_for_Long-term_Personalized_Dialogue_Agents__p4__score1.00.png",
        "Total_Abs_Diff": 3.476
    },
    {
        "figure_name": "How_Do_Moral_Emotions_Shape_Political_Participation_A_Cross-Cultural_Analysis_of_Online_Petitions_Using_Language_Models__p3__score1.00.png",
        "Total_Abs_Diff": 3.476
    },
    {
        "figure_name": "Self-Knowledge_Guided_Retrieval_Augmentation_for_Large_Language_Models__p3__score1.00.png",
        "Total_Abs_Diff": 3.476
    },
    {
        "figure_name": "Progressive_Multimodal_Reasoning_via_Active_Retrieval__p3__score1.00.png",
        "Total_Abs_Diff": 3.4290000000000003
    },
    {
        "figure_name": "Can_You_Trick_the_Grader_Adversarial_Persuasion_of_LLM_Judges__p0__score0.90.png",
        "Total_Abs_Diff": 3.4290000000000003
    },
    {
        "figure_name": "Self-Knowledge_Guided_Retrieval_Augmentation_for_Large_Language_Models__p2__score1.00.png",
        "Total_Abs_Diff": 3.380000000000001
    },
    {
        "figure_name": "ZoomEye_Enhancing_Multimodal_LLMs_with_Human-Like_Zooming_Capabilities_through_Tree-Based_Image_Exploration__p7__score0.95.png",
        "Total_Abs_Diff": 3.3800000000000003
    },
    {
        "figure_name": "Conditional_MASK_Discrete_Diffusion_Language_Model__p3__score1.00.png",
        "Total_Abs_Diff": 3.333
    },
    {
        "figure_name": "MemInsight_Autonomous_Memory_Augmentation_for_LLM_Agents__p2__score1.00.png",
        "Total_Abs_Diff": 3.333
    },
    {
        "figure_name": "Ko-LongRAG_A_Korean_Long-Context_RAG_Benchmark_Built_with_a_Retrieval-Free_Approach__p1__score1.00.png",
        "Total_Abs_Diff": 3.333
    },
    {
        "figure_name": "Weakly_Supervised_Semantic_Parsing_with_Execution-based_Spurious_Program_Filtering__p3__score0.70.png",
        "Total_Abs_Diff": 3.2379999999999995
    },
    {
        "figure_name": "Towards_Statistical_Factuality_Guarantee_for_Large_Vision-Language_Models__p1__score1.00.png",
        "Total_Abs_Diff": 3.237
    },
    {
        "figure_name": "Finetuning_LLMs_for_Human_Behavior_Prediction_in_Social_Science_Experiments__p3__score1.00.png",
        "Total_Abs_Diff": 3.1900000000000004
    },
    {
        "figure_name": "OVM_utcome-supervised_alue_odels_for_Planning_in_Mathematical_Reasoning__p2__score1.00.png",
        "Total_Abs_Diff": 3.1900000000000004
    },
    {
        "figure_name": "LINC_A_Neurosymbolic_Approach_for_Logical_Reasoning_by_Combining_Language_Models_with_First-Order_Logic_Provers__p3__score1.00.png",
        "Total_Abs_Diff": 3.143
    },
    {
        "figure_name": "ImageInWords_Unlocking_Hyper-Detailed_Image_Descriptions__p4__score0.90.png",
        "Total_Abs_Diff": 3.143
    },
    {
        "figure_name": "LINC_A_Neurosymbolic_Approach_for_Logical_Reasoning_by_Combining_Language_Models_with_First-Order_Logic_Provers__p3__score0.98.png",
        "Total_Abs_Diff": 3.143
    },
    {
        "figure_name": "Bridging_the_Visual_Gap_Fine-Tuning_Multimodal_Models_with_Knowledge-Adapted_Captions__p0__score1.00.png",
        "Total_Abs_Diff": 3.143
    },
    {
        "figure_name": "FaST_Feature-aware_Sampling_and_Tuning_for_Personalized_Preference_Alignment_with_Limited_Data__p2__score1.00.png",
        "Total_Abs_Diff": 3.096
    },
    {
        "figure_name": "On_LLM-Based_Scientific_Inductive_Reasoning_Beyond_Equations__p0__score1.00.png",
        "Total_Abs_Diff": 3.0950000000000006
    },
    {
        "figure_name": "Reverse_Thinking_Makes_LLMs_Stronger_Reasoners__p3__score1.00.png",
        "Total_Abs_Diff": 3.0470000000000006
    },
    {
        "figure_name": "In_Prospect_and_Retrospect_Re_ective_Memory_Management_for_Long-term_Personalized_Dialogue_Agents__p0__score0.95.png",
        "Total_Abs_Diff": 3.0
    },
    {
        "figure_name": "Error-driven_Data-efficient_Large_Multimodal_Model_Tuning__p2__score1.00.png",
        "Total_Abs_Diff": 2.953
    },
    {
        "figure_name": "Generating_Diverse_Hypotheses_for_Inductive_Reasoning__p3__score1.00.png",
        "Total_Abs_Diff": 2.9529999999999994
    },
    {
        "figure_name": "Are_LLM-Judges_Robust_to_Expressions_of_Uncertainty_Investigating_the_effect_of_Epistemic_Markers_on_LLM-based_Evaluation__p4__score1.00.png",
        "Total_Abs_Diff": 2.9529999999999994
    },
    {
        "figure_name": "How_Johnny_Can_Persuade_LLMs_to_Jailbreak_Them_Rethinking_Persuasion_to_Challenge_AI_Safety_by_Humanizing_LLMs__p0__score0.95.png",
        "Total_Abs_Diff": 2.952
    },
    {
        "figure_name": "ZoomEye_Enhancing_Multimodal_LLMs_with_Human-Like_Zooming_Capabilities_through_Tree-Based_Image_Exploration__p1__score0.95.png",
        "Total_Abs_Diff": 2.9040000000000004
    },
    {
        "figure_name": "AKE_Assessing_Knowledge_Editing_in_Language_Models_via_Multi-Hop_Questions__p6__score1.00.png",
        "Total_Abs_Diff": 2.763
    },
    {
        "figure_name": "Step-level_Value_Preference_Optimization_for_Mathematical_Reasoning__p2__score1.00.png",
        "Total_Abs_Diff": 2.762
    },
    {
        "figure_name": "VLind-Bench_Measuring_Language_Priors_in_Large_Vision-Language_Models__p1__score1.00.png",
        "Total_Abs_Diff": 2.7140000000000004
    },
    {
        "figure_name": "Measuring_Chain_of_Thought_Faithfulness_by_Unlearning_Reasoning_Steps__p3__score1.00.png",
        "Total_Abs_Diff": 2.7140000000000004
    },
    {
        "figure_name": "MP2D_AnAutomated_Topic_Shift_Dialogue_Generation_Framework__p0__score0.90.png",
        "Total_Abs_Diff": 2.5709999999999997
    },
    {
        "figure_name": "Vision-Language_Models_Can_Self-Improve_Reasoning_via_Reflection__p3__score1.00.png",
        "Total_Abs_Diff": 2.5700000000000003
    },
    {
        "figure_name": "Visual_Evidence_Prompting_Mitigates_Hallucinations_in_Large_Vision-Language_Models__p0__score0.90.png",
        "Total_Abs_Diff": 2.4769999999999994
    },
    {
        "figure_name": "LLMs_Trust_Humans_More_That_s_a_Problem_Unveiling_and_Mitigating_the_Authority_Bias_in_Retrieval-Augmented_Generation__p1__score1.00.png",
        "Total_Abs_Diff": 2.4299999999999993
    },
    {
        "figure_name": "Improve_Vision_Language_Model_Chain-of-thought_Reasoning__p2__score0.70.png",
        "Total_Abs_Diff": 2.238
    },
    {
        "figure_name": "Bridging_the_Visual_Gap_Fine-Tuning_Multimodal_Models_with_Knowledge-Adapted_Captions__p3__score1.00.png",
        "Total_Abs_Diff": 2.2379999999999995
    },
    {
        "figure_name": "Do_Large_Language_Models_Latently_Perform_Multi-Hop_Reasoning__p0__score0.90.png",
        "Total_Abs_Diff": 2.143
    },
    {
        "figure_name": "DRAGIN_Dynamic_Retrieval_Augmented_Generation_based_on_the_Information_Needs_of_Large_Language_Models__p5__score0.60.png",
        "Total_Abs_Diff": 2.0959999999999996
    },
    {
        "figure_name": "AdaRewriter_Unleashing_the_Power_of_Prompting-based_Conversational_Query_Reformulation_via_Test-Time_Adaptation__p2__score1.00.png",
        "Total_Abs_Diff": 1.7620000000000005
    },
    {
        "figure_name": "To_Mask_or_to_Mirror_Human-AI_Alignment_in_Collective_Reasoning__p5__score1.00.png",
        "Total_Abs_Diff": 1.7620000000000005
    },
    {
        "figure_name": "RAG-Instruct_Boosting_LLMs_with_Diverse_Retrieval-Augmented_Instructions__p3__score0.95.png",
        "Total_Abs_Diff": 1.6660000000000004
    },
    {
        "figure_name": "WebEvolver_Enhancing_Web_Agent_Self-Improvement_with_Co-evolving_World_Model__p0__score1.00.png",
        "Total_Abs_Diff": 1.476
    },
    {
        "figure_name": "WebEvolver_Enhancing_Web_Agent_Self-Improvement_with_Co-evolving_World_Model__p2__score1.00.png",
        "Total_Abs_Diff": 1.1429999999999998
    },
    {
        "figure_name": "DRAGIN_Dynamic_Retrieval_Augmented_Generation_based_on_the_Information_Needs_of_Large_Language_Models__p2__score1.00.png",
        "Total_Abs_Diff": 0.9039999999999999
    },
    {
        "figure_name": "Collaborative_Instance_Object_Navigation_Leveraging_Uncertainty-Awareness_to_Minimize_Human-Agent_Dialogues__p3__score1.00.png",
        "Total_Abs_Diff": 0.0
    },
    {
        "figure_name": "AKE_Assessing_Knowledge_Editing_in_Language_Models_via_Multi-Hop_Questions__p3__score0.80.png",
        "Total_Abs_Diff": 0.0
    },
    {
        "figure_name": "Boosting_Language_Models_Reasoning_with_Chain-of-Knowledge_Prompting__p2__score1.00.png",
        "Total_Abs_Diff": 0.0
    },
    {
        "figure_name": "Boosting_Language_Models_Reasoning_with_Chain-of-Knowledge_Prompting__p1__score1.00.png",
        "Total_Abs_Diff": 0.0
    },
    {
        "figure_name": "Knowledge_Unlearning_for_Mitigating_Privacy_Risks_in_Language_Models__p1__score1.00__1.png",
        "Total_Abs_Diff": 0.0
    },
    {
        "figure_name": "Retrieval-Augmented_Black-Box_Language_Models__p2__score1.00.png",
        "Total_Abs_Diff": 0.0
    },
    {
        "figure_name": "Retrieval-Augmented_Black-Box_Language_Models__p0__score1.00.png",
        "Total_Abs_Diff": 0.0
    },
    {
        "figure_name": "Mitigating_Visual_Forgetting_via_Take-along_Visual_Conditioning_for_Multi-modal_Long_CoT_Reasoning__p4__score1.00.png",
        "Total_Abs_Diff": 0.0
    },
    {
        "figure_name": "Mitigating_Visual_Forgetting_via_Take-along_Visual_Conditioning_for_Multi-modal_Long_CoT_Reasoning__p7__score0.93.png",
        "Total_Abs_Diff": 0.0
    },
    {
        "figure_name": "Mitigating_Visual_Forgetting_via_Take-along_Visual_Conditioning_for_Multi-modal_Long_CoT_Reasoning__p2__score0.90.png",
        "Total_Abs_Diff": 0.0
    },
    {
        "figure_name": "Models_Fine-grained_Gender_Control_in_Machine_Translation_with_Large_Language__p2__score0.80.png",
        "Total_Abs_Diff": 0.0
    },
    {
        "figure_name": "Retrieval-Augmented_Black-Box_Language_Models__p4__score1.00.png",
        "Total_Abs_Diff": 0.0
    },
    {
        "figure_name": "RAG_Overcoming_Imperfect_Retrieval_Augmentation_and_Knowledge_Conflicts_for_Large_Language_Models__p3__score1.00.png",
        "Total_Abs_Diff": 0.0
    },
    {
        "figure_name": "RAG_Overcoming_Imperfect_Retrieval_Augmentation_and_Knowledge_Conflicts_for_Large_Language_Models__p1__score0.95.png",
        "Total_Abs_Diff": 0.0
    },
    {
        "figure_name": "Mitigating_Visual_Forgetting_via_Take-along_Visual_Conditioning_for_Multi-modal_Long_CoT_Reasoning__p3__score1.00.png",
        "Total_Abs_Diff": 0.0
    },
    {
        "figure_name": "When_Not_to_Trust_Language_Models_Investigating_Effectiveness_of_Parametric_and_Non-Parametric_Memories__p2__score1.00__1.png",
        "Total_Abs_Diff": 0.0
    },
    {
        "figure_name": "When_Not_to_Trust_Language_Models_Investigating_Effectiveness_of_Parametric_and_Non-Parametric_Memories__p0__score0.80.png",
        "Total_Abs_Diff": 0.0
    }
]