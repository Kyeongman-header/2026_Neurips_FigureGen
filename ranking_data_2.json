[
    {
        "filename": "Weakly_Supervised_Semantic_Parsing_with_Execution-based_Spurious_Program_Filtering__p2__score0.70.png",
        "Total_Impact": -0.041733,
        "details": {
            "Informativeness": {
                "impact": 0.001612,
                "llm_score": 1.667,
                "human_score": 3.0
            },
            "Overall Readability": {
                "impact": 0.000766,
                "llm_score": 4.0,
                "human_score": 4.0
            },
            "Creativity": {
                "impact": -0.005586,
                "llm_score": 2.667,
                "human_score": 4.0
            },
            "Design Quality": {
                "impact": -0.024685,
                "llm_score": 2.143,
                "human_score": 4.0
            },
            "Fidelity": {
                "impact": -0.01384,
                "llm_score": 1.0,
                "human_score": 5.0
            }
        }
    },
    {
        "filename": "Exploring_Precision_and_Recall_to_assess_the_quality_and_diversity_of_LLMs__p4__score1.00.png",
        "Total_Impact": -0.036512,
        "details": {
            "Informativeness": {
                "impact": -0.001574,
                "llm_score": 2.333,
                "human_score": 4.0
            },
            "Overall Readability": {
                "impact": -0.022011,
                "llm_score": 2.0,
                "human_score": 5.0
            },
            "Creativity": {
                "impact": -0.011926,
                "llm_score": 2.667,
                "human_score": 5.0
            },
            "Design Quality": {
                "impact": -0.000198,
                "llm_score": 4.143,
                "human_score": 5.0
            },
            "Fidelity": {
                "impact": -0.000803,
                "llm_score": 4.0,
                "human_score": 5.0
            }
        }
    },
    {
        "filename": "Distilling_Step-by-Step_Outperforming_Larger_Language_Models_with_Less_Training_Data_and_Smaller_Model_Sizes__p2__score0.95.png",
        "Total_Impact": -0.031942,
        "details": {
            "Informativeness": {
                "impact": -0.00239,
                "llm_score": 3.0,
                "human_score": 3.0
            },
            "Overall Readability": {
                "impact": -0.012533,
                "llm_score": 4.333,
                "human_score": 2.0
            },
            "Creativity": {
                "impact": 0.007041,
                "llm_score": 2.667,
                "human_score": 1.0
            },
            "Design Quality": {
                "impact": -0.009266,
                "llm_score": 4.286,
                "human_score": 1.0
            },
            "Fidelity": {
                "impact": -0.014794,
                "llm_score": 5.0,
                "human_score": 2.0
            }
        }
    },
    {
        "filename": "IHEval_Evaluating_Language_Models_on_Following_the_Instruction_Hierarchy__p4__score0.80.png",
        "Total_Impact": -0.028143,
        "details": {
            "Informativeness": {
                "impact": -0.022862,
                "llm_score": 3.333,
                "human_score": 1.0
            },
            "Overall Readability": {
                "impact": 8.9e-05,
                "llm_score": 3.667,
                "human_score": 4.0
            },
            "Creativity": {
                "impact": -0.00122,
                "llm_score": 2.333,
                "human_score": 3.0
            },
            "Design Quality": {
                "impact": -0.00158,
                "llm_score": 3.857,
                "human_score": 4.0
            },
            "Fidelity": {
                "impact": -0.00257,
                "llm_score": 5.0,
                "human_score": 4.0
            }
        }
    },
    {
        "filename": "VISTA_Visualized_Text_Embedding_For_Universal_Multi-Modal_Retrieval__p3__score1.00.png",
        "Total_Impact": -0.025386,
        "details": {
            "Informativeness": {
                "impact": 6.3e-05,
                "llm_score": 2.667,
                "human_score": 4.0
            },
            "Overall Readability": {
                "impact": -0.01235,
                "llm_score": 2.667,
                "human_score": 5.0
            },
            "Creativity": {
                "impact": 0.003919,
                "llm_score": 3.667,
                "human_score": 4.0
            },
            "Design Quality": {
                "impact": -0.012114,
                "llm_score": 3.571,
                "human_score": 5.0
            },
            "Fidelity": {
                "impact": -0.004905,
                "llm_score": 3.0,
                "human_score": 5.0
            }
        }
    },
    {
        "filename": "ImageInWords_Unlocking_Hyper-Detailed_Image_Descriptions__p1__score0.98.png",
        "Total_Impact": -0.024103,
        "details": {
            "Informativeness": {
                "impact": 0.001523,
                "llm_score": 3.333,
                "human_score": 4.0
            },
            "Overall Readability": {
                "impact": -0.022011,
                "llm_score": 2.0,
                "human_score": 5.0
            },
            "Creativity": {
                "impact": -0.000364,
                "llm_score": 2.667,
                "human_score": 3.0
            },
            "Design Quality": {
                "impact": -0.000681,
                "llm_score": 4.0,
                "human_score": 4.0
            },
            "Fidelity": {
                "impact": -0.00257,
                "llm_score": 5.0,
                "human_score": 4.0
            }
        }
    },
    {
        "filename": "How_Johnny_Can_Persuade_LLMs_to_Jailbreak_Them_Rethinking_Persuasion_to_Challenge_AI_Safety_by_Humanizing_LLMs__p4__score0.80.png",
        "Total_Impact": -0.021845,
        "details": {
            "Informativeness": {
                "impact": -0.00382,
                "llm_score": 2.0,
                "human_score": 4.0
            },
            "Overall Readability": {
                "impact": -0.022011,
                "llm_score": 2.0,
                "human_score": 5.0
            },
            "Creativity": {
                "impact": 0.000895,
                "llm_score": 3.0,
                "human_score": 2.0
            },
            "Design Quality": {
                "impact": -0.00158,
                "llm_score": 3.857,
                "human_score": 4.0
            },
            "Fidelity": {
                "impact": 0.004671,
                "llm_score": 2.667,
                "human_score": 4.0
            }
        }
    },
    {
        "filename": "DocFinQA_A_Long-Context_Financial_Reasoning_Dataset__p0__score0.80.png",
        "Total_Impact": -0.020728,
        "details": {
            "Informativeness": {
                "impact": 0.000871,
                "llm_score": 2.333,
                "human_score": 1.0
            },
            "Overall Readability": {
                "impact": -0.003593,
                "llm_score": 3.667,
                "human_score": 1.0
            },
            "Creativity": {
                "impact": -0.006438,
                "llm_score": 3.667,
                "human_score": 2.0
            },
            "Design Quality": {
                "impact": 0.001433,
                "llm_score": 4.0,
                "human_score": 1.0
            },
            "Fidelity": {
                "impact": -0.013,
                "llm_score": 4.667,
                "human_score": 1.0
            }
        }
    },
    {
        "filename": "Exploring_Precision_and_Recall_to_assess_the_quality_and_diversity_of_LLMs__p3__score0.80.png",
        "Total_Impact": -0.018518,
        "details": {
            "Informativeness": {
                "impact": 0.001517,
                "llm_score": 2.0,
                "human_score": 3.0
            },
            "Overall Readability": {
                "impact": -0.002767,
                "llm_score": 4.0,
                "human_score": 3.0
            },
            "Creativity": {
                "impact": -0.011926,
                "llm_score": 2.667,
                "human_score": 5.0
            },
            "Design Quality": {
                "impact": -0.005873,
                "llm_score": 3.857,
                "human_score": 5.0
            },
            "Fidelity": {
                "impact": 0.000531,
                "llm_score": 4.333,
                "human_score": 5.0
            }
        }
    },
    {
        "filename": "Humans_or_LLMs_as_the_Judge_A_Study_on_Judgement_Bias__p3__score1.00.png",
        "Total_Impact": -0.018499,
        "details": {
            "Informativeness": {
                "impact": -0.007483,
                "llm_score": 3.0,
                "human_score": 2.0
            },
            "Overall Readability": {
                "impact": -0.001687,
                "llm_score": 3.667,
                "human_score": 2.0
            },
            "Creativity": {
                "impact": 0.000765,
                "llm_score": 3.0,
                "human_score": 1.0
            },
            "Design Quality": {
                "impact": -0.005063,
                "llm_score": 4.286,
                "human_score": 2.0
            },
            "Fidelity": {
                "impact": -0.00503,
                "llm_score": 4.667,
                "human_score": 3.0
            }
        }
    },
    {
        "filename": "Know_When_To_Stop_A_Study_of_Semantic_Drift_in_Text_Generation__p1__score0.70.png",
        "Total_Impact": -0.018016,
        "details": {
            "Informativeness": {
                "impact": 0.001644,
                "llm_score": 2.333,
                "human_score": 2.0
            },
            "Overall Readability": {
                "impact": -0.006984,
                "llm_score": 4.0,
                "human_score": 2.0
            },
            "Creativity": {
                "impact": 0.000895,
                "llm_score": 3.0,
                "human_score": 2.0
            },
            "Design Quality": {
                "impact": -0.005063,
                "llm_score": 4.286,
                "human_score": 2.0
            },
            "Fidelity": {
                "impact": -0.008508,
                "llm_score": 5.0,
                "human_score": 3.0
            }
        }
    },
    {
        "filename": "Locating_and_Extracting_Relational_Concepts_in_Large_Language_Models__p0__score0.95.png",
        "Total_Impact": -0.017953,
        "details": {
            "Informativeness": {
                "impact": -0.016663,
                "llm_score": 1.667,
                "human_score": 5.0
            },
            "Overall Readability": {
                "impact": 0.003674,
                "llm_score": 4.0,
                "human_score": 5.0
            },
            "Creativity": {
                "impact": -0.005586,
                "llm_score": 2.667,
                "human_score": 4.0
            },
            "Design Quality": {
                "impact": 9e-05,
                "llm_score": 4.143,
                "human_score": 4.0
            },
            "Fidelity": {
                "impact": 0.000531,
                "llm_score": 4.333,
                "human_score": 5.0
            }
        }
    },
    {
        "filename": "Memory_OS_of_AI_Agent__p7__score0.90.png",
        "Total_Impact": -0.017399,
        "details": {
            "Informativeness": {
                "impact": -0.004914,
                "llm_score": 3.333,
                "human_score": 3.0
            },
            "Overall Readability": {
                "impact": -0.00486,
                "llm_score": 2.333,
                "human_score": 4.0
            },
            "Creativity": {
                "impact": -0.006438,
                "llm_score": 3.667,
                "human_score": 2.0
            },
            "Design Quality": {
                "impact": 0.003719,
                "llm_score": 3.571,
                "human_score": 3.0
            },
            "Fidelity": {
                "impact": -0.004905,
                "llm_score": 3.0,
                "human_score": 5.0
            }
        }
    },
    {
        "filename": "MP2D_AnAutomated_Topic_Shift_Dialogue_Generation_Framework__p2__score1.00.png",
        "Total_Impact": -0.016478,
        "details": {
            "Informativeness": {
                "impact": -0.00382,
                "llm_score": 2.0,
                "human_score": 4.0
            },
            "Overall Readability": {
                "impact": -0.005293,
                "llm_score": 4.333,
                "human_score": 3.0
            },
            "Creativity": {
                "impact": -0.006438,
                "llm_score": 3.667,
                "human_score": 2.0
            },
            "Design Quality": {
                "impact": 0.001642,
                "llm_score": 4.571,
                "human_score": 4.0
            },
            "Fidelity": {
                "impact": -0.00257,
                "llm_score": 5.0,
                "human_score": 4.0
            }
        }
    },
    {
        "filename": "Finetuning_LLMs_for_Human_Behavior_Prediction_in_Social_Science_Experiments__p0__score1.00.png",
        "Total_Impact": -0.016034,
        "details": {
            "Informativeness": {
                "impact": 0.001093,
                "llm_score": 3.0,
                "human_score": 4.0
            },
            "Overall Readability": {
                "impact": -0.001687,
                "llm_score": 3.667,
                "human_score": 2.0
            },
            "Creativity": {
                "impact": -0.006438,
                "llm_score": 3.667,
                "human_score": 2.0
            },
            "Design Quality": {
                "impact": -0.008557,
                "llm_score": 4.429,
                "human_score": 2.0
            },
            "Fidelity": {
                "impact": -0.000445,
                "llm_score": 4.333,
                "human_score": 4.0
            }
        }
    },
    {
        "filename": "Less_is_More_Mitigating_Multimodal_Hallucination_from_an_EOS_Decision_Perspective__p4__score0.70.png",
        "Total_Impact": -0.015498,
        "details": {
            "Informativeness": {
                "impact": 0.001517,
                "llm_score": 2.0,
                "human_score": 3.0
            },
            "Overall Readability": {
                "impact": -0.005293,
                "llm_score": 4.333,
                "human_score": 3.0
            },
            "Creativity": {
                "impact": 0.000895,
                "llm_score": 3.0,
                "human_score": 2.0
            },
            "Design Quality": {
                "impact": -0.012172,
                "llm_score": 4.571,
                "human_score": 2.0
            },
            "Fidelity": {
                "impact": -0.000445,
                "llm_score": 4.333,
                "human_score": 4.0
            }
        }
    },
    {
        "filename": "Models_Fine-grained_Gender_Control_in_Machine_Translation_with_Large_Language__p1__score0.70.png",
        "Total_Impact": -0.015209,
        "details": {
            "Informativeness": {
                "impact": -0.010781,
                "llm_score": 2.0,
                "human_score": 5.0
            },
            "Overall Readability": {
                "impact": 0.000766,
                "llm_score": 4.0,
                "human_score": 4.0
            },
            "Creativity": {
                "impact": -0.001932,
                "llm_score": 3.0,
                "human_score": 4.0
            },
            "Design Quality": {
                "impact": 0.001642,
                "llm_score": 4.571,
                "human_score": 4.0
            },
            "Fidelity": {
                "impact": -0.004905,
                "llm_score": 3.0,
                "human_score": 5.0
            }
        }
    },
    {
        "filename": "AGrail_A_Lifelong_Agent_Guardrail_with_Effective_and_Adaptive_Safety_Detection__p3__score1.00.png",
        "Total_Impact": -0.014543,
        "details": {
            "Informativeness": {
                "impact": 0.001093,
                "llm_score": 3.0,
                "human_score": 4.0
            },
            "Overall Readability": {
                "impact": -0.00671,
                "llm_score": 2.0,
                "human_score": 4.0
            },
            "Creativity": {
                "impact": 0.003919,
                "llm_score": 3.667,
                "human_score": 4.0
            },
            "Design Quality": {
                "impact": -0.006533,
                "llm_score": 3.286,
                "human_score": 4.0
            },
            "Fidelity": {
                "impact": -0.006313,
                "llm_score": 2.667,
                "human_score": 5.0
            }
        }
    },
    {
        "filename": "A_Theory_of_Response_Sampling_in_LLMs_Part_Descriptive_and_Part_Prescriptive__p4__score0.80.png",
        "Total_Impact": -0.014509,
        "details": {
            "Informativeness": {
                "impact": -0.00382,
                "llm_score": 2.0,
                "human_score": 4.0
            },
            "Overall Readability": {
                "impact": 0.003674,
                "llm_score": 4.0,
                "human_score": 5.0
            },
            "Creativity": {
                "impact": -0.011926,
                "llm_score": 2.667,
                "human_score": 5.0
            },
            "Design Quality": {
                "impact": -0.002969,
                "llm_score": 4.0,
                "human_score": 5.0
            },
            "Fidelity": {
                "impact": 0.000531,
                "llm_score": 4.333,
                "human_score": 5.0
            }
        }
    },
    {
        "filename": "How_Johnny_Can_Persuade_LLMs_to_Jailbreak_Them_Rethinking_Persuasion_to_Challenge_AI_Safety_by_Humanizing_LLMs__p3__score1.00.png",
        "Total_Impact": -0.014098,
        "details": {
            "Informativeness": {
                "impact": 0.001093,
                "llm_score": 3.0,
                "human_score": 4.0
            },
            "Overall Readability": {
                "impact": -0.001921,
                "llm_score": 3.0,
                "human_score": 4.0
            },
            "Creativity": {
                "impact": -0.011926,
                "llm_score": 2.667,
                "human_score": 5.0
            },
            "Design Quality": {
                "impact": -0.002969,
                "llm_score": 4.0,
                "human_score": 5.0
            },
            "Fidelity": {
                "impact": 0.001624,
                "llm_score": 3.667,
                "human_score": 4.0
            }
        }
    },
    {
        "filename": "Learning_from_Diverse_Reasoning_Paths_with_Routing_and_Collaboration__p0__score0.95.png",
        "Total_Impact": -0.0137,
        "details": {
            "Informativeness": {
                "impact": -0.00239,
                "llm_score": 3.0,
                "human_score": 3.0
            },
            "Overall Readability": {
                "impact": -0.000474,
                "llm_score": 3.667,
                "human_score": 3.0
            },
            "Creativity": {
                "impact": -0.000743,
                "llm_score": 3.667,
                "human_score": 3.0
            },
            "Design Quality": {
                "impact": -0.00378,
                "llm_score": 3.571,
                "human_score": 4.0
            },
            "Fidelity": {
                "impact": -0.006313,
                "llm_score": 2.667,
                "human_score": 5.0
            }
        }
    },
    {
        "filename": "Generating_Diverse_Hypotheses_for_Inductive_Reasoning__p7__score0.70.png",
        "Total_Impact": -0.013521,
        "details": {
            "Informativeness": {
                "impact": -0.007483,
                "llm_score": 3.0,
                "human_score": 2.0
            },
            "Overall Readability": {
                "impact": -0.002767,
                "llm_score": 4.0,
                "human_score": 3.0
            },
            "Creativity": {
                "impact": -0.002516,
                "llm_score": 3.333,
                "human_score": 2.0
            },
            "Design Quality": {
                "impact": -0.002612,
                "llm_score": 3.714,
                "human_score": 4.0
            },
            "Fidelity": {
                "impact": 0.001858,
                "llm_score": 4.667,
                "human_score": 5.0
            }
        }
    },
    {
        "filename": "LLMs_Trust_Humans_More_That_s_a_Problem_Unveiling_and_Mitigating_the_Authority_Bias_in_Retrieval-Augmented_Generation__p4__score1.00.png",
        "Total_Impact": -0.012766,
        "details": {
            "Informativeness": {
                "impact": 0.000818,
                "llm_score": 2.333,
                "human_score": 3.0
            },
            "Overall Readability": {
                "impact": -0.00671,
                "llm_score": 2.0,
                "human_score": 4.0
            },
            "Creativity": {
                "impact": -0.000364,
                "llm_score": 2.667,
                "human_score": 3.0
            },
            "Design Quality": {
                "impact": -0.000198,
                "llm_score": 4.143,
                "human_score": 5.0
            },
            "Fidelity": {
                "impact": -0.006313,
                "llm_score": 2.667,
                "human_score": 5.0
            }
        }
    },
    {
        "filename": "Making_Long-Context_Language_Models_Better_Multi-Hop_Reasoners__p3__score1.00.png",
        "Total_Impact": -0.012433,
        "details": {
            "Informativeness": {
                "impact": 0.005306,
                "llm_score": 2.0,
                "human_score": 2.0
            },
            "Overall Readability": {
                "impact": -0.006984,
                "llm_score": 4.0,
                "human_score": 2.0
            },
            "Creativity": {
                "impact": 0.00631,
                "llm_score": 2.333,
                "human_score": 2.0
            },
            "Design Quality": {
                "impact": -0.008557,
                "llm_score": 4.429,
                "human_score": 2.0
            },
            "Fidelity": {
                "impact": -0.008508,
                "llm_score": 5.0,
                "human_score": 3.0
            }
        }
    },
    {
        "filename": "Locating_and_Extracting_Relational_Concepts_in_Large_Language_Models__p3__score1.00.png",
        "Total_Impact": -0.012415,
        "details": {
            "Informativeness": {
                "impact": -0.010781,
                "llm_score": 2.0,
                "human_score": 5.0
            },
            "Overall Readability": {
                "impact": 0.003674,
                "llm_score": 4.0,
                "human_score": 5.0
            },
            "Creativity": {
                "impact": -0.005586,
                "llm_score": 2.667,
                "human_score": 4.0
            },
            "Design Quality": {
                "impact": -0.00158,
                "llm_score": 3.857,
                "human_score": 4.0
            },
            "Fidelity": {
                "impact": 0.001858,
                "llm_score": 4.667,
                "human_score": 5.0
            }
        }
    },
    {
        "filename": "Mind_the_Value-Action_Gap_Do_LLMs_Act_in_Alignment_with_Their_Values__p1__score1.00.png",
        "Total_Impact": -0.012047,
        "details": {
            "Informativeness": {
                "impact": 0.006417,
                "llm_score": 3.333,
                "human_score": 5.0
            },
            "Overall Readability": {
                "impact": -0.00387,
                "llm_score": 3.333,
                "human_score": 5.0
            },
            "Creativity": {
                "impact": -0.00978,
                "llm_score": 2.333,
                "human_score": 4.0
            },
            "Design Quality": {
                "impact": 9e-05,
                "llm_score": 4.143,
                "human_score": 4.0
            },
            "Fidelity": {
                "impact": -0.004905,
                "llm_score": 3.0,
                "human_score": 5.0
            }
        }
    },
    {
        "filename": "When_Not_to_Trust_Language_Models_Investigating_Effectiveness_of_Parametric_and_Non-Parametric_Memories__p2__score1.00.png",
        "Total_Impact": -0.011944,
        "details": {
            "Informativeness": {
                "impact": 0.001517,
                "llm_score": 2.0,
                "human_score": 3.0
            },
            "Overall Readability": {
                "impact": 8.9e-05,
                "llm_score": 3.667,
                "human_score": 4.0
            },
            "Creativity": {
                "impact": -0.005586,
                "llm_score": 2.667,
                "human_score": 4.0
            },
            "Design Quality": {
                "impact": 0.001252,
                "llm_score": 4.429,
                "human_score": 4.0
            },
            "Fidelity": {
                "impact": -0.009216,
                "llm_score": 2.0,
                "human_score": 5.0
            }
        }
    },
    {
        "filename": "Locating_and_Extracting_Relational_Concepts_in_Large_Language_Models__p6__score0.97.png",
        "Total_Impact": -0.011701,
        "details": {
            "Informativeness": {
                "impact": -0.010781,
                "llm_score": 2.0,
                "human_score": 5.0
            },
            "Overall Readability": {
                "impact": 0.003674,
                "llm_score": 4.0,
                "human_score": 5.0
            },
            "Creativity": {
                "impact": -0.004928,
                "llm_score": 3.0,
                "human_score": 5.0
            },
            "Design Quality": {
                "impact": -0.000198,
                "llm_score": 4.143,
                "human_score": 5.0
            },
            "Fidelity": {
                "impact": 0.000531,
                "llm_score": 4.333,
                "human_score": 5.0
            }
        }
    },
    {
        "filename": "Express_Uncertainty__p0__score0.80.png",
        "Total_Impact": -0.011609,
        "details": {
            "Informativeness": {
                "impact": 0.001644,
                "llm_score": 2.333,
                "human_score": 2.0
            },
            "Overall Readability": {
                "impact": -0.000474,
                "llm_score": 3.667,
                "human_score": 3.0
            },
            "Creativity": {
                "impact": 0.000895,
                "llm_score": 3.0,
                "human_score": 2.0
            },
            "Design Quality": {
                "impact": -0.012172,
                "llm_score": 4.571,
                "human_score": 2.0
            },
            "Fidelity": {
                "impact": -0.001502,
                "llm_score": 4.667,
                "human_score": 4.0
            }
        }
    },
    {
        "filename": "Learning_from_Diverse_Reasoning_Paths_with_Routing_and_Collaboration__p2__score0.95.png",
        "Total_Impact": -0.010445,
        "details": {
            "Informativeness": {
                "impact": 0.001612,
                "llm_score": 1.667,
                "human_score": 3.0
            },
            "Overall Readability": {
                "impact": -0.000474,
                "llm_score": 3.667,
                "human_score": 3.0
            },
            "Creativity": {
                "impact": -0.00122,
                "llm_score": 2.333,
                "human_score": 3.0
            },
            "Design Quality": {
                "impact": -0.002612,
                "llm_score": 3.714,
                "human_score": 4.0
            },
            "Fidelity": {
                "impact": -0.007751,
                "llm_score": 2.333,
                "human_score": 5.0
            }
        }
    },
    {
        "filename": "VISTA_Visualized_Text_Embedding_For_Universal_Multi-Modal_Retrieval__p2__score1.00.png",
        "Total_Impact": -0.00917,
        "details": {
            "Informativeness": {
                "impact": -0.000966,
                "llm_score": 2.667,
                "human_score": 5.0
            },
            "Overall Readability": {
                "impact": 0.003674,
                "llm_score": 4.0,
                "human_score": 5.0
            },
            "Creativity": {
                "impact": -0.006438,
                "llm_score": 3.667,
                "human_score": 2.0
            },
            "Design Quality": {
                "impact": -0.00041,
                "llm_score": 4.143,
                "human_score": 3.0
            },
            "Fidelity": {
                "impact": -0.00503,
                "llm_score": 4.667,
                "human_score": 3.0
            }
        }
    },
    {
        "filename": "of_Multimodal_Large_Language_Models_Multimodal_Needle_in_a_Haystack_Benchmarking_Long-Context_Capability__p1__score1.00.png",
        "Total_Impact": -0.008961,
        "details": {
            "Informativeness": {
                "impact": 0.001342,
                "llm_score": 3.667,
                "human_score": 4.0
            },
            "Overall Readability": {
                "impact": -0.002767,
                "llm_score": 4.0,
                "human_score": 3.0
            },
            "Creativity": {
                "impact": -0.00013,
                "llm_score": 3.333,
                "human_score": 3.0
            },
            "Design Quality": {
                "impact": -0.004836,
                "llm_score": 4.571,
                "human_score": 3.0
            },
            "Fidelity": {
                "impact": -0.00257,
                "llm_score": 5.0,
                "human_score": 4.0
            }
        }
    },
    {
        "filename": "MASTER_A_Multi-Agent_System_with_LLM_Specialized_MCTS__p2__score1.00.png",
        "Total_Impact": -0.008943,
        "details": {
            "Informativeness": {
                "impact": 0.001093,
                "llm_score": 3.0,
                "human_score": 4.0
            },
            "Overall Readability": {
                "impact": -0.001687,
                "llm_score": 3.667,
                "human_score": 2.0
            },
            "Creativity": {
                "impact": -0.006438,
                "llm_score": 3.667,
                "human_score": 2.0
            },
            "Design Quality": {
                "impact": -0.00041,
                "llm_score": 4.143,
                "human_score": 3.0
            },
            "Fidelity": {
                "impact": -0.001502,
                "llm_score": 4.667,
                "human_score": 4.0
            }
        }
    },
    {
        "filename": "MARVEL_Unlocking_the_Multi-Modal_Capability_of_Dense_Retrieval_via_Visual_Module_Plugin__p0__score1.00.png",
        "Total_Impact": -0.008691,
        "details": {
            "Informativeness": {
                "impact": -0.007483,
                "llm_score": 3.0,
                "human_score": 2.0
            },
            "Overall Readability": {
                "impact": 0.003674,
                "llm_score": 4.0,
                "human_score": 5.0
            },
            "Creativity": {
                "impact": -0.006438,
                "llm_score": 3.667,
                "human_score": 2.0
            },
            "Design Quality": {
                "impact": -0.002612,
                "llm_score": 3.714,
                "human_score": 4.0
            },
            "Fidelity": {
                "impact": 0.004169,
                "llm_score": 4.0,
                "human_score": 1.0
            }
        }
    },
    {
        "filename": "On_LLM-Based_Scientific_Inductive_Reasoning_Beyond_Equations__p6__score1.00.png",
        "Total_Impact": -0.008631,
        "details": {
            "Informativeness": {
                "impact": -0.005565,
                "llm_score": 2.333,
                "human_score": 5.0
            },
            "Overall Readability": {
                "impact": -0.002767,
                "llm_score": 4.0,
                "human_score": 3.0
            },
            "Creativity": {
                "impact": -0.000364,
                "llm_score": 2.667,
                "human_score": 3.0
            },
            "Design Quality": {
                "impact": 0.004971,
                "llm_score": 4.429,
                "human_score": 5.0
            },
            "Fidelity": {
                "impact": -0.004905,
                "llm_score": 3.0,
                "human_score": 5.0
            }
        }
    },
    {
        "filename": "R-VLM_Region-Aware_Vision_Language_Model_for_Precise_GUI_Grounding__p1__score1.00.png",
        "Total_Impact": -0.008589,
        "details": {
            "Informativeness": {
                "impact": 6.3e-05,
                "llm_score": 2.667,
                "human_score": 4.0
            },
            "Overall Readability": {
                "impact": 0.000766,
                "llm_score": 4.0,
                "human_score": 4.0
            },
            "Creativity": {
                "impact": -0.006438,
                "llm_score": 3.667,
                "human_score": 2.0
            },
            "Design Quality": {
                "impact": -0.00041,
                "llm_score": 4.143,
                "human_score": 3.0
            },
            "Fidelity": {
                "impact": -0.00257,
                "llm_score": 5.0,
                "human_score": 4.0
            }
        }
    },
    {
        "filename": "Blinded_by_Generated_Contexts_How_Language_Models_Merge_Generated_and_Retrieved_Contexts_When_Knowledge_Conflicts__p2__score0.95.png",
        "Total_Impact": -0.008567,
        "details": {
            "Informativeness": {
                "impact": 6.3e-05,
                "llm_score": 2.667,
                "human_score": 4.0
            },
            "Overall Readability": {
                "impact": -0.012533,
                "llm_score": 4.333,
                "human_score": 2.0
            },
            "Creativity": {
                "impact": -5e-06,
                "llm_score": 3.0,
                "human_score": 3.0
            },
            "Design Quality": {
                "impact": 0.000734,
                "llm_score": 4.286,
                "human_score": 4.0
            },
            "Fidelity": {
                "impact": 0.003173,
                "llm_score": 5.0,
                "human_score": 5.0
            }
        }
    },
    {
        "filename": "ZoomEye_Enhancing_Multimodal_LLMs_with_Human-Like_Zooming_Capabilities_through_Tree-Based_Image_Exploration__p3__score0.95.png",
        "Total_Impact": -0.008304,
        "details": {
            "Informativeness": {
                "impact": -0.006699,
                "llm_score": 1.667,
                "human_score": 4.0
            },
            "Overall Readability": {
                "impact": -0.002767,
                "llm_score": 4.0,
                "human_score": 3.0
            },
            "Creativity": {
                "impact": -0.000743,
                "llm_score": 3.667,
                "human_score": 3.0
            },
            "Design Quality": {
                "impact": -0.001756,
                "llm_score": 4.286,
                "human_score": 3.0
            },
            "Fidelity": {
                "impact": 0.003661,
                "llm_score": 3.0,
                "human_score": 4.0
            }
        }
    },
    {
        "filename": "Fooling_the_LVLM_Judges_Visual_Biases_in_LVLM-Based_Evaluation_3.5_4.1__p0__score0.95.png",
        "Total_Impact": -0.00821,
        "details": {
            "Informativeness": {
                "impact": -0.001574,
                "llm_score": 2.333,
                "human_score": 4.0
            },
            "Overall Readability": {
                "impact": -0.00387,
                "llm_score": 3.333,
                "human_score": 5.0
            },
            "Creativity": {
                "impact": -0.005586,
                "llm_score": 2.667,
                "human_score": 4.0
            },
            "Design Quality": {
                "impact": 0.004971,
                "llm_score": 4.429,
                "human_score": 5.0
            },
            "Fidelity": {
                "impact": -0.002151,
                "llm_score": 3.667,
                "human_score": 5.0
            }
        }
    },
    {
        "filename": "Fooling_the_LVLM_Judges_Visual_Biases_in_LVLM-Based_Evaluation_3.5_4.1__p2__score0.60.png",
        "Total_Impact": -0.007578,
        "details": {
            "Informativeness": {
                "impact": -0.00382,
                "llm_score": 2.0,
                "human_score": 4.0
            },
            "Overall Readability": {
                "impact": 0.001229,
                "llm_score": 4.333,
                "human_score": 4.0
            },
            "Creativity": {
                "impact": -0.00978,
                "llm_score": 2.333,
                "human_score": 4.0
            },
            "Design Quality": {
                "impact": 0.007363,
                "llm_score": 4.571,
                "human_score": 5.0
            },
            "Fidelity": {
                "impact": -0.00257,
                "llm_score": 5.0,
                "human_score": 4.0
            }
        }
    },
    {
        "filename": "Less_is_More_Mitigating_Multimodal_Hallucination_from_an_EOS_Decision_Perspective__p0__score0.60.png",
        "Total_Impact": -0.007443,
        "details": {
            "Informativeness": {
                "impact": -0.006699,
                "llm_score": 1.667,
                "human_score": 4.0
            },
            "Overall Readability": {
                "impact": -0.007979,
                "llm_score": 3.0,
                "human_score": 5.0
            },
            "Creativity": {
                "impact": 0.001227,
                "llm_score": 3.333,
                "human_score": 4.0
            },
            "Design Quality": {
                "impact": -0.000681,
                "llm_score": 4.0,
                "human_score": 4.0
            },
            "Fidelity": {
                "impact": 0.006689,
                "llm_score": 2.0,
                "human_score": 4.0
            }
        }
    },
    {
        "filename": "IHEval_Evaluating_Language_Models_on_Following_the_Instruction_Hierarchy__p1__score1.00.png",
        "Total_Impact": -0.007367,
        "details": {
            "Informativeness": {
                "impact": 0.001093,
                "llm_score": 3.0,
                "human_score": 4.0
            },
            "Overall Readability": {
                "impact": -0.012533,
                "llm_score": 4.333,
                "human_score": 2.0
            },
            "Creativity": {
                "impact": -0.000743,
                "llm_score": 3.667,
                "human_score": 3.0
            },
            "Design Quality": {
                "impact": 0.001642,
                "llm_score": 4.571,
                "human_score": 4.0
            },
            "Fidelity": {
                "impact": 0.003173,
                "llm_score": 5.0,
                "human_score": 5.0
            }
        }
    },
    {
        "filename": "Spiral_of_Silence_How_is_Large_Language_Model_Killing_Information_Retrieval_A_Case_Study_on_Open_Domain_Question_Answering__p0__score1.00.png",
        "Total_Impact": -0.00727,
        "details": {
            "Informativeness": {
                "impact": 0.000818,
                "llm_score": 2.333,
                "human_score": 3.0
            },
            "Overall Readability": {
                "impact": 8.9e-05,
                "llm_score": 3.667,
                "human_score": 4.0
            },
            "Creativity": {
                "impact": -0.004928,
                "llm_score": 3.0,
                "human_score": 5.0
            },
            "Design Quality": {
                "impact": -0.00378,
                "llm_score": 3.571,
                "human_score": 4.0
            },
            "Fidelity": {
                "impact": 0.000531,
                "llm_score": 4.333,
                "human_score": 5.0
            }
        }
    },
    {
        "filename": "When_Not_to_Trust_Language_Models_Investigating_Effectiveness_of_Parametric_and_Non-Parametric_Memories__p0__score0.70.png",
        "Total_Impact": -0.006922,
        "details": {
            "Informativeness": {
                "impact": 0.000818,
                "llm_score": 2.333,
                "human_score": 3.0
            },
            "Overall Readability": {
                "impact": -0.002767,
                "llm_score": 4.0,
                "human_score": 3.0
            },
            "Creativity": {
                "impact": -0.006438,
                "llm_score": 3.667,
                "human_score": 2.0
            },
            "Design Quality": {
                "impact": -0.001707,
                "llm_score": 4.143,
                "human_score": 2.0
            },
            "Fidelity": {
                "impact": 0.003173,
                "llm_score": 5.0,
                "human_score": 5.0
            }
        }
    },
    {
        "filename": "Blinded_by_Generated_Contexts_How_Language_Models_Merge_Generated_and_Retrieved_Contexts_When_Knowledge_Conflicts__p2__score1.00.png",
        "Total_Impact": -0.006854,
        "details": {
            "Informativeness": {
                "impact": 6.3e-05,
                "llm_score": 2.667,
                "human_score": 4.0
            },
            "Overall Readability": {
                "impact": -0.012533,
                "llm_score": 4.333,
                "human_score": 2.0
            },
            "Creativity": {
                "impact": -5e-06,
                "llm_score": 3.0,
                "human_score": 3.0
            },
            "Design Quality": {
                "impact": 0.002447,
                "llm_score": 4.286,
                "human_score": 5.0
            },
            "Fidelity": {
                "impact": 0.003173,
                "llm_score": 5.0,
                "human_score": 5.0
            }
        }
    },
    {
        "filename": "LINC_A_Neurosymbolic_Approach_for_Logical_Reasoning_by_Combining_Language_Models_with_First-Order_Logic_Provers__p3__score0.98.png",
        "Total_Impact": -0.006582,
        "details": {
            "Informativeness": {
                "impact": -0.00262,
                "llm_score": 2.667,
                "human_score": 2.0
            },
            "Overall Readability": {
                "impact": -0.005293,
                "llm_score": 4.333,
                "human_score": 3.0
            },
            "Creativity": {
                "impact": -0.001932,
                "llm_score": 3.0,
                "human_score": 4.0
            },
            "Design Quality": {
                "impact": 9e-05,
                "llm_score": 4.143,
                "human_score": 4.0
            },
            "Fidelity": {
                "impact": 0.003173,
                "llm_score": 5.0,
                "human_score": 5.0
            }
        }
    },
    {
        "filename": "LINC_A_Neurosymbolic_Approach_for_Logical_Reasoning_by_Combining_Language_Models_with_First-Order_Logic_Provers__p3__score1.00.png",
        "Total_Impact": -0.006582,
        "details": {
            "Informativeness": {
                "impact": -0.00262,
                "llm_score": 2.667,
                "human_score": 2.0
            },
            "Overall Readability": {
                "impact": -0.005293,
                "llm_score": 4.333,
                "human_score": 3.0
            },
            "Creativity": {
                "impact": -0.001932,
                "llm_score": 3.0,
                "human_score": 4.0
            },
            "Design Quality": {
                "impact": 9e-05,
                "llm_score": 4.143,
                "human_score": 4.0
            },
            "Fidelity": {
                "impact": 0.003173,
                "llm_score": 5.0,
                "human_score": 5.0
            }
        }
    },
    {
        "filename": "DRAGIN_Dynamic_Retrieval_Augmented_Generation_based_on_the_Information_Needs_of_Large_Language_Models__p5__score0.60.png",
        "Total_Impact": -0.006576,
        "details": {
            "Informativeness": {
                "impact": -0.00239,
                "llm_score": 3.0,
                "human_score": 3.0
            },
            "Overall Readability": {
                "impact": -0.000807,
                "llm_score": 3.333,
                "human_score": 4.0
            },
            "Creativity": {
                "impact": -0.00013,
                "llm_score": 3.333,
                "human_score": 3.0
            },
            "Design Quality": {
                "impact": -0.00378,
                "llm_score": 3.571,
                "human_score": 4.0
            },
            "Fidelity": {
                "impact": 0.000531,
                "llm_score": 4.333,
                "human_score": 5.0
            }
        }
    },
    {
        "filename": "Weakly_Supervised_Semantic_Parsing_with_Execution-based_Spurious_Program_Filtering__p0__score0.80.png",
        "Total_Impact": -0.006537,
        "details": {
            "Informativeness": {
                "impact": 0.008391,
                "llm_score": 1.667,
                "human_score": 2.0
            },
            "Overall Readability": {
                "impact": 0.008283,
                "llm_score": 3.0,
                "human_score": 2.0
            },
            "Creativity": {
                "impact": 0.00383,
                "llm_score": 2.667,
                "human_score": 2.0
            },
            "Design Quality": {
                "impact": -0.016325,
                "llm_score": 2.571,
                "human_score": 4.0
            },
            "Fidelity": {
                "impact": -0.010716,
                "llm_score": 1.667,
                "human_score": 5.0
            }
        }
    },
    {
        "filename": "Self-Knowledge_Guided_Retrieval_Augmentation_for_Large_Language_Models__p3__score1.00.png",
        "Total_Impact": -0.006225,
        "details": {
            "Informativeness": {
                "impact": 0.001517,
                "llm_score": 2.0,
                "human_score": 3.0
            },
            "Overall Readability": {
                "impact": 8.9e-05,
                "llm_score": 3.667,
                "human_score": 4.0
            },
            "Creativity": {
                "impact": -0.00978,
                "llm_score": 2.333,
                "human_score": 4.0
            },
            "Design Quality": {
                "impact": 9e-05,
                "llm_score": 4.143,
                "human_score": 4.0
            },
            "Fidelity": {
                "impact": 0.001858,
                "llm_score": 4.667,
                "human_score": 5.0
            }
        }
    },
    {
        "filename": "How_Johnny_Can_Persuade_LLMs_to_Jailbreak_Them_Rethinking_Persuasion_to_Challenge_AI_Safety_by_Humanizing_LLMs__p0__score0.95.png",
        "Total_Impact": -0.006161,
        "details": {
            "Informativeness": {
                "impact": -0.00239,
                "llm_score": 3.0,
                "human_score": 3.0
            },
            "Overall Readability": {
                "impact": -0.007979,
                "llm_score": 3.0,
                "human_score": 5.0
            },
            "Creativity": {
                "impact": 0.003919,
                "llm_score": 3.667,
                "human_score": 4.0
            },
            "Design Quality": {
                "impact": 0.000734,
                "llm_score": 4.286,
                "human_score": 4.0
            },
            "Fidelity": {
                "impact": -0.000445,
                "llm_score": 4.333,
                "human_score": 4.0
            }
        }
    },
    {
        "filename": "Can_You_Trick_the_Grader_Adversarial_Persuasion_of_LLM_Judges__p0__score0.90.png",
        "Total_Impact": -0.005863,
        "details": {
            "Informativeness": {
                "impact": 0.001644,
                "llm_score": 2.333,
                "human_score": 2.0
            },
            "Overall Readability": {
                "impact": -0.002767,
                "llm_score": 4.0,
                "human_score": 3.0
            },
            "Creativity": {
                "impact": -5e-06,
                "llm_score": 3.0,
                "human_score": 3.0
            },
            "Design Quality": {
                "impact": -0.003234,
                "llm_score": 4.429,
                "human_score": 3.0
            },
            "Fidelity": {
                "impact": -0.001502,
                "llm_score": 4.667,
                "human_score": 4.0
            }
        }
    },
    {
        "filename": "Language_Models_as_Inductive_Reasoners__p4__score1.00.png",
        "Total_Impact": -0.005788,
        "details": {
            "Informativeness": {
                "impact": 0.001093,
                "llm_score": 3.0,
                "human_score": 4.0
            },
            "Overall Readability": {
                "impact": -0.00486,
                "llm_score": 2.333,
                "human_score": 4.0
            },
            "Creativity": {
                "impact": 0.000765,
                "llm_score": 3.0,
                "human_score": 1.0
            },
            "Design Quality": {
                "impact": 0.000734,
                "llm_score": 4.286,
                "human_score": 4.0
            },
            "Fidelity": {
                "impact": -0.00352,
                "llm_score": 3.333,
                "human_score": 5.0
            }
        }
    },
    {
        "filename": "Mind_the_Value-Action_Gap_Do_LLMs_Act_in_Alignment_with_Their_Values__p0__score0.95.png",
        "Total_Impact": -0.005754,
        "details": {
            "Informativeness": {
                "impact": 0.000818,
                "llm_score": 2.333,
                "human_score": 3.0
            },
            "Overall Readability": {
                "impact": -0.000807,
                "llm_score": 3.333,
                "human_score": 4.0
            },
            "Creativity": {
                "impact": 0.000895,
                "llm_score": 3.0,
                "human_score": 2.0
            },
            "Design Quality": {
                "impact": -0.001756,
                "llm_score": 4.286,
                "human_score": 3.0
            },
            "Fidelity": {
                "impact": -0.004905,
                "llm_score": 3.0,
                "human_score": 5.0
            }
        }
    },
    {
        "filename": "Cross-Lingual_Retrieval_Augmented_Prompt_for_Low-Resource_Languages__p0__score1.00.png",
        "Total_Impact": -0.005536,
        "details": {
            "Informativeness": {
                "impact": -0.007483,
                "llm_score": 3.0,
                "human_score": 2.0
            },
            "Overall Readability": {
                "impact": 0.003674,
                "llm_score": 4.0,
                "human_score": 5.0
            },
            "Creativity": {
                "impact": -0.001932,
                "llm_score": 3.0,
                "human_score": 4.0
            },
            "Design Quality": {
                "impact": -0.002969,
                "llm_score": 4.0,
                "human_score": 5.0
            },
            "Fidelity": {
                "impact": 0.003173,
                "llm_score": 5.0,
                "human_score": 5.0
            }
        }
    },
    {
        "filename": "Don_t_Forget_Your_ABC_s_Evaluating_the_State-of-the-Art_in_Chat-Oriented_Dialogue_Systems__p4__score0.70.png",
        "Total_Impact": -0.005521,
        "details": {
            "Informativeness": {
                "impact": -0.00382,
                "llm_score": 2.0,
                "human_score": 4.0
            },
            "Overall Readability": {
                "impact": -0.002767,
                "llm_score": 4.0,
                "human_score": 3.0
            },
            "Creativity": {
                "impact": 0.012902,
                "llm_score": 2.333,
                "human_score": 1.0
            },
            "Design Quality": {
                "impact": -0.009266,
                "llm_score": 4.286,
                "human_score": 1.0
            },
            "Fidelity": {
                "impact": -0.00257,
                "llm_score": 5.0,
                "human_score": 4.0
            }
        }
    },
    {
        "filename": "In_Prospect_and_Retrospect_Re_ective_Memory_Management_for_Long-term_Personalized_Dialogue_Agents__p4__score1.00.png",
        "Total_Impact": -0.005341,
        "details": {
            "Informativeness": {
                "impact": -0.00382,
                "llm_score": 2.0,
                "human_score": 4.0
            },
            "Overall Readability": {
                "impact": 0.000766,
                "llm_score": 4.0,
                "human_score": 4.0
            },
            "Creativity": {
                "impact": -0.001932,
                "llm_score": 3.0,
                "human_score": 4.0
            },
            "Design Quality": {
                "impact": 9e-05,
                "llm_score": 4.143,
                "human_score": 4.0
            },
            "Fidelity": {
                "impact": -0.000445,
                "llm_score": 4.333,
                "human_score": 4.0
            }
        }
    },
    {
        "filename": "Machine_Unlearning_of_Pre-trained_Large_Language_Models__p1__score1.00.png",
        "Total_Impact": -0.005179,
        "details": {
            "Informativeness": {
                "impact": 0.001093,
                "llm_score": 3.0,
                "human_score": 4.0
            },
            "Overall Readability": {
                "impact": 1.6e-05,
                "llm_score": 3.667,
                "human_score": 5.0
            },
            "Creativity": {
                "impact": -0.006438,
                "llm_score": 3.667,
                "human_score": 2.0
            },
            "Design Quality": {
                "impact": -0.001707,
                "llm_score": 4.143,
                "human_score": 2.0
            },
            "Fidelity": {
                "impact": 0.001858,
                "llm_score": 4.667,
                "human_score": 5.0
            }
        }
    },
    {
        "filename": "WebEvolver_Enhancing_Web_Agent_Self-Improvement_with_Co-evolving_World_Model__p0__score1.00.png",
        "Total_Impact": -0.005006,
        "details": {
            "Informativeness": {
                "impact": -0.00239,
                "llm_score": 3.0,
                "human_score": 3.0
            },
            "Overall Readability": {
                "impact": 8.9e-05,
                "llm_score": 3.667,
                "human_score": 4.0
            },
            "Creativity": {
                "impact": -5e-06,
                "llm_score": 3.0,
                "human_score": 3.0
            },
            "Design Quality": {
                "impact": -0.005873,
                "llm_score": 3.857,
                "human_score": 5.0
            },
            "Fidelity": {
                "impact": 0.003173,
                "llm_score": 5.0,
                "human_score": 5.0
            }
        }
    },
    {
        "filename": "IHEval_Evaluating_Language_Models_on_Following_the_Instruction_Hierarchy__p3__score1.00.png",
        "Total_Impact": -0.004821,
        "details": {
            "Informativeness": {
                "impact": 0.006417,
                "llm_score": 3.333,
                "human_score": 5.0
            },
            "Overall Readability": {
                "impact": -0.000474,
                "llm_score": 3.667,
                "human_score": 3.0
            },
            "Creativity": {
                "impact": -0.006438,
                "llm_score": 3.667,
                "human_score": 2.0
            },
            "Design Quality": {
                "impact": -0.001756,
                "llm_score": 4.286,
                "human_score": 3.0
            },
            "Fidelity": {
                "impact": -0.00257,
                "llm_score": 5.0,
                "human_score": 4.0
            }
        }
    },
    {
        "filename": "Error-driven_Data-efficient_Large_Multimodal_Model_Tuning__p3__score0.95.png",
        "Total_Impact": -0.004719,
        "details": {
            "Informativeness": {
                "impact": 6.3e-05,
                "llm_score": 2.667,
                "human_score": 4.0
            },
            "Overall Readability": {
                "impact": 0.003674,
                "llm_score": 4.0,
                "human_score": 5.0
            },
            "Creativity": {
                "impact": -0.011926,
                "llm_score": 2.667,
                "human_score": 5.0
            },
            "Design Quality": {
                "impact": 0.004971,
                "llm_score": 4.429,
                "human_score": 5.0
            },
            "Fidelity": {
                "impact": -0.001502,
                "llm_score": 4.667,
                "human_score": 4.0
            }
        }
    },
    {
        "filename": "Learning_from_Diverse_Reasoning_Paths_with_Routing_and_Collaboration__p3__score1.00.png",
        "Total_Impact": -0.004618,
        "details": {
            "Informativeness": {
                "impact": 0.001523,
                "llm_score": 3.333,
                "human_score": 4.0
            },
            "Overall Readability": {
                "impact": -0.007979,
                "llm_score": 3.0,
                "human_score": 5.0
            },
            "Creativity": {
                "impact": 0.003919,
                "llm_score": 3.667,
                "human_score": 4.0
            },
            "Design Quality": {
                "impact": -0.002612,
                "llm_score": 3.714,
                "human_score": 4.0
            },
            "Fidelity": {
                "impact": 0.000531,
                "llm_score": 4.333,
                "human_score": 5.0
            }
        }
    },
    {
        "filename": "Conditional_MASK_Discrete_Diffusion_Language_Model__p0__score1.00.png",
        "Total_Impact": -0.004597,
        "details": {
            "Informativeness": {
                "impact": 0.001644,
                "llm_score": 2.333,
                "human_score": 2.0
            },
            "Overall Readability": {
                "impact": -0.003266,
                "llm_score": 2.667,
                "human_score": 4.0
            },
            "Creativity": {
                "impact": -0.000743,
                "llm_score": 3.667,
                "human_score": 3.0
            },
            "Design Quality": {
                "impact": 0.00552,
                "llm_score": 3.143,
                "human_score": 3.0
            },
            "Fidelity": {
                "impact": -0.007751,
                "llm_score": 2.333,
                "human_score": 5.0
            }
        }
    },
    {
        "filename": "Beyond_Demographics_Fine-tuning_Large_Language_Models_to_Predict_Individuals_Subjective_Text_Perceptions__p0__score1.00.png",
        "Total_Impact": -0.004592,
        "details": {
            "Informativeness": {
                "impact": 0.000818,
                "llm_score": 2.333,
                "human_score": 3.0
            },
            "Overall Readability": {
                "impact": -0.006984,
                "llm_score": 4.0,
                "human_score": 2.0
            },
            "Creativity": {
                "impact": 0.00631,
                "llm_score": 2.333,
                "human_score": 2.0
            },
            "Design Quality": {
                "impact": -0.003234,
                "llm_score": 4.429,
                "human_score": 3.0
            },
            "Fidelity": {
                "impact": -0.001502,
                "llm_score": 4.667,
                "human_score": 4.0
            }
        }
    },
    {
        "filename": "Knowledge_Unlearning_for_Mitigating_Privacy_Risks_in_Language_Models__p1__score1.00.png",
        "Total_Impact": -0.00446,
        "details": {
            "Informativeness": {
                "impact": 0.001517,
                "llm_score": 2.0,
                "human_score": 3.0
            },
            "Overall Readability": {
                "impact": -0.002767,
                "llm_score": 4.0,
                "human_score": 3.0
            },
            "Creativity": {
                "impact": -5e-06,
                "llm_score": 3.0,
                "human_score": 3.0
            },
            "Design Quality": {
                "impact": -0.005063,
                "llm_score": 4.286,
                "human_score": 2.0
            },
            "Fidelity": {
                "impact": 0.001858,
                "llm_score": 4.667,
                "human_score": 5.0
            }
        }
    },
    {
        "filename": "Establishing_Trustworthy_LLM_Evaluation_via_Shortcut_Neuron_Analysis__p0__score0.95.png",
        "Total_Impact": -0.004437,
        "details": {
            "Informativeness": {
                "impact": 0.001085,
                "llm_score": 1.333,
                "human_score": 3.0
            },
            "Overall Readability": {
                "impact": 0.000766,
                "llm_score": 4.0,
                "human_score": 4.0
            },
            "Creativity": {
                "impact": -0.006438,
                "llm_score": 3.667,
                "human_score": 2.0
            },
            "Design Quality": {
                "impact": -0.001707,
                "llm_score": 4.143,
                "human_score": 2.0
            },
            "Fidelity": {
                "impact": 0.001858,
                "llm_score": 4.667,
                "human_score": 5.0
            }
        }
    },
    {
        "filename": "Carpe_Diem_On_the_Evaluation_of_World_Knowledge_in_Lifelong_Language_Models__p0__score0.95.png",
        "Total_Impact": -0.00413,
        "details": {
            "Informativeness": {
                "impact": 0.001093,
                "llm_score": 3.0,
                "human_score": 4.0
            },
            "Overall Readability": {
                "impact": 0.000766,
                "llm_score": 4.0,
                "human_score": 4.0
            },
            "Creativity": {
                "impact": -0.006438,
                "llm_score": 3.667,
                "human_score": 2.0
            },
            "Design Quality": {
                "impact": 0.001252,
                "llm_score": 4.429,
                "human_score": 4.0
            },
            "Fidelity": {
                "impact": -0.000803,
                "llm_score": 4.0,
                "human_score": 5.0
            }
        }
    },
    {
        "filename": "Carpe_Diem_On_the_Evaluation_of_World_Knowledge_in_Lifelong_Language_Models__p2__score1.00.png",
        "Total_Impact": -0.004022,
        "details": {
            "Informativeness": {
                "impact": 0.001093,
                "llm_score": 3.0,
                "human_score": 4.0
            },
            "Overall Readability": {
                "impact": -0.000807,
                "llm_score": 3.333,
                "human_score": 4.0
            },
            "Creativity": {
                "impact": 0.00383,
                "llm_score": 2.667,
                "human_score": 2.0
            },
            "Design Quality": {
                "impact": -0.003234,
                "llm_score": 4.429,
                "human_score": 3.0
            },
            "Fidelity": {
                "impact": -0.004905,
                "llm_score": 3.0,
                "human_score": 5.0
            }
        }
    },
    {
        "filename": "Improve_Vision_Language_Model_Chain-of-thought_Reasoning__p3__score0.95.png",
        "Total_Impact": -0.003932,
        "details": {
            "Informativeness": {
                "impact": 6.3e-05,
                "llm_score": 2.667,
                "human_score": 4.0
            },
            "Overall Readability": {
                "impact": -0.001921,
                "llm_score": 3.0,
                "human_score": 4.0
            },
            "Creativity": {
                "impact": -0.00122,
                "llm_score": 2.333,
                "human_score": 3.0
            },
            "Design Quality": {
                "impact": -0.00041,
                "llm_score": 4.143,
                "human_score": 3.0
            },
            "Fidelity": {
                "impact": -0.000445,
                "llm_score": 4.333,
                "human_score": 4.0
            }
        }
    },
    {
        "filename": "Visual_Evidence_Prompting_Mitigates_Hallucinations_in_Large_Vision-Language_Models__p3__score1.00.png",
        "Total_Impact": -0.003874,
        "details": {
            "Informativeness": {
                "impact": 0.001093,
                "llm_score": 3.0,
                "human_score": 4.0
            },
            "Overall Readability": {
                "impact": -0.002767,
                "llm_score": 4.0,
                "human_score": 3.0
            },
            "Creativity": {
                "impact": -0.000364,
                "llm_score": 2.667,
                "human_score": 3.0
            },
            "Design Quality": {
                "impact": 0.000734,
                "llm_score": 4.286,
                "human_score": 4.0
            },
            "Fidelity": {
                "impact": -0.00257,
                "llm_score": 5.0,
                "human_score": 4.0
            }
        }
    },
    {
        "filename": "To_Mask_or_to_Mirror_Human-AI_Alignment_in_Collective_Reasoning__p5__score1.00.png",
        "Total_Impact": -0.003612,
        "details": {
            "Informativeness": {
                "impact": -0.007483,
                "llm_score": 3.0,
                "human_score": 2.0
            },
            "Overall Readability": {
                "impact": 0.000766,
                "llm_score": 4.0,
                "human_score": 4.0
            },
            "Creativity": {
                "impact": -5e-06,
                "llm_score": 3.0,
                "human_score": 3.0
            },
            "Design Quality": {
                "impact": 0.001252,
                "llm_score": 4.429,
                "human_score": 4.0
            },
            "Fidelity": {
                "impact": 0.001858,
                "llm_score": 4.667,
                "human_score": 5.0
            }
        }
    },
    {
        "filename": "Active_Prompting_with_Chain-of-Thought_for_Large_Language_Models__p1__score1.00.png",
        "Total_Impact": -0.00331,
        "details": {
            "Informativeness": {
                "impact": 0.001093,
                "llm_score": 3.0,
                "human_score": 4.0
            },
            "Overall Readability": {
                "impact": 0.000766,
                "llm_score": 4.0,
                "human_score": 4.0
            },
            "Creativity": {
                "impact": 0.00383,
                "llm_score": 2.667,
                "human_score": 2.0
            },
            "Design Quality": {
                "impact": -0.012172,
                "llm_score": 4.571,
                "human_score": 2.0
            },
            "Fidelity": {
                "impact": 0.003173,
                "llm_score": 5.0,
                "human_score": 5.0
            }
        }
    },
    {
        "filename": "RAG-Instruct_Boosting_LLMs_with_Diverse_Retrieval-Augmented_Instructions__p3__score0.95.png",
        "Total_Impact": -0.003103,
        "details": {
            "Informativeness": {
                "impact": -0.012988,
                "llm_score": 3.333,
                "human_score": 2.0
            },
            "Overall Readability": {
                "impact": 0.003473,
                "llm_score": 3.0,
                "human_score": 3.0
            },
            "Creativity": {
                "impact": 0.003919,
                "llm_score": 3.667,
                "human_score": 4.0
            },
            "Design Quality": {
                "impact": -0.000681,
                "llm_score": 4.0,
                "human_score": 4.0
            },
            "Fidelity": {
                "impact": 0.003173,
                "llm_score": 5.0,
                "human_score": 5.0
            }
        }
    },
    {
        "filename": "How_Johnny_Can_Persuade_LLMs_to_Jailbreak_Them_Rethinking_Persuasion_to_Challenge_AI_Safety_by_Humanizing_LLMs__p1__score1.00.png",
        "Total_Impact": -0.003018,
        "details": {
            "Informativeness": {
                "impact": 0.001093,
                "llm_score": 3.0,
                "human_score": 4.0
            },
            "Overall Readability": {
                "impact": -0.000474,
                "llm_score": 3.667,
                "human_score": 3.0
            },
            "Creativity": {
                "impact": 0.000895,
                "llm_score": 3.0,
                "human_score": 2.0
            },
            "Design Quality": {
                "impact": -0.005063,
                "llm_score": 4.286,
                "human_score": 2.0
            },
            "Fidelity": {
                "impact": 0.000531,
                "llm_score": 4.333,
                "human_score": 5.0
            }
        }
    },
    {
        "filename": "ImageInWords_Unlocking_Hyper-Detailed_Image_Descriptions__p4__score0.90.png",
        "Total_Impact": -0.003008,
        "details": {
            "Informativeness": {
                "impact": 0.001523,
                "llm_score": 3.333,
                "human_score": 4.0
            },
            "Overall Readability": {
                "impact": -0.001921,
                "llm_score": 3.0,
                "human_score": 4.0
            },
            "Creativity": {
                "impact": -0.00013,
                "llm_score": 3.333,
                "human_score": 3.0
            },
            "Design Quality": {
                "impact": 9e-05,
                "llm_score": 4.143,
                "human_score": 4.0
            },
            "Fidelity": {
                "impact": -0.00257,
                "llm_score": 5.0,
                "human_score": 4.0
            }
        }
    },
    {
        "filename": "AKE_Assessing_Knowledge_Editing_in_Language_Models_via_Multi-Hop_Questions__p6__score1.00.png",
        "Total_Impact": -0.002658,
        "details": {
            "Informativeness": {
                "impact": -0.00262,
                "llm_score": 2.667,
                "human_score": 2.0
            },
            "Overall Readability": {
                "impact": 0.000766,
                "llm_score": 4.0,
                "human_score": 4.0
            },
            "Creativity": {
                "impact": -0.000743,
                "llm_score": 3.667,
                "human_score": 3.0
            },
            "Design Quality": {
                "impact": -0.003234,
                "llm_score": 4.429,
                "human_score": 3.0
            },
            "Fidelity": {
                "impact": 0.003173,
                "llm_score": 5.0,
                "human_score": 5.0
            }
        }
    },
    {
        "filename": "Progressive_Multimodal_Reasoning_via_Active_Retrieval__p3__score1.00.png",
        "Total_Impact": -0.002556,
        "details": {
            "Informativeness": {
                "impact": 0.005306,
                "llm_score": 2.0,
                "human_score": 2.0
            },
            "Overall Readability": {
                "impact": 0.000766,
                "llm_score": 4.0,
                "human_score": 4.0
            },
            "Creativity": {
                "impact": -0.000364,
                "llm_score": 2.667,
                "human_score": 3.0
            },
            "Design Quality": {
                "impact": -0.003234,
                "llm_score": 4.429,
                "human_score": 3.0
            },
            "Fidelity": {
                "impact": -0.00503,
                "llm_score": 4.667,
                "human_score": 3.0
            }
        }
    },
    {
        "filename": "Make_Every_Penny_Count_Difficulty-Adaptive_Self-Consistency_for_Cost-Efficient_Reasoning__p1__score1.00.png",
        "Total_Impact": -0.00245,
        "details": {
            "Informativeness": {
                "impact": 0.001085,
                "llm_score": 1.333,
                "human_score": 3.0
            },
            "Overall Readability": {
                "impact": -0.002767,
                "llm_score": 4.0,
                "human_score": 3.0
            },
            "Creativity": {
                "impact": 0.000895,
                "llm_score": 3.0,
                "human_score": 2.0
            },
            "Design Quality": {
                "impact": -0.004836,
                "llm_score": 4.571,
                "human_score": 3.0
            },
            "Fidelity": {
                "impact": 0.003173,
                "llm_score": 5.0,
                "human_score": 5.0
            }
        }
    },
    {
        "filename": "Sociodemographic_Persona_Prompts_Evaluation__p0__score0.95.png",
        "Total_Impact": -0.002405,
        "details": {
            "Informativeness": {
                "impact": 0.001342,
                "llm_score": 3.667,
                "human_score": 4.0
            },
            "Overall Readability": {
                "impact": 0.003674,
                "llm_score": 4.0,
                "human_score": 5.0
            },
            "Creativity": {
                "impact": -0.005586,
                "llm_score": 2.667,
                "human_score": 4.0
            },
            "Design Quality": {
                "impact": 0.000734,
                "llm_score": 4.286,
                "human_score": 4.0
            },
            "Fidelity": {
                "impact": -0.00257,
                "llm_score": 5.0,
                "human_score": 4.0
            }
        }
    },
    {
        "filename": "On_LLM-Based_Scientific_Inductive_Reasoning_Beyond_Equations__p4__score1.00.png",
        "Total_Impact": -0.00199,
        "details": {
            "Informativeness": {
                "impact": 0.003018,
                "llm_score": 3.0,
                "human_score": 5.0
            },
            "Overall Readability": {
                "impact": 8.9e-05,
                "llm_score": 3.667,
                "human_score": 4.0
            },
            "Creativity": {
                "impact": -0.011926,
                "llm_score": 2.667,
                "human_score": 5.0
            },
            "Design Quality": {
                "impact": 0.004971,
                "llm_score": 4.429,
                "human_score": 5.0
            },
            "Fidelity": {
                "impact": 0.001858,
                "llm_score": 4.667,
                "human_score": 5.0
            }
        }
    },
    {
        "filename": "MARVEL_Unlocking_the_Multi-Modal_Capability_of_Dense_Retrieval_via_Visual_Module_Plugin__p3__score1.00.png",
        "Total_Impact": -0.001896,
        "details": {
            "Informativeness": {
                "impact": 0.001093,
                "llm_score": 3.0,
                "human_score": 4.0
            },
            "Overall Readability": {
                "impact": -0.000807,
                "llm_score": 3.333,
                "human_score": 4.0
            },
            "Creativity": {
                "impact": -0.002516,
                "llm_score": 3.333,
                "human_score": 2.0
            },
            "Design Quality": {
                "impact": -0.000198,
                "llm_score": 4.143,
                "human_score": 5.0
            },
            "Fidelity": {
                "impact": 0.000531,
                "llm_score": 4.333,
                "human_score": 5.0
            }
        }
    },
    {
        "filename": "OVM_utcome-supervised_alue_odels_for_Planning_in_Mathematical_Reasoning__p2__score1.00.png",
        "Total_Impact": -0.001672,
        "details": {
            "Informativeness": {
                "impact": -0.000485,
                "llm_score": 2.667,
                "human_score": 3.0
            },
            "Overall Readability": {
                "impact": 0.000766,
                "llm_score": 4.0,
                "human_score": 4.0
            },
            "Creativity": {
                "impact": -0.004928,
                "llm_score": 3.0,
                "human_score": 5.0
            },
            "Design Quality": {
                "impact": -0.000198,
                "llm_score": 4.143,
                "human_score": 5.0
            },
            "Fidelity": {
                "impact": 0.003173,
                "llm_score": 5.0,
                "human_score": 5.0
            }
        }
    },
    {
        "filename": "LINC_A_Neurosymbolic_Approach_for_Logical_Reasoning_by_Combining_Language_Models_with_First-Order_Logic_Provers__p1__score1.00.png",
        "Total_Impact": -0.001572,
        "details": {
            "Informativeness": {
                "impact": 0.001342,
                "llm_score": 3.667,
                "human_score": 4.0
            },
            "Overall Readability": {
                "impact": 0.003674,
                "llm_score": 4.0,
                "human_score": 5.0
            },
            "Creativity": {
                "impact": -0.006438,
                "llm_score": 3.667,
                "human_score": 2.0
            },
            "Design Quality": {
                "impact": -0.000681,
                "llm_score": 4.0,
                "human_score": 4.0
            },
            "Fidelity": {
                "impact": 0.000531,
                "llm_score": 4.333,
                "human_score": 5.0
            }
        }
    },
    {
        "filename": "LINC_A_Neurosymbolic_Approach_for_Logical_Reasoning_by_Combining_Language_Models_with_First-Order_Logic_Provers__p1__score1.00__1.png",
        "Total_Impact": -0.001572,
        "details": {
            "Informativeness": {
                "impact": 0.001342,
                "llm_score": 3.667,
                "human_score": 4.0
            },
            "Overall Readability": {
                "impact": 0.003674,
                "llm_score": 4.0,
                "human_score": 5.0
            },
            "Creativity": {
                "impact": -0.006438,
                "llm_score": 3.667,
                "human_score": 2.0
            },
            "Design Quality": {
                "impact": -0.000681,
                "llm_score": 4.0,
                "human_score": 4.0
            },
            "Fidelity": {
                "impact": 0.000531,
                "llm_score": 4.333,
                "human_score": 5.0
            }
        }
    },
    {
        "filename": "Interpretable_Preferences_via_Multi-Objective_Reward_Modeling_and_Mixture-of-Experts__p1__score1.00.png",
        "Total_Impact": -0.001386,
        "details": {
            "Informativeness": {
                "impact": 0.001093,
                "llm_score": 3.0,
                "human_score": 4.0
            },
            "Overall Readability": {
                "impact": 1.6e-05,
                "llm_score": 3.667,
                "human_score": 5.0
            },
            "Creativity": {
                "impact": -0.000364,
                "llm_score": 2.667,
                "human_score": 3.0
            },
            "Design Quality": {
                "impact": 0.000734,
                "llm_score": 4.286,
                "human_score": 4.0
            },
            "Fidelity": {
                "impact": -0.002865,
                "llm_score": 4.333,
                "human_score": 2.0
            }
        }
    },
    {
        "filename": "Performance_Gap_in_Entity_Knowledge_Extraction_Across_Modalities_in_Vision_Language_Models__p1__score1.00.png",
        "Total_Impact": -0.001266,
        "details": {
            "Informativeness": {
                "impact": -0.006699,
                "llm_score": 1.667,
                "human_score": 4.0
            },
            "Overall Readability": {
                "impact": 0.013534,
                "llm_score": 5.0,
                "human_score": 5.0
            },
            "Creativity": {
                "impact": -0.006438,
                "llm_score": 3.667,
                "human_score": 2.0
            },
            "Design Quality": {
                "impact": -0.004836,
                "llm_score": 4.571,
                "human_score": 3.0
            },
            "Fidelity": {
                "impact": 0.003173,
                "llm_score": 5.0,
                "human_score": 5.0
            }
        }
    },
    {
        "filename": "Performance_Gap_in_Entity_Knowledge_Extraction_Across_Modalities_in_Vision_Language_Models__p2__score1.00.png",
        "Total_Impact": -0.001176,
        "details": {
            "Informativeness": {
                "impact": -0.000966,
                "llm_score": 2.667,
                "human_score": 5.0
            },
            "Overall Readability": {
                "impact": -0.000807,
                "llm_score": 3.333,
                "human_score": 4.0
            },
            "Creativity": {
                "impact": -0.000743,
                "llm_score": 3.667,
                "human_score": 3.0
            },
            "Design Quality": {
                "impact": 0.000809,
                "llm_score": 4.0,
                "human_score": 3.0
            },
            "Fidelity": {
                "impact": 0.000531,
                "llm_score": 4.333,
                "human_score": 5.0
            }
        }
    },
    {
        "filename": "How_Johnny_Can_Persuade_LLMs_to_Jailbreak_Them_Rethinking_Persuasion_to_Challenge_AI_Safety_by_Humanizing_LLMs__p2__score0.95.png",
        "Total_Impact": -0.001126,
        "details": {
            "Informativeness": {
                "impact": -0.00382,
                "llm_score": 2.0,
                "human_score": 4.0
            },
            "Overall Readability": {
                "impact": -0.005293,
                "llm_score": 4.333,
                "human_score": 3.0
            },
            "Creativity": {
                "impact": 0.009876,
                "llm_score": 1.667,
                "human_score": 2.0
            },
            "Design Quality": {
                "impact": -0.005063,
                "llm_score": 4.286,
                "human_score": 2.0
            },
            "Fidelity": {
                "impact": 0.003173,
                "llm_score": 5.0,
                "human_score": 5.0
            }
        }
    },
    {
        "filename": "Measuring_Chain_of_Thought_Faithfulness_by_Unlearning_Reasoning_Steps__p3__score1.00.png",
        "Total_Impact": -0.00075,
        "details": {
            "Informativeness": {
                "impact": -0.00239,
                "llm_score": 3.0,
                "human_score": 3.0
            },
            "Overall Readability": {
                "impact": 0.001229,
                "llm_score": 4.333,
                "human_score": 4.0
            },
            "Creativity": {
                "impact": 0.00383,
                "llm_score": 2.667,
                "human_score": 2.0
            },
            "Design Quality": {
                "impact": -0.006591,
                "llm_score": 4.714,
                "human_score": 3.0
            },
            "Fidelity": {
                "impact": 0.003173,
                "llm_score": 5.0,
                "human_score": 5.0
            }
        }
    },
    {
        "filename": "Mission_Impossible_Language_Models__p0__score0.95.png",
        "Total_Impact": -0.000611,
        "details": {
            "Informativeness": {
                "impact": -0.00382,
                "llm_score": 2.0,
                "human_score": 4.0
            },
            "Overall Readability": {
                "impact": 0.003674,
                "llm_score": 4.0,
                "human_score": 5.0
            },
            "Creativity": {
                "impact": -0.000743,
                "llm_score": 3.667,
                "human_score": 3.0
            },
            "Design Quality": {
                "impact": -0.00158,
                "llm_score": 3.857,
                "human_score": 4.0
            },
            "Fidelity": {
                "impact": 0.001858,
                "llm_score": 4.667,
                "human_score": 5.0
            }
        }
    },
    {
        "filename": "Error-driven_Data-efficient_Large_Multimodal_Model_Tuning__p2__score1.00.png",
        "Total_Impact": -0.000554,
        "details": {
            "Informativeness": {
                "impact": 0.001523,
                "llm_score": 3.333,
                "human_score": 4.0
            },
            "Overall Readability": {
                "impact": 0.003473,
                "llm_score": 3.0,
                "human_score": 3.0
            },
            "Creativity": {
                "impact": -0.005586,
                "llm_score": 2.667,
                "human_score": 4.0
            },
            "Design Quality": {
                "impact": -0.002612,
                "llm_score": 3.714,
                "human_score": 4.0
            },
            "Fidelity": {
                "impact": 0.002647,
                "llm_score": 3.333,
                "human_score": 4.0
            }
        }
    },
    {
        "filename": "ZoomEye_Enhancing_Multimodal_LLMs_with_Human-Like_Zooming_Capabilities_through_Tree-Based_Image_Exploration__p0__score1.00.png",
        "Total_Impact": -0.000514,
        "details": {
            "Informativeness": {
                "impact": -0.005565,
                "llm_score": 2.333,
                "human_score": 5.0
            },
            "Overall Readability": {
                "impact": -0.001921,
                "llm_score": 3.0,
                "human_score": 4.0
            },
            "Creativity": {
                "impact": 0.0079,
                "llm_score": 4.333,
                "human_score": 4.0
            },
            "Design Quality": {
                "impact": 0.001642,
                "llm_score": 4.571,
                "human_score": 4.0
            },
            "Fidelity": {
                "impact": -0.00257,
                "llm_score": 5.0,
                "human_score": 4.0
            }
        }
    },
    {
        "filename": "Establishing_Trustworthy_LLM_Evaluation_via_Shortcut_Neuron_Analysis__p3__score1.00.png",
        "Total_Impact": -0.000375,
        "details": {
            "Informativeness": {
                "impact": 0.001093,
                "llm_score": 3.0,
                "human_score": 4.0
            },
            "Overall Readability": {
                "impact": 0.001607,
                "llm_score": 3.333,
                "human_score": 3.0
            },
            "Creativity": {
                "impact": -0.000364,
                "llm_score": 2.667,
                "human_score": 3.0
            },
            "Design Quality": {
                "impact": 0.000809,
                "llm_score": 4.0,
                "human_score": 3.0
            },
            "Fidelity": {
                "impact": -0.00352,
                "llm_score": 3.333,
                "human_score": 5.0
            }
        }
    },
    {
        "filename": "Progressive_Multimodal_Reasoning_via_Active_Retrieval__p5__score1.00.png",
        "Total_Impact": -7.8e-05,
        "details": {
            "Informativeness": {
                "impact": 0.001517,
                "llm_score": 2.0,
                "human_score": 3.0
            },
            "Overall Readability": {
                "impact": -0.000474,
                "llm_score": 3.667,
                "human_score": 3.0
            },
            "Creativity": {
                "impact": -0.000364,
                "llm_score": 2.667,
                "human_score": 3.0
            },
            "Design Quality": {
                "impact": 0.000809,
                "llm_score": 4.0,
                "human_score": 3.0
            },
            "Fidelity": {
                "impact": -0.001566,
                "llm_score": 4.333,
                "human_score": 3.0
            }
        }
    },
    {
        "filename": "Mind_the_Value-Action_Gap_Do_LLMs_Act_in_Alignment_with_Their_Values__p3__score1.00.png",
        "Total_Impact": 0.000249,
        "details": {
            "Informativeness": {
                "impact": -0.00382,
                "llm_score": 2.0,
                "human_score": 4.0
            },
            "Overall Readability": {
                "impact": 0.007136,
                "llm_score": 4.333,
                "human_score": 5.0
            },
            "Creativity": {
                "impact": -0.000364,
                "llm_score": 2.667,
                "human_score": 3.0
            },
            "Design Quality": {
                "impact": -0.003234,
                "llm_score": 4.429,
                "human_score": 3.0
            },
            "Fidelity": {
                "impact": 0.000531,
                "llm_score": 4.333,
                "human_score": 5.0
            }
        }
    },
    {
        "filename": "LLMs_Trust_Humans_More_That_s_a_Problem_Unveiling_and_Mitigating_the_Authority_Bias_in_Retrieval-Augmented_Generation__p1__score1.00.png",
        "Total_Impact": 0.000299,
        "details": {
            "Informativeness": {
                "impact": 0.000818,
                "llm_score": 2.333,
                "human_score": 3.0
            },
            "Overall Readability": {
                "impact": 0.003473,
                "llm_score": 3.0,
                "human_score": 3.0
            },
            "Creativity": {
                "impact": -0.000743,
                "llm_score": 3.667,
                "human_score": 3.0
            },
            "Design Quality": {
                "impact": -0.00378,
                "llm_score": 3.571,
                "human_score": 4.0
            },
            "Fidelity": {
                "impact": 0.000531,
                "llm_score": 4.333,
                "human_score": 5.0
            }
        }
    },
    {
        "filename": "DiffusionBERT_Improving_Generative_Masked_Language_Models_with_Diffusion_Models__p0__score1.00.png",
        "Total_Impact": 0.000943,
        "details": {
            "Informativeness": {
                "impact": 0.007556,
                "llm_score": 2.0,
                "human_score": 1.0
            },
            "Overall Readability": {
                "impact": -0.002767,
                "llm_score": 4.0,
                "human_score": 3.0
            },
            "Creativity": {
                "impact": -0.006438,
                "llm_score": 3.667,
                "human_score": 2.0
            },
            "Design Quality": {
                "impact": 0.000734,
                "llm_score": 4.286,
                "human_score": 4.0
            },
            "Fidelity": {
                "impact": 0.001858,
                "llm_score": 4.667,
                "human_score": 5.0
            }
        }
    },
    {
        "filename": "AKE_Assessing_Knowledge_Editing_in_Language_Models_via_Multi-Hop_Questions__p0__score0.70.png",
        "Total_Impact": 0.00125,
        "details": {
            "Informativeness": {
                "impact": -0.00239,
                "llm_score": 3.0,
                "human_score": 3.0
            },
            "Overall Readability": {
                "impact": 1.6e-05,
                "llm_score": 3.667,
                "human_score": 5.0
            },
            "Creativity": {
                "impact": -0.002516,
                "llm_score": 3.333,
                "human_score": 2.0
            },
            "Design Quality": {
                "impact": 0.009661,
                "llm_score": 4.714,
                "human_score": 5.0
            },
            "Fidelity": {
                "impact": -0.00352,
                "llm_score": 3.333,
                "human_score": 5.0
            }
        }
    },
    {
        "filename": "Improve_Vision_Language_Model_Chain-of-thought_Reasoning__p1__score0.98.png",
        "Total_Impact": 0.001703,
        "details": {
            "Informativeness": {
                "impact": 0.001093,
                "llm_score": 3.0,
                "human_score": 4.0
            },
            "Overall Readability": {
                "impact": -0.001921,
                "llm_score": 3.0,
                "human_score": 4.0
            },
            "Creativity": {
                "impact": -0.000743,
                "llm_score": 3.667,
                "human_score": 3.0
            },
            "Design Quality": {
                "impact": 0.003719,
                "llm_score": 3.571,
                "human_score": 3.0
            },
            "Fidelity": {
                "impact": -0.000445,
                "llm_score": 4.333,
                "human_score": 4.0
            }
        }
    },
    {
        "filename": "CoPL_Collaborative_Preference_Learning_for_Personalizing_LLMs__p3__score1.00.png",
        "Total_Impact": 0.001705,
        "details": {
            "Informativeness": {
                "impact": 0.006417,
                "llm_score": 3.333,
                "human_score": 5.0
            },
            "Overall Readability": {
                "impact": 0.000766,
                "llm_score": 4.0,
                "human_score": 4.0
            },
            "Creativity": {
                "impact": -0.000743,
                "llm_score": 3.667,
                "human_score": 3.0
            },
            "Design Quality": {
                "impact": -0.003234,
                "llm_score": 4.429,
                "human_score": 3.0
            },
            "Fidelity": {
                "impact": -0.001502,
                "llm_score": 4.667,
                "human_score": 4.0
            }
        }
    },
    {
        "filename": "WebEvolver_Enhancing_Web_Agent_Self-Improvement_with_Co-evolving_World_Model__p2__score1.00.png",
        "Total_Impact": 0.001737,
        "details": {
            "Informativeness": {
                "impact": -0.00239,
                "llm_score": 3.0,
                "human_score": 3.0
            },
            "Overall Readability": {
                "impact": 0.001607,
                "llm_score": 3.333,
                "human_score": 3.0
            },
            "Creativity": {
                "impact": -0.000743,
                "llm_score": 3.667,
                "human_score": 3.0
            },
            "Design Quality": {
                "impact": 9e-05,
                "llm_score": 4.143,
                "human_score": 4.0
            },
            "Fidelity": {
                "impact": 0.003173,
                "llm_score": 5.0,
                "human_score": 5.0
            }
        }
    },
    {
        "filename": "SafeDecoding_Defending_against_Jailbreak_Attacks_via_Safety-Aware_Decoding__p0__score0.95.png",
        "Total_Impact": 0.002104,
        "details": {
            "Informativeness": {
                "impact": -0.001574,
                "llm_score": 2.333,
                "human_score": 4.0
            },
            "Overall Readability": {
                "impact": 8.9e-05,
                "llm_score": 3.667,
                "human_score": 4.0
            },
            "Creativity": {
                "impact": 0.007603,
                "llm_score": 3.667,
                "human_score": 5.0
            },
            "Design Quality": {
                "impact": -0.005873,
                "llm_score": 3.857,
                "human_score": 5.0
            },
            "Fidelity": {
                "impact": 0.001858,
                "llm_score": 4.667,
                "human_score": 5.0
            }
        }
    },
    {
        "filename": "Do_Large_Language_Models_Latently_Perform_Multi-Hop_Reasoning__p0__score0.90.png",
        "Total_Impact": 0.002301,
        "details": {
            "Informativeness": {
                "impact": -0.000485,
                "llm_score": 2.667,
                "human_score": 3.0
            },
            "Overall Readability": {
                "impact": 0.000766,
                "llm_score": 4.0,
                "human_score": 4.0
            },
            "Creativity": {
                "impact": -0.000743,
                "llm_score": 3.667,
                "human_score": 3.0
            },
            "Design Quality": {
                "impact": -0.00041,
                "llm_score": 4.143,
                "human_score": 3.0
            },
            "Fidelity": {
                "impact": 0.003173,
                "llm_score": 5.0,
                "human_score": 5.0
            }
        }
    },
    {
        "filename": "Blinded_by_Generated_Contexts_How_Language_Models_Merge_Generated_and_Retrieved_Contexts_When_Knowledge_Conflicts__p3__score1.00.png",
        "Total_Impact": 0.002316,
        "details": {
            "Informativeness": {
                "impact": 0.006417,
                "llm_score": 3.333,
                "human_score": 5.0
            },
            "Overall Readability": {
                "impact": 0.001607,
                "llm_score": 3.333,
                "human_score": 3.0
            },
            "Creativity": {
                "impact": -0.00013,
                "llm_score": 3.333,
                "human_score": 3.0
            },
            "Design Quality": {
                "impact": 0.000734,
                "llm_score": 4.286,
                "human_score": 4.0
            },
            "Fidelity": {
                "impact": -0.006313,
                "llm_score": 2.667,
                "human_score": 5.0
            }
        }
    },
    {
        "filename": "DiffusionBERT_Improving_Generative_Masked_Language_Models_with_Diffusion_Models__p0__score1.00__1.png",
        "Total_Impact": 0.002656,
        "details": {
            "Informativeness": {
                "impact": 0.007556,
                "llm_score": 2.0,
                "human_score": 1.0
            },
            "Overall Readability": {
                "impact": -0.002767,
                "llm_score": 4.0,
                "human_score": 3.0
            },
            "Creativity": {
                "impact": -0.006438,
                "llm_score": 3.667,
                "human_score": 2.0
            },
            "Design Quality": {
                "impact": 0.002447,
                "llm_score": 4.286,
                "human_score": 5.0
            },
            "Fidelity": {
                "impact": 0.001858,
                "llm_score": 4.667,
                "human_score": 5.0
            }
        }
    },
    {
        "filename": "DiffusionBERT_Improving_Generative_Masked_Language_Models_with_Diffusion_Models__p0__score1.00__2.png",
        "Total_Impact": 0.002656,
        "details": {
            "Informativeness": {
                "impact": 0.007556,
                "llm_score": 2.0,
                "human_score": 1.0
            },
            "Overall Readability": {
                "impact": -0.002767,
                "llm_score": 4.0,
                "human_score": 3.0
            },
            "Creativity": {
                "impact": -0.006438,
                "llm_score": 3.667,
                "human_score": 2.0
            },
            "Design Quality": {
                "impact": 0.002447,
                "llm_score": 4.286,
                "human_score": 5.0
            },
            "Fidelity": {
                "impact": 0.001858,
                "llm_score": 4.667,
                "human_score": 5.0
            }
        }
    },
    {
        "filename": "Self-Knowledge_Guided_Retrieval_Augmentation_for_Large_Language_Models__p2__score1.00.png",
        "Total_Impact": 0.002825,
        "details": {
            "Informativeness": {
                "impact": -0.00239,
                "llm_score": 3.0,
                "human_score": 3.0
            },
            "Overall Readability": {
                "impact": 1.6e-05,
                "llm_score": 3.667,
                "human_score": 5.0
            },
            "Creativity": {
                "impact": 0.000895,
                "llm_score": 3.0,
                "human_score": 2.0
            },
            "Design Quality": {
                "impact": 0.002447,
                "llm_score": 4.286,
                "human_score": 5.0
            },
            "Fidelity": {
                "impact": 0.001858,
                "llm_score": 4.667,
                "human_score": 5.0
            }
        }
    },
    {
        "filename": "Measuring_Chain_of_Thought_Faithfulness_by_Unlearning_Reasoning_Steps__p7__score0.80.png",
        "Total_Impact": 0.002878,
        "details": {
            "Informativeness": {
                "impact": 0.001517,
                "llm_score": 2.0,
                "human_score": 3.0
            },
            "Overall Readability": {
                "impact": -0.000807,
                "llm_score": 3.333,
                "human_score": 4.0
            },
            "Creativity": {
                "impact": -0.000364,
                "llm_score": 2.667,
                "human_score": 3.0
            },
            "Design Quality": {
                "impact": 0.013247,
                "llm_score": 3.429,
                "human_score": 2.0
            },
            "Fidelity": {
                "impact": -0.010716,
                "llm_score": 1.667,
                "human_score": 5.0
            }
        }
    },
    {
        "filename": "Mitigating_Hallucinations_in_Vision-Language_Models_through_Image-Guided_Head_Suppression__p0__score0.95.png",
        "Total_Impact": 0.003175,
        "details": {
            "Informativeness": {
                "impact": 0.001517,
                "llm_score": 2.0,
                "human_score": 3.0
            },
            "Overall Readability": {
                "impact": 0.007136,
                "llm_score": 4.333,
                "human_score": 5.0
            },
            "Creativity": {
                "impact": -0.000743,
                "llm_score": 3.667,
                "human_score": 3.0
            },
            "Design Quality": {
                "impact": -0.003234,
                "llm_score": 4.429,
                "human_score": 3.0
            },
            "Fidelity": {
                "impact": -0.001502,
                "llm_score": 4.667,
                "human_score": 4.0
            }
        }
    },
    {
        "filename": "Finetuning_LLMs_for_Human_Behavior_Prediction_in_Social_Science_Experiments__p3__score1.00.png",
        "Total_Impact": 0.003781,
        "details": {
            "Informativeness": {
                "impact": 0.001093,
                "llm_score": 3.0,
                "human_score": 4.0
            },
            "Overall Readability": {
                "impact": -0.000474,
                "llm_score": 3.667,
                "human_score": 3.0
            },
            "Creativity": {
                "impact": -0.000364,
                "llm_score": 2.667,
                "human_score": 3.0
            },
            "Design Quality": {
                "impact": 0.001902,
                "llm_score": 3.857,
                "human_score": 3.0
            },
            "Fidelity": {
                "impact": 0.001624,
                "llm_score": 3.667,
                "human_score": 4.0
            }
        }
    },
    {
        "filename": "Progressive_Multimodal_Reasoning_via_Active_Retrieval__p2__score0.95.png",
        "Total_Impact": 0.00379,
        "details": {
            "Informativeness": {
                "impact": -0.006699,
                "llm_score": 1.667,
                "human_score": 4.0
            },
            "Overall Readability": {
                "impact": 0.003473,
                "llm_score": 3.0,
                "human_score": 3.0
            },
            "Creativity": {
                "impact": -0.000364,
                "llm_score": 2.667,
                "human_score": 3.0
            },
            "Design Quality": {
                "impact": 0.003719,
                "llm_score": 3.571,
                "human_score": 3.0
            },
            "Fidelity": {
                "impact": 0.003661,
                "llm_score": 3.0,
                "human_score": 4.0
            }
        }
    },
    {
        "filename": "CoPL_Collaborative_Preference_Learning_for_Personalizing_LLMs__p4__score0.95.png",
        "Total_Impact": 0.003958,
        "details": {
            "Informativeness": {
                "impact": 0.006417,
                "llm_score": 3.333,
                "human_score": 5.0
            },
            "Overall Readability": {
                "impact": 0.003674,
                "llm_score": 4.0,
                "human_score": 5.0
            },
            "Creativity": {
                "impact": 0.003919,
                "llm_score": 3.667,
                "human_score": 4.0
            },
            "Design Quality": {
                "impact": -0.006533,
                "llm_score": 3.286,
                "human_score": 4.0
            },
            "Fidelity": {
                "impact": -0.00352,
                "llm_score": 3.333,
                "human_score": 5.0
            }
        }
    },
    {
        "filename": "ZoomEye_Enhancing_Multimodal_LLMs_with_Human-Like_Zooming_Capabilities_through_Tree-Based_Image_Exploration__p1__score0.95.png",
        "Total_Impact": 0.004085,
        "details": {
            "Informativeness": {
                "impact": 0.000818,
                "llm_score": 2.333,
                "human_score": 3.0
            },
            "Overall Readability": {
                "impact": 0.003473,
                "llm_score": 3.0,
                "human_score": 3.0
            },
            "Creativity": {
                "impact": -0.00348,
                "llm_score": 4.333,
                "human_score": 3.0
            },
            "Design Quality": {
                "impact": 0.003719,
                "llm_score": 3.571,
                "human_score": 3.0
            },
            "Fidelity": {
                "impact": -0.000445,
                "llm_score": 4.333,
                "human_score": 4.0
            }
        }
    },
    {
        "filename": "Humans_or_LLMs_as_the_Judge_A_Study_on_Judgement_Bias__p4__score1.00__1.png",
        "Total_Impact": 0.004228,
        "details": {
            "Informativeness": {
                "impact": -0.014307,
                "llm_score": 3.0,
                "human_score": 1.0
            },
            "Overall Readability": {
                "impact": 0.008283,
                "llm_score": 3.0,
                "human_score": 2.0
            },
            "Creativity": {
                "impact": -0.00013,
                "llm_score": 3.333,
                "human_score": 3.0
            },
            "Design Quality": {
                "impact": 0.013247,
                "llm_score": 3.429,
                "human_score": 2.0
            },
            "Fidelity": {
                "impact": -0.002865,
                "llm_score": 4.333,
                "human_score": 2.0
            }
        }
    },
    {
        "filename": "A_Theory_of_Response_Sampling_in_LLMs_Part_Descriptive_and_Part_Prescriptive__p1__score1.00.png",
        "Total_Impact": 0.004447,
        "details": {
            "Informativeness": {
                "impact": -0.005565,
                "llm_score": 2.333,
                "human_score": 5.0
            },
            "Overall Readability": {
                "impact": 0.000766,
                "llm_score": 4.0,
                "human_score": 4.0
            },
            "Creativity": {
                "impact": 0.007603,
                "llm_score": 3.667,
                "human_score": 5.0
            },
            "Design Quality": {
                "impact": 0.002447,
                "llm_score": 4.286,
                "human_score": 5.0
            },
            "Fidelity": {
                "impact": -0.000803,
                "llm_score": 4.0,
                "human_score": 5.0
            }
        }
    },
    {
        "filename": "MP2D_AnAutomated_Topic_Shift_Dialogue_Generation_Framework__p0__score0.90.png",
        "Total_Impact": 0.004864,
        "details": {
            "Informativeness": {
                "impact": 0.005306,
                "llm_score": 2.0,
                "human_score": 2.0
            },
            "Overall Readability": {
                "impact": 0.001229,
                "llm_score": 4.333,
                "human_score": 4.0
            },
            "Creativity": {
                "impact": -0.000743,
                "llm_score": 3.667,
                "human_score": 3.0
            },
            "Design Quality": {
                "impact": 0.001642,
                "llm_score": 4.571,
                "human_score": 4.0
            },
            "Fidelity": {
                "impact": -0.00257,
                "llm_score": 5.0,
                "human_score": 4.0
            }
        }
    },
    {
        "filename": "Conditional_MASK_Discrete_Diffusion_Language_Model__p3__score1.00.png",
        "Total_Impact": 0.005302,
        "details": {
            "Informativeness": {
                "impact": 0.001093,
                "llm_score": 3.0,
                "human_score": 4.0
            },
            "Overall Readability": {
                "impact": 0.003473,
                "llm_score": 3.0,
                "human_score": 3.0
            },
            "Creativity": {
                "impact": -0.001932,
                "llm_score": 3.0,
                "human_score": 4.0
            },
            "Design Quality": {
                "impact": 0.000809,
                "llm_score": 4.0,
                "human_score": 3.0
            },
            "Fidelity": {
                "impact": 0.001858,
                "llm_score": 4.667,
                "human_score": 5.0
            }
        }
    },
    {
        "filename": "MemInsight_Autonomous_Memory_Augmentation_for_LLM_Agents__p7__score1.00.png",
        "Total_Impact": 0.006146,
        "details": {
            "Informativeness": {
                "impact": -0.010781,
                "llm_score": 2.0,
                "human_score": 5.0
            },
            "Overall Readability": {
                "impact": 0.007878,
                "llm_score": 2.0,
                "human_score": 3.0
            },
            "Creativity": {
                "impact": 0.00631,
                "llm_score": 2.333,
                "human_score": 2.0
            },
            "Design Quality": {
                "impact": 0.010491,
                "llm_score": 3.571,
                "human_score": 2.0
            },
            "Fidelity": {
                "impact": -0.007751,
                "llm_score": 2.333,
                "human_score": 5.0
            }
        }
    },
    {
        "filename": "R-VLM_Region-Aware_Vision_Language_Model_for_Precise_GUI_Grounding__p4__score1.00.png",
        "Total_Impact": 0.0062,
        "details": {
            "Informativeness": {
                "impact": 0.003018,
                "llm_score": 3.0,
                "human_score": 5.0
            },
            "Overall Readability": {
                "impact": -0.001921,
                "llm_score": 3.0,
                "human_score": 4.0
            },
            "Creativity": {
                "impact": -5e-06,
                "llm_score": 3.0,
                "human_score": 3.0
            },
            "Design Quality": {
                "impact": -0.00158,
                "llm_score": 3.857,
                "human_score": 4.0
            },
            "Fidelity": {
                "impact": 0.006689,
                "llm_score": 2.0,
                "human_score": 4.0
            }
        }
    },
    {
        "filename": "Mission_Impossible_Language_Models__p7__score0.95.png",
        "Total_Impact": 0.006893,
        "details": {
            "Informativeness": {
                "impact": 0.001085,
                "llm_score": 1.333,
                "human_score": 3.0
            },
            "Overall Readability": {
                "impact": -0.007979,
                "llm_score": 3.0,
                "human_score": 5.0
            },
            "Creativity": {
                "impact": -0.006438,
                "llm_score": 3.667,
                "human_score": 2.0
            },
            "Design Quality": {
                "impact": 0.010491,
                "llm_score": 3.571,
                "human_score": 2.0
            },
            "Fidelity": {
                "impact": 0.009735,
                "llm_score": 1.0,
                "human_score": 4.0
            }
        }
    },
    {
        "filename": "Ko-LongRAG_A_Korean_Long-Context_RAG_Benchmark_Built_with_a_Retrieval-Free_Approach__p1__score1.00.png",
        "Total_Impact": 0.006894,
        "details": {
            "Informativeness": {
                "impact": 0.001093,
                "llm_score": 3.0,
                "human_score": 4.0
            },
            "Overall Readability": {
                "impact": 0.001607,
                "llm_score": 3.333,
                "human_score": 3.0
            },
            "Creativity": {
                "impact": 0.00383,
                "llm_score": 2.667,
                "human_score": 2.0
            },
            "Design Quality": {
                "impact": 0.000809,
                "llm_score": 4.0,
                "human_score": 3.0
            },
            "Fidelity": {
                "impact": -0.000445,
                "llm_score": 4.333,
                "human_score": 4.0
            }
        }
    },
    {
        "filename": "Weakly_Supervised_Semantic_Parsing_with_Execution-based_Spurious_Program_Filtering__p3__score0.70.png",
        "Total_Impact": 0.006967,
        "details": {
            "Informativeness": {
                "impact": 0.005306,
                "llm_score": 2.0,
                "human_score": 2.0
            },
            "Overall Readability": {
                "impact": -0.006984,
                "llm_score": 4.0,
                "human_score": 2.0
            },
            "Creativity": {
                "impact": 0.00383,
                "llm_score": 2.667,
                "human_score": 2.0
            },
            "Design Quality": {
                "impact": 0.001642,
                "llm_score": 4.571,
                "human_score": 4.0
            },
            "Fidelity": {
                "impact": 0.003173,
                "llm_score": 5.0,
                "human_score": 5.0
            }
        }
    },
    {
        "filename": "FaST_Feature-aware_Sampling_and_Tuning_for_Personalized_Preference_Alignment_with_Limited_Data__p2__score1.00.png",
        "Total_Impact": 0.007117,
        "details": {
            "Informativeness": {
                "impact": 0.006417,
                "llm_score": 3.333,
                "human_score": 5.0
            },
            "Overall Readability": {
                "impact": 0.000766,
                "llm_score": 4.0,
                "human_score": 4.0
            },
            "Creativity": {
                "impact": -5e-06,
                "llm_score": 3.0,
                "human_score": 3.0
            },
            "Design Quality": {
                "impact": -0.003234,
                "llm_score": 4.429,
                "human_score": 3.0
            },
            "Fidelity": {
                "impact": 0.003173,
                "llm_score": 5.0,
                "human_score": 5.0
            }
        }
    },
    {
        "filename": "Ko-LongRAG_A_Korean_Long-Context_RAG_Benchmark_Built_with_a_Retrieval-Free_Approach__p6__score0.90.png",
        "Total_Impact": 0.007183,
        "details": {
            "Informativeness": {
                "impact": 0.010906,
                "llm_score": 1.333,
                "human_score": 2.0
            },
            "Overall Readability": {
                "impact": -0.001921,
                "llm_score": 3.0,
                "human_score": 4.0
            },
            "Creativity": {
                "impact": 0.012902,
                "llm_score": 2.333,
                "human_score": 1.0
            },
            "Design Quality": {
                "impact": 9e-05,
                "llm_score": 4.143,
                "human_score": 4.0
            },
            "Fidelity": {
                "impact": -0.014794,
                "llm_score": 5.0,
                "human_score": 2.0
            }
        }
    },
    {
        "filename": "Mitigating_Hallucinations_in_Large_Vision-Language_Models_with_Instruction_Contrastive_Decoding__p3__score1.00.png",
        "Total_Impact": 0.007286,
        "details": {
            "Informativeness": {
                "impact": 0.003018,
                "llm_score": 3.0,
                "human_score": 5.0
            },
            "Overall Readability": {
                "impact": 1.6e-05,
                "llm_score": 3.667,
                "human_score": 5.0
            },
            "Creativity": {
                "impact": 0.003919,
                "llm_score": 3.667,
                "human_score": 4.0
            },
            "Design Quality": {
                "impact": -0.000198,
                "llm_score": 4.143,
                "human_score": 5.0
            },
            "Fidelity": {
                "impact": 0.000531,
                "llm_score": 4.333,
                "human_score": 5.0
            }
        }
    },
    {
        "filename": "Improve_Vision_Language_Model_Chain-of-thought_Reasoning__p2__score0.70.png",
        "Total_Impact": 0.007463,
        "details": {
            "Informativeness": {
                "impact": 0.005306,
                "llm_score": 2.0,
                "human_score": 2.0
            },
            "Overall Readability": {
                "impact": 0.003473,
                "llm_score": 3.0,
                "human_score": 3.0
            },
            "Creativity": {
                "impact": -5e-06,
                "llm_score": 3.0,
                "human_score": 3.0
            },
            "Design Quality": {
                "impact": 0.003719,
                "llm_score": 3.571,
                "human_score": 3.0
            },
            "Fidelity": {
                "impact": -0.00503,
                "llm_score": 4.667,
                "human_score": 3.0
            }
        }
    },
    {
        "filename": "Generating_Diverse_Hypotheses_for_Inductive_Reasoning__p4__score0.95.png",
        "Total_Impact": 0.00749,
        "details": {
            "Informativeness": {
                "impact": 0.005306,
                "llm_score": 2.0,
                "human_score": 2.0
            },
            "Overall Readability": {
                "impact": -0.001687,
                "llm_score": 3.667,
                "human_score": 2.0
            },
            "Creativity": {
                "impact": 0.000895,
                "llm_score": 3.0,
                "human_score": 2.0
            },
            "Design Quality": {
                "impact": -0.000198,
                "llm_score": 4.143,
                "human_score": 5.0
            },
            "Fidelity": {
                "impact": 0.003173,
                "llm_score": 5.0,
                "human_score": 5.0
            }
        }
    },
    {
        "filename": "Memory_OS_of_AI_Agent__p2__score1.00.png",
        "Total_Impact": 0.007633,
        "details": {
            "Informativeness": {
                "impact": 0.006417,
                "llm_score": 3.333,
                "human_score": 5.0
            },
            "Overall Readability": {
                "impact": -0.000474,
                "llm_score": 3.667,
                "human_score": 3.0
            },
            "Creativity": {
                "impact": -0.000743,
                "llm_score": 3.667,
                "human_score": 3.0
            },
            "Design Quality": {
                "impact": 0.001902,
                "llm_score": 3.857,
                "human_score": 3.0
            },
            "Fidelity": {
                "impact": 0.000531,
                "llm_score": 4.333,
                "human_score": 5.0
            }
        }
    },
    {
        "filename": "PopAlign_Diversifying_Contrasting_Patterns_for_a_More_Comprehensive_Alignment__p0__score0.90.png",
        "Total_Impact": 0.007895,
        "details": {
            "Informativeness": {
                "impact": 0.001523,
                "llm_score": 3.333,
                "human_score": 4.0
            },
            "Overall Readability": {
                "impact": -0.00387,
                "llm_score": 3.333,
                "human_score": 5.0
            },
            "Creativity": {
                "impact": 0.00614,
                "llm_score": 4.0,
                "human_score": 4.0
            },
            "Design Quality": {
                "impact": -0.00158,
                "llm_score": 3.857,
                "human_score": 4.0
            },
            "Fidelity": {
                "impact": 0.005682,
                "llm_score": 2.333,
                "human_score": 4.0
            }
        }
    },
    {
        "filename": "Competition_of_Mechanisms_Tracing_How_Language_Models_Handle_Facts_and_Counterfactuals__p0__score1.00.png",
        "Total_Impact": 0.007898,
        "details": {
            "Informativeness": {
                "impact": -0.001574,
                "llm_score": 2.333,
                "human_score": 4.0
            },
            "Overall Readability": {
                "impact": -0.000807,
                "llm_score": 3.333,
                "human_score": 4.0
            },
            "Creativity": {
                "impact": -0.000743,
                "llm_score": 3.667,
                "human_score": 3.0
            },
            "Design Quality": {
                "impact": 0.010491,
                "llm_score": 3.571,
                "human_score": 2.0
            },
            "Fidelity": {
                "impact": 0.000531,
                "llm_score": 4.333,
                "human_score": 5.0
            }
        }
    },
    {
        "filename": "RAG-Instruct_Boosting_LLMs_with_Diverse_Retrieval-Augmented_Instructions__p4__score0.95.png",
        "Total_Impact": 0.00815,
        "details": {
            "Informativeness": {
                "impact": 0.001523,
                "llm_score": 3.333,
                "human_score": 4.0
            },
            "Overall Readability": {
                "impact": 0.007878,
                "llm_score": 2.0,
                "human_score": 3.0
            },
            "Creativity": {
                "impact": -0.005981,
                "llm_score": 3.333,
                "human_score": 1.0
            },
            "Design Quality": {
                "impact": 0.002872,
                "llm_score": 3.714,
                "human_score": 3.0
            },
            "Fidelity": {
                "impact": 0.001858,
                "llm_score": 4.667,
                "human_score": 5.0
            }
        }
    },
    {
        "filename": "In_Prospect_and_Retrospect_Re_ective_Memory_Management_for_Long-term_Personalized_Dialogue_Agents__p3__score0.95.png",
        "Total_Impact": 0.008274,
        "details": {
            "Informativeness": {
                "impact": 0.005306,
                "llm_score": 2.0,
                "human_score": 2.0
            },
            "Overall Readability": {
                "impact": -0.002767,
                "llm_score": 4.0,
                "human_score": 3.0
            },
            "Creativity": {
                "impact": 0.00383,
                "llm_score": 2.667,
                "human_score": 2.0
            },
            "Design Quality": {
                "impact": -0.001756,
                "llm_score": 4.286,
                "human_score": 3.0
            },
            "Fidelity": {
                "impact": 0.003661,
                "llm_score": 3.0,
                "human_score": 4.0
            }
        }
    },
    {
        "filename": "Bridging_the_Visual_Gap_Fine-Tuning_Multimodal_Models_with_Knowledge-Adapted_Captions__p1__score1.00.png",
        "Total_Impact": 0.008639,
        "details": {
            "Informativeness": {
                "impact": 0.003018,
                "llm_score": 3.0,
                "human_score": 5.0
            },
            "Overall Readability": {
                "impact": 8.9e-05,
                "llm_score": 3.667,
                "human_score": 4.0
            },
            "Creativity": {
                "impact": 0.001227,
                "llm_score": 3.333,
                "human_score": 4.0
            },
            "Design Quality": {
                "impact": 0.002447,
                "llm_score": 4.286,
                "human_score": 5.0
            },
            "Fidelity": {
                "impact": 0.001858,
                "llm_score": 4.667,
                "human_score": 5.0
            }
        }
    },
    {
        "filename": "Measuring_Chain_of_Thought_Faithfulness_by_Unlearning_Reasoning_Steps__p0__score0.95.png",
        "Total_Impact": 0.008896,
        "details": {
            "Informativeness": {
                "impact": -0.001574,
                "llm_score": 2.333,
                "human_score": 4.0
            },
            "Overall Readability": {
                "impact": 0.003674,
                "llm_score": 4.0,
                "human_score": 5.0
            },
            "Creativity": {
                "impact": 0.003919,
                "llm_score": 3.667,
                "human_score": 4.0
            },
            "Design Quality": {
                "impact": 0.001252,
                "llm_score": 4.429,
                "human_score": 4.0
            },
            "Fidelity": {
                "impact": 0.001624,
                "llm_score": 3.667,
                "human_score": 4.0
            }
        }
    },
    {
        "filename": "Lost_in_the_Middle_How_Language_Models_Use_Long_Contexts__p3__score0.60.png",
        "Total_Impact": 0.009115,
        "details": {
            "Informativeness": {
                "impact": 0.007556,
                "llm_score": 2.0,
                "human_score": 1.0
            },
            "Overall Readability": {
                "impact": -0.000474,
                "llm_score": 3.667,
                "human_score": 3.0
            },
            "Creativity": {
                "impact": 0.00631,
                "llm_score": 2.333,
                "human_score": 2.0
            },
            "Design Quality": {
                "impact": -0.001707,
                "llm_score": 4.143,
                "human_score": 2.0
            },
            "Fidelity": {
                "impact": -0.00257,
                "llm_score": 5.0,
                "human_score": 4.0
            }
        }
    },
    {
        "filename": "MemInsight_Autonomous_Memory_Augmentation_for_LLM_Agents__p2__score1.00.png",
        "Total_Impact": 0.009168,
        "details": {
            "Informativeness": {
                "impact": 0.006417,
                "llm_score": 3.333,
                "human_score": 5.0
            },
            "Overall Readability": {
                "impact": 8.9e-05,
                "llm_score": 3.667,
                "human_score": 4.0
            },
            "Creativity": {
                "impact": -5e-06,
                "llm_score": 3.0,
                "human_score": 3.0
            },
            "Design Quality": {
                "impact": 0.000809,
                "llm_score": 4.0,
                "human_score": 3.0
            },
            "Fidelity": {
                "impact": 0.001858,
                "llm_score": 4.667,
                "human_score": 5.0
            }
        }
    },
    {
        "filename": "On_LLM-Based_Scientific_Inductive_Reasoning_Beyond_Equations__p0__score1.00.png",
        "Total_Impact": 0.009402,
        "details": {
            "Informativeness": {
                "impact": 0.001644,
                "llm_score": 2.333,
                "human_score": 2.0
            },
            "Overall Readability": {
                "impact": -0.005293,
                "llm_score": 4.333,
                "human_score": 3.0
            },
            "Creativity": {
                "impact": 0.00383,
                "llm_score": 2.667,
                "human_score": 2.0
            },
            "Design Quality": {
                "impact": 0.007363,
                "llm_score": 4.571,
                "human_score": 5.0
            },
            "Fidelity": {
                "impact": 0.001858,
                "llm_score": 4.667,
                "human_score": 5.0
            }
        }
    },
    {
        "filename": "Mitigating_Biases_for_Instruction-following_Language_Models_via_Bias_Neurons_Elimination__p0__score0.95.png",
        "Total_Impact": 0.00946,
        "details": {
            "Informativeness": {
                "impact": -0.00382,
                "llm_score": 2.0,
                "human_score": 4.0
            },
            "Overall Readability": {
                "impact": 0.003674,
                "llm_score": 4.0,
                "human_score": 5.0
            },
            "Creativity": {
                "impact": 0.007603,
                "llm_score": 3.667,
                "human_score": 5.0
            },
            "Design Quality": {
                "impact": 0.002447,
                "llm_score": 4.286,
                "human_score": 5.0
            },
            "Fidelity": {
                "impact": -0.000445,
                "llm_score": 4.333,
                "human_score": 4.0
            }
        }
    },
    {
        "filename": "Bridging_the_Visual_Gap_Fine-Tuning_Multimodal_Models_with_Knowledge-Adapted_Captions__p3__score1.00.png",
        "Total_Impact": 0.009473,
        "details": {
            "Informativeness": {
                "impact": 0.001093,
                "llm_score": 3.0,
                "human_score": 4.0
            },
            "Overall Readability": {
                "impact": 0.000766,
                "llm_score": 4.0,
                "human_score": 4.0
            },
            "Creativity": {
                "impact": -5e-06,
                "llm_score": 3.0,
                "human_score": 3.0
            },
            "Design Quality": {
                "impact": 0.004971,
                "llm_score": 4.429,
                "human_score": 5.0
            },
            "Fidelity": {
                "impact": 0.002647,
                "llm_score": 3.333,
                "human_score": 4.0
            }
        }
    },
    {
        "filename": "AdaRewriter_Unleashing_the_Power_of_Prompting-based_Conversational_Query_Reformulation_via_Test-Time_Adaptation__p2__score1.00.png",
        "Total_Impact": 0.010204,
        "details": {
            "Informativeness": {
                "impact": 0.001093,
                "llm_score": 3.0,
                "human_score": 4.0
            },
            "Overall Readability": {
                "impact": 0.000766,
                "llm_score": 4.0,
                "human_score": 4.0
            },
            "Creativity": {
                "impact": 0.003919,
                "llm_score": 3.667,
                "human_score": 4.0
            },
            "Design Quality": {
                "impact": 0.001252,
                "llm_score": 4.429,
                "human_score": 4.0
            },
            "Fidelity": {
                "impact": 0.003173,
                "llm_score": 5.0,
                "human_score": 5.0
            }
        }
    },
    {
        "filename": "In_Prospect_and_Retrospect_Re_ective_Memory_Management_for_Long-term_Personalized_Dialogue_Agents__p0__score0.95.png",
        "Total_Impact": 0.010369,
        "details": {
            "Informativeness": {
                "impact": 0.010906,
                "llm_score": 1.333,
                "human_score": 2.0
            },
            "Overall Readability": {
                "impact": 0.001229,
                "llm_score": 4.333,
                "human_score": 4.0
            },
            "Creativity": {
                "impact": -5e-06,
                "llm_score": 3.0,
                "human_score": 3.0
            },
            "Design Quality": {
                "impact": 0.000809,
                "llm_score": 4.0,
                "human_score": 3.0
            },
            "Fidelity": {
                "impact": -0.00257,
                "llm_score": 5.0,
                "human_score": 4.0
            }
        }
    },
    {
        "filename": "DRAGIN_Dynamic_Retrieval_Augmented_Generation_based_on_the_Information_Needs_of_Large_Language_Models__p2__score1.00.png",
        "Total_Impact": 0.010439,
        "details": {
            "Informativeness": {
                "impact": -0.00239,
                "llm_score": 3.0,
                "human_score": 3.0
            },
            "Overall Readability": {
                "impact": 0.000766,
                "llm_score": 4.0,
                "human_score": 4.0
            },
            "Creativity": {
                "impact": 0.003919,
                "llm_score": 3.667,
                "human_score": 4.0
            },
            "Design Quality": {
                "impact": 0.004971,
                "llm_score": 4.429,
                "human_score": 5.0
            },
            "Fidelity": {
                "impact": 0.003173,
                "llm_score": 5.0,
                "human_score": 5.0
            }
        }
    },
    {
        "filename": "Towards_Statistical_Factuality_Guarantee_for_Large_Vision-Language_Models__p1__score1.00.png",
        "Total_Impact": 0.010779,
        "details": {
            "Informativeness": {
                "impact": 0.001342,
                "llm_score": 3.667,
                "human_score": 4.0
            },
            "Overall Readability": {
                "impact": 1.6e-05,
                "llm_score": 3.667,
                "human_score": 5.0
            },
            "Creativity": {
                "impact": 0.003919,
                "llm_score": 3.667,
                "human_score": 4.0
            },
            "Design Quality": {
                "impact": 0.004971,
                "llm_score": 4.429,
                "human_score": 5.0
            },
            "Fidelity": {
                "impact": 0.000531,
                "llm_score": 4.333,
                "human_score": 5.0
            }
        }
    },
    {
        "filename": "How_Do_Moral_Emotions_Shape_Political_Participation_A_Cross-Cultural_Analysis_of_Online_Petitions_Using_Language_Models__p3__score1.00.png",
        "Total_Impact": 0.011173,
        "details": {
            "Informativeness": {
                "impact": 0.009248,
                "llm_score": 3.667,
                "human_score": 5.0
            },
            "Overall Readability": {
                "impact": -0.000474,
                "llm_score": 3.667,
                "human_score": 3.0
            },
            "Creativity": {
                "impact": -0.000364,
                "llm_score": 2.667,
                "human_score": 3.0
            },
            "Design Quality": {
                "impact": -0.00041,
                "llm_score": 4.143,
                "human_score": 3.0
            },
            "Fidelity": {
                "impact": 0.003173,
                "llm_score": 5.0,
                "human_score": 5.0
            }
        }
    },
    {
        "filename": "Steering_Llama_2_via_Contrastive_Activation_Addition__p0__score1.00.png",
        "Total_Impact": 0.011426,
        "details": {
            "Informativeness": {
                "impact": -0.000966,
                "llm_score": 2.667,
                "human_score": 5.0
            },
            "Overall Readability": {
                "impact": 0.007136,
                "llm_score": 4.333,
                "human_score": 5.0
            },
            "Creativity": {
                "impact": -0.000364,
                "llm_score": 2.667,
                "human_score": 3.0
            },
            "Design Quality": {
                "impact": 0.002447,
                "llm_score": 4.286,
                "human_score": 5.0
            },
            "Fidelity": {
                "impact": 0.003173,
                "llm_score": 5.0,
                "human_score": 5.0
            }
        }
    },
    {
        "filename": "Visual_Evidence_Prompting_Mitigates_Hallucinations_in_Large_Vision-Language_Models__p0__score0.90.png",
        "Total_Impact": 0.012008,
        "details": {
            "Informativeness": {
                "impact": -0.00239,
                "llm_score": 3.0,
                "human_score": 3.0
            },
            "Overall Readability": {
                "impact": -0.001921,
                "llm_score": 3.0,
                "human_score": 4.0
            },
            "Creativity": {
                "impact": -0.00122,
                "llm_score": 2.333,
                "human_score": 3.0
            },
            "Design Quality": {
                "impact": -0.00158,
                "llm_score": 3.857,
                "human_score": 4.0
            },
            "Fidelity": {
                "impact": 0.019119,
                "llm_score": 2.333,
                "human_score": 3.0
            }
        }
    },
    {
        "filename": "Generating_Diverse_Hypotheses_for_Inductive_Reasoning__p1__score1.00.png",
        "Total_Impact": 0.012058,
        "details": {
            "Informativeness": {
                "impact": -0.00239,
                "llm_score": 3.0,
                "human_score": 3.0
            },
            "Overall Readability": {
                "impact": 1.6e-05,
                "llm_score": 3.667,
                "human_score": 5.0
            },
            "Creativity": {
                "impact": 0.007603,
                "llm_score": 3.667,
                "human_score": 5.0
            },
            "Design Quality": {
                "impact": 0.004971,
                "llm_score": 4.429,
                "human_score": 5.0
            },
            "Fidelity": {
                "impact": 0.001858,
                "llm_score": 4.667,
                "human_score": 5.0
            }
        }
    },
    {
        "filename": "Language_Models_as_Inductive_Reasoners__p1__score0.70.png",
        "Total_Impact": 0.012257,
        "details": {
            "Informativeness": {
                "impact": 0.005306,
                "llm_score": 2.0,
                "human_score": 2.0
            },
            "Overall Readability": {
                "impact": 0.003404,
                "llm_score": 3.333,
                "human_score": 2.0
            },
            "Creativity": {
                "impact": 0.010953,
                "llm_score": 1.333,
                "human_score": 2.0
            },
            "Design Quality": {
                "impact": -0.004836,
                "llm_score": 4.571,
                "human_score": 3.0
            },
            "Fidelity": {
                "impact": -0.00257,
                "llm_score": 5.0,
                "human_score": 4.0
            }
        }
    },
    {
        "filename": "Humans_or_LLMs_as_the_Judge_A_Study_on_Judgement_Bias__p4__score1.00.png",
        "Total_Impact": 0.01235,
        "details": {
            "Informativeness": {
                "impact": -0.007483,
                "llm_score": 3.0,
                "human_score": 2.0
            },
            "Overall Readability": {
                "impact": 0.008283,
                "llm_score": 3.0,
                "human_score": 2.0
            },
            "Creativity": {
                "impact": -0.00013,
                "llm_score": 3.333,
                "human_score": 3.0
            },
            "Design Quality": {
                "impact": 0.013247,
                "llm_score": 3.429,
                "human_score": 2.0
            },
            "Fidelity": {
                "impact": -0.001566,
                "llm_score": 4.333,
                "human_score": 3.0
            }
        }
    },
    {
        "filename": "Con_dence_Improves_Self-Consistency_in_LLMs__p1__score0.90.png",
        "Total_Impact": 0.012994,
        "details": {
            "Informativeness": {
                "impact": -0.000966,
                "llm_score": 2.667,
                "human_score": 5.0
            },
            "Overall Readability": {
                "impact": 0.007136,
                "llm_score": 4.333,
                "human_score": 5.0
            },
            "Creativity": {
                "impact": -5e-06,
                "llm_score": 3.0,
                "human_score": 3.0
            },
            "Design Quality": {
                "impact": 0.004971,
                "llm_score": 4.429,
                "human_score": 5.0
            },
            "Fidelity": {
                "impact": 0.001858,
                "llm_score": 4.667,
                "human_score": 5.0
            }
        }
    },
    {
        "filename": "Rewarding_the_Unlikely_Lifting_GRPO_Beyond_Distribution_Sharpening__p0__score0.90.png",
        "Total_Impact": 0.014009,
        "details": {
            "Informativeness": {
                "impact": -0.001574,
                "llm_score": 2.333,
                "human_score": 4.0
            },
            "Overall Readability": {
                "impact": 0.003674,
                "llm_score": 4.0,
                "human_score": 5.0
            },
            "Creativity": {
                "impact": 0.007603,
                "llm_score": 3.667,
                "human_score": 5.0
            },
            "Design Quality": {
                "impact": 0.002447,
                "llm_score": 4.286,
                "human_score": 5.0
            },
            "Fidelity": {
                "impact": 0.001858,
                "llm_score": 4.667,
                "human_score": 5.0
            }
        }
    },
    {
        "filename": "Are_LLM-Judges_Robust_to_Expressions_of_Uncertainty_Investigating_the_effect_of_Epistemic_Markers_on_LLM-based_Evaluation__p4__score1.00.png",
        "Total_Impact": 0.014936,
        "details": {
            "Informativeness": {
                "impact": 6.3e-05,
                "llm_score": 2.667,
                "human_score": 4.0
            },
            "Overall Readability": {
                "impact": 0.007136,
                "llm_score": 4.333,
                "human_score": 5.0
            },
            "Creativity": {
                "impact": 0.00383,
                "llm_score": 2.667,
                "human_score": 2.0
            },
            "Design Quality": {
                "impact": 0.000734,
                "llm_score": 4.286,
                "human_score": 4.0
            },
            "Fidelity": {
                "impact": 0.003173,
                "llm_score": 5.0,
                "human_score": 5.0
            }
        }
    },
    {
        "filename": "Reverse_Thinking_Makes_LLMs_Stronger_Reasoners__p0__score0.98.png",
        "Total_Impact": 0.015262,
        "details": {
            "Informativeness": {
                "impact": 0.006417,
                "llm_score": 3.333,
                "human_score": 5.0
            },
            "Overall Readability": {
                "impact": -0.007979,
                "llm_score": 3.0,
                "human_score": 5.0
            },
            "Creativity": {
                "impact": 0.007603,
                "llm_score": 3.667,
                "human_score": 5.0
            },
            "Design Quality": {
                "impact": 0.007363,
                "llm_score": 4.571,
                "human_score": 5.0
            },
            "Fidelity": {
                "impact": 0.001858,
                "llm_score": 4.667,
                "human_score": 5.0
            }
        }
    },
    {
        "filename": "Shifting_Attention_to_Relevance_Towards_the_Predictive_Uncertainty_Quantification_of_Free-Form_Large_Language_Models__p0__score0.90.png",
        "Total_Impact": 0.015272,
        "details": {
            "Informativeness": {
                "impact": 0.001093,
                "llm_score": 3.0,
                "human_score": 4.0
            },
            "Overall Readability": {
                "impact": 1.6e-05,
                "llm_score": 3.667,
                "human_score": 5.0
            },
            "Creativity": {
                "impact": 0.007603,
                "llm_score": 3.667,
                "human_score": 5.0
            },
            "Design Quality": {
                "impact": 0.007363,
                "llm_score": 4.571,
                "human_score": 5.0
            },
            "Fidelity": {
                "impact": -0.000803,
                "llm_score": 4.0,
                "human_score": 5.0
            }
        }
    },
    {
        "filename": "Bridging_the_Visual_Gap_Fine-Tuning_Multimodal_Models_with_Knowledge-Adapted_Captions__p0__score1.00.png",
        "Total_Impact": 0.015359,
        "details": {
            "Informativeness": {
                "impact": 0.000818,
                "llm_score": 2.333,
                "human_score": 3.0
            },
            "Overall Readability": {
                "impact": 0.003674,
                "llm_score": 4.0,
                "human_score": 5.0
            },
            "Creativity": {
                "impact": 0.007603,
                "llm_score": 3.667,
                "human_score": 5.0
            },
            "Design Quality": {
                "impact": 9e-05,
                "llm_score": 4.143,
                "human_score": 4.0
            },
            "Fidelity": {
                "impact": 0.003173,
                "llm_score": 5.0,
                "human_score": 5.0
            }
        }
    },
    {
        "filename": "Vision-Language_Models_Can_Self-Improve_Reasoning_via_Reflection__p3__score1.00.png",
        "Total_Impact": 0.015765,
        "details": {
            "Informativeness": {
                "impact": 0.001342,
                "llm_score": 3.667,
                "human_score": 4.0
            },
            "Overall Readability": {
                "impact": 0.003674,
                "llm_score": 4.0,
                "human_score": 5.0
            },
            "Creativity": {
                "impact": 0.003919,
                "llm_score": 3.667,
                "human_score": 4.0
            },
            "Design Quality": {
                "impact": 0.004971,
                "llm_score": 4.429,
                "human_score": 5.0
            },
            "Fidelity": {
                "impact": 0.001858,
                "llm_score": 4.667,
                "human_score": 5.0
            }
        }
    },
    {
        "filename": "AGrail_A_Lifelong_Agent_Guardrail_with_Effective_and_Adaptive_Safety_Detection__p0__score0.95.png",
        "Total_Impact": 0.016259,
        "details": {
            "Informativeness": {
                "impact": -0.00239,
                "llm_score": 3.0,
                "human_score": 3.0
            },
            "Overall Readability": {
                "impact": 0.035773,
                "llm_score": 2.0,
                "human_score": 1.0
            },
            "Creativity": {
                "impact": -0.013265,
                "llm_score": 3.667,
                "human_score": 1.0
            },
            "Design Quality": {
                "impact": -0.001707,
                "llm_score": 4.143,
                "human_score": 2.0
            },
            "Fidelity": {
                "impact": -0.002151,
                "llm_score": 3.667,
                "human_score": 5.0
            }
        }
    },
    {
        "filename": "PopAlign_Diversifying_Contrasting_Patterns_for_a_More_Comprehensive_Alignment__p2__score1.00.png",
        "Total_Impact": 0.016283,
        "details": {
            "Informativeness": {
                "impact": 0.006417,
                "llm_score": 3.333,
                "human_score": 5.0
            },
            "Overall Readability": {
                "impact": 0.003674,
                "llm_score": 4.0,
                "human_score": 5.0
            },
            "Creativity": {
                "impact": 0.007603,
                "llm_score": 3.667,
                "human_score": 5.0
            },
            "Design Quality": {
                "impact": 9e-05,
                "llm_score": 4.143,
                "human_score": 4.0
            },
            "Fidelity": {
                "impact": -0.001502,
                "llm_score": 4.667,
                "human_score": 4.0
            }
        }
    },
    {
        "filename": "VLind-Bench_Measuring_Language_Priors_in_Large_Vision-Language_Models__p1__score1.00.png",
        "Total_Impact": 0.017769,
        "details": {
            "Informativeness": {
                "impact": 0.001093,
                "llm_score": 3.0,
                "human_score": 4.0
            },
            "Overall Readability": {
                "impact": 0.007136,
                "llm_score": 4.333,
                "human_score": 5.0
            },
            "Creativity": {
                "impact": 0.003919,
                "llm_score": 3.667,
                "human_score": 4.0
            },
            "Design Quality": {
                "impact": 0.002447,
                "llm_score": 4.286,
                "human_score": 5.0
            },
            "Fidelity": {
                "impact": 0.003173,
                "llm_score": 5.0,
                "human_score": 5.0
            }
        }
    },
    {
        "filename": "Make_Every_Penny_Count_Difficulty-Adaptive_Self-Consistency_for_Cost-Efficient_Reasoning__p2__score1.00.png",
        "Total_Impact": 0.018847,
        "details": {
            "Informativeness": {
                "impact": 0.006417,
                "llm_score": 3.333,
                "human_score": 5.0
            },
            "Overall Readability": {
                "impact": 0.008283,
                "llm_score": 3.0,
                "human_score": 2.0
            },
            "Creativity": {
                "impact": 0.000895,
                "llm_score": 3.0,
                "human_score": 2.0
            },
            "Design Quality": {
                "impact": -0.00041,
                "llm_score": 4.143,
                "human_score": 3.0
            },
            "Fidelity": {
                "impact": 0.003661,
                "llm_score": 3.0,
                "human_score": 4.0
            }
        }
    },
    {
        "filename": "ZoomEye_Enhancing_Multimodal_LLMs_with_Human-Like_Zooming_Capabilities_through_Tree-Based_Image_Exploration__p7__score0.95.png",
        "Total_Impact": 0.020448,
        "details": {
            "Informativeness": {
                "impact": -0.00382,
                "llm_score": 2.0,
                "human_score": 4.0
            },
            "Overall Readability": {
                "impact": 0.021971,
                "llm_score": 2.0,
                "human_score": 2.0
            },
            "Creativity": {
                "impact": -0.00013,
                "llm_score": 3.333,
                "human_score": 3.0
            },
            "Design Quality": {
                "impact": 0.002872,
                "llm_score": 3.714,
                "human_score": 3.0
            },
            "Fidelity": {
                "impact": -0.000445,
                "llm_score": 4.333,
                "human_score": 4.0
            }
        }
    },
    {
        "filename": "Long-text_Uncertainty_Quantification_for_LLMs__p1__score1.00.png",
        "Total_Impact": 0.022283,
        "details": {
            "Informativeness": {
                "impact": 0.003018,
                "llm_score": 3.0,
                "human_score": 5.0
            },
            "Overall Readability": {
                "impact": 0.007136,
                "llm_score": 4.333,
                "human_score": 5.0
            },
            "Creativity": {
                "impact": 0.007603,
                "llm_score": 3.667,
                "human_score": 5.0
            },
            "Design Quality": {
                "impact": 0.004971,
                "llm_score": 4.429,
                "human_score": 5.0
            },
            "Fidelity": {
                "impact": -0.000445,
                "llm_score": 4.333,
                "human_score": 4.0
            }
        }
    },
    {
        "filename": "SafeDecoding_Defending_against_Jailbreak_Attacks_via_Safety-Aware_Decoding__p4__score1.00.png",
        "Total_Impact": 0.023058,
        "details": {
            "Informativeness": {
                "impact": 0.003018,
                "llm_score": 3.0,
                "human_score": 5.0
            },
            "Overall Readability": {
                "impact": 1.6e-05,
                "llm_score": 3.667,
                "human_score": 5.0
            },
            "Creativity": {
                "impact": 0.013196,
                "llm_score": 4.0,
                "human_score": 5.0
            },
            "Design Quality": {
                "impact": 0.004971,
                "llm_score": 4.429,
                "human_score": 5.0
            },
            "Fidelity": {
                "impact": 0.001858,
                "llm_score": 4.667,
                "human_score": 5.0
            }
        }
    },
    {
        "filename": "How_Johnny_Can_Persuade_LLMs_to_Jailbreak_Them_Rethinking_Persuasion_to_Challenge_AI_Safety_by_Humanizing_LLMs__p3__score0.70.png",
        "Total_Impact": 0.023068,
        "details": {
            "Informativeness": {
                "impact": -0.007483,
                "llm_score": 3.0,
                "human_score": 2.0
            },
            "Overall Readability": {
                "impact": 0.01256,
                "llm_score": 3.0,
                "human_score": 1.0
            },
            "Creativity": {
                "impact": 0.00383,
                "llm_score": 2.667,
                "human_score": 2.0
            },
            "Design Quality": {
                "impact": 0.001433,
                "llm_score": 4.0,
                "human_score": 1.0
            },
            "Fidelity": {
                "impact": 0.012728,
                "llm_score": 3.667,
                "human_score": 1.0
            }
        }
    },
    {
        "filename": "MemInsight_Autonomous_Memory_Augmentation_for_LLM_Agents__p3__score0.95.png",
        "Total_Impact": 0.023868,
        "details": {
            "Informativeness": {
                "impact": -0.010781,
                "llm_score": 2.0,
                "human_score": 5.0
            },
            "Overall Readability": {
                "impact": 0.021971,
                "llm_score": 2.0,
                "human_score": 2.0
            },
            "Creativity": {
                "impact": 0.012902,
                "llm_score": 2.333,
                "human_score": 1.0
            },
            "Design Quality": {
                "impact": 0.010491,
                "llm_score": 3.571,
                "human_score": 2.0
            },
            "Fidelity": {
                "impact": -0.010716,
                "llm_score": 1.667,
                "human_score": 5.0
            }
        }
    },
    {
        "filename": "Reverse_Thinking_Makes_LLMs_Stronger_Reasoners__p3__score1.00.png",
        "Total_Impact": 0.025386,
        "details": {
            "Informativeness": {
                "impact": 0.009248,
                "llm_score": 3.667,
                "human_score": 5.0
            },
            "Overall Readability": {
                "impact": 0.007136,
                "llm_score": 4.333,
                "human_score": 5.0
            },
            "Creativity": {
                "impact": 0.003919,
                "llm_score": 3.667,
                "human_score": 4.0
            },
            "Design Quality": {
                "impact": 0.00191,
                "llm_score": 4.714,
                "human_score": 4.0
            },
            "Fidelity": {
                "impact": 0.003173,
                "llm_score": 5.0,
                "human_score": 5.0
            }
        }
    },
    {
        "filename": "Step-level_Value_Preference_Optimization_for_Mathematical_Reasoning__p2__score1.00.png",
        "Total_Impact": 0.026149,
        "details": {
            "Informativeness": {
                "impact": 6.3e-05,
                "llm_score": 2.667,
                "human_score": 4.0
            },
            "Overall Readability": {
                "impact": 8.9e-05,
                "llm_score": 3.667,
                "human_score": 4.0
            },
            "Creativity": {
                "impact": 0.018384,
                "llm_score": 4.333,
                "human_score": 5.0
            },
            "Design Quality": {
                "impact": 0.004439,
                "llm_score": 3.429,
                "human_score": 3.0
            },
            "Fidelity": {
                "impact": 0.003173,
                "llm_score": 5.0,
                "human_score": 5.0
            }
        }
    },
    {
        "filename": "Generating_Diverse_Hypotheses_for_Inductive_Reasoning__p3__score1.00.png",
        "Total_Impact": 0.028475,
        "details": {
            "Informativeness": {
                "impact": 0.009248,
                "llm_score": 3.667,
                "human_score": 5.0
            },
            "Overall Readability": {
                "impact": 0.007136,
                "llm_score": 4.333,
                "human_score": 5.0
            },
            "Creativity": {
                "impact": -0.000743,
                "llm_score": 3.667,
                "human_score": 3.0
            },
            "Design Quality": {
                "impact": 0.009661,
                "llm_score": 4.714,
                "human_score": 5.0
            },
            "Fidelity": {
                "impact": 0.003173,
                "llm_score": 5.0,
                "human_score": 5.0
            }
        }
    },
    {
        "filename": "Self-Knowledge_Guided_Retrieval_Augmentation_for_Large_Language_Models__p0__score0.95.png",
        "Total_Impact": 0.031618,
        "details": {
            "Informativeness": {
                "impact": 0.010906,
                "llm_score": 1.333,
                "human_score": 2.0
            },
            "Overall Readability": {
                "impact": -0.002767,
                "llm_score": 4.0,
                "human_score": 3.0
            },
            "Creativity": {
                "impact": 0.000765,
                "llm_score": 3.0,
                "human_score": 1.0
            },
            "Design Quality": {
                "impact": 9e-05,
                "llm_score": 4.143,
                "human_score": 4.0
            },
            "Fidelity": {
                "impact": 0.022624,
                "llm_score": 2.0,
                "human_score": 3.0
            }
        }
    },
    {
        "filename": "Model_Editing_by_Standard_Fine-Tuning__p6__score0.90.png",
        "Total_Impact": 0.046329,
        "details": {
            "Informativeness": {
                "impact": -0.00382,
                "llm_score": 2.0,
                "human_score": 4.0
            },
            "Overall Readability": {
                "impact": 0.008283,
                "llm_score": 3.0,
                "human_score": 2.0
            },
            "Creativity": {
                "impact": 0.023395,
                "llm_score": 1.667,
                "human_score": 1.0
            },
            "Design Quality": {
                "impact": 0.016613,
                "llm_score": 3.571,
                "human_score": 1.0
            },
            "Fidelity": {
                "impact": 0.001858,
                "llm_score": 4.667,
                "human_score": 5.0
            }
        }
    },
    {
        "filename": "Distilling_Step-by-Step_Outperforming_Larger_Language_Models_with_Less_Training_Data_and_Smaller_Model_Sizes__p0__score0.60.png",
        "Total_Impact": 0.05146,
        "details": {
            "Informativeness": {
                "impact": 0.013689,
                "llm_score": 1.667,
                "human_score": 1.0
            },
            "Overall Readability": {
                "impact": -0.003593,
                "llm_score": 3.667,
                "human_score": 1.0
            },
            "Creativity": {
                "impact": 0.007041,
                "llm_score": 2.667,
                "human_score": 1.0
            },
            "Design Quality": {
                "impact": 0.001433,
                "llm_score": 4.0,
                "human_score": 1.0
            },
            "Fidelity": {
                "impact": 0.03289,
                "llm_score": 2.333,
                "human_score": 2.0
            }
        }
    }
]