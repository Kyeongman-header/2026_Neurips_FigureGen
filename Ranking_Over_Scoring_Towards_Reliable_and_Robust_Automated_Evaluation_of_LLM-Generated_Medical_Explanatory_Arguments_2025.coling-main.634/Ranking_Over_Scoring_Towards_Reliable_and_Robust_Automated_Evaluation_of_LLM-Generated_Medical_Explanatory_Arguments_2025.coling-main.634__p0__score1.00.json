{
  "source_pdf": "/home/zzangmane/2025_null_Figure/pdfs/coling-2025/Ranking_Over_Scoring_Towards_Reliable_and_Robust_Automated_Evaluation_of_LLM-Generated_Medical_Explanatory_Arguments_2025.coling-main.634.pdf",
  "page": 0,
  "figureType": null,
  "name": "1",
  "caption": "Figure 1: Graphical abstract illustrating the key elements of our approach. Synthetic arguments are first generated by prompting multiple LLMs, which are then ranked alongside gold-standard arguments by both our trained LM evaluator and a human expert. Our results show the LM evaluator aligns with human preferences.",
  "regionBoundary": {
    "x1": 305.76,
    "x2": 499.2,
    "y1": 220.32,
    "y2": 457.91999999999996
  },
  "score": 1.0,
  "reason": "Diagram shows a system architecture for evaluating arguments in MCQA tasks using LLMs."
}