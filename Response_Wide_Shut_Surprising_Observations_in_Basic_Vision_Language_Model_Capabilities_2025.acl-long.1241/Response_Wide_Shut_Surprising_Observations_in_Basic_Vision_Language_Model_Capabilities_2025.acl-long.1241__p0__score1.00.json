{
  "source_pdf": "/home/zzangmane/2025_null_Figure/pdfs/acl-2025/Response_Wide_Shut_Surprising_Observations_in_Basic_Vision_Language_Model_Capabilities_2025.acl-long.1241.pdf",
  "page": 0,
  "figureType": null,
  "name": "1",
  "caption": "Figure 1: Overview of our VLM analysis. Going beyond existing efforts that analyze VLMs as a whole, we study performance of VLMs in terms of intermediate spaces that represent knowledge as it is processed through the VLM network. Specifically, we consider three spaces in VLMs: visual, VL projection and response space; to understand what aspects of visual information are captured (not captured) and where.",
  "regionBoundary": {
    "x1": 321.59999999999997,
    "x2": 507.35999999999996,
    "y1": 220.79999999999998,
    "y2": 363.84
  },
  "score": 1.0,
  "reason": "Depicts a high-level architecture of a vision-language reasoning system, showing its main components and tasks."
}